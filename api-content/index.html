{"posts":[{"title":"互联网+技术存档","content":"研发思路页 审不准 引入模态较少，模态融合不均 模态较少：不解释 模态融合不均（辅助任务与主要模态目标任务之间的权衡和平衡不理想）：（1）主导效应：某些辅助任务可能对网络权重具有过大的影响，甚至主导了网络的学习过程，导致主要模态目标任务的推荐精度下降。（2）影响不足：其他辅助任务可能影响过于弱小，无法有效地帮助主要模态目标任务的学习和性能提升。 核心：为什么会少？（因为引入多了容易导致不均） 数据不均衡 贷款不同情况的数据种类不同。如果某些类别的样本数量较少，会导致数据集的类别分布不平衡。这可能会影响模型对于少数类别的学习能力，造成不平衡预测。 审不起 数据量小且标注成本高 原因：隐私政策，脱敏处理难，标注需要专业训练 3D人脸采集需特定设备（识别改成采集：识别过程中的采集环节花费大，而且本身也缺少采集的3d人脸摄像） 审不快 审批次序绝对固化 实时数据处理与集成低，影响自动化审批速度 自动化审批可能需要与其他系统进行实时数据更新和集成。如果数据更新和集成的频率较低，审批过程中的数据可能不够准确和实时，从而影响审批速度。 （并且传统模型更新网络传输需要一次上传所有样本，更新慢） 审得准 多模态与多过程的数据融合与集成技术 转换成Transformer Embedding：转换成为一种通用编码，整合不同模态数据成为同一种编码，方便数据的对齐和后续的融合 构建图注意力网络：图注意力网络（Graph Attention Networks，GAT）：GAT 是一种使用注意力机制的图深度学习模型，用于对图结构中的节点进行特征表示学习。它通过学习每个节点与其邻居节点之间的注意力权重，对节点进行聚合操作。在数据集成中，可以使用 GAT 对不同数据源的图结构进行编码，并学习节点的表示向量。然后，通过注意力权重，可以对不同数据源的节点表示向量进行加权融合，从而实现数据集成。 为什么构建图注意力网络：解决模态融合不均问题，通过注意力权重很好的平很不同模态的重要性 综合的数据优化策略 positive:出借并按时还款 hard negative：出借缺没按时还款 simple negative：未出借 审得起 对比式联邦学习技术： 对比式联邦学习（Contrastive-style Federated Learning）是将对比学习和联邦学习相结合的一种方法。它旨在通过结合两种技术的优势，同时解决数据隐私和模型性能的问题。它为解决数据隐私和模型性能之间的平衡问题提供了一种有效的解决方案。 在对比式联邦学习中，每个本地设备或数据中心都具有自己的数据集，并使用对比学习的方式来提取本地数据的特征表示。对比学习通过将同一样本的不同视图进行对比，学习样本之间的相似性和差异性。这样可以使得模型能够学习到更具判别性的特征表示。 然后，这些本地设备将使用对比学习得到的特征表示，通过联邦学习的方式进行模型的聚合和更新。联邦学习的过程中，本地设备只需将本地模型的参数传输给中央服务器，而无需上传原始数据。中央服务器根据接收到的参数进行模型的聚合和更新，并将更新后的全局模型发送回本地设备。 通过对比式联邦学习，可以实现以下优势： 数据隐私保护：对比式联邦学习不需要将原始数据上传到中央服务器，保护了用户的隐私。数据仅在本地设备上进行训练和更新，减少了数据泄露的风险。 特征学习和模型聚合：对比学习允许在分散的设备或服务器上进行本地训练，无需依赖中央服务器。联邦学习支持在线学习，本地设备可以在使用的过程中不断更新本地模型，而无需重新上传所有数据。这使得模型能够适应实时数据的变化和演化。且通过联邦学习的方式将不同设备的特征表示进行聚合，从而生成更强大的全局模型。（可以买了设备可以享受联邦学习，没买就只给你对比的，分割商法） 增加样本多样性：对比学习通过生成不同视图的方式增加数据样本的多样性，可以帮助模型更好地处理不同分布的数据。 提高模型性能：通过结合对比学习和联邦学习，可以同时提高模型的隐私性能和学习能力，获得更好的模型性能和泛化能力。这促进了不同组织或个体之间的合作和知识共享，加速了模型的进步。 审得快 打造端边云协同的数据仓库（这个是协同联邦学习的） 端边云协同中的数据仓库是用于存储和管理从设备端和边缘节点收集的数据的中央存储系统。它的作用是集中存储来自各个端点的数据，并提供高效的数据查询、分析和决策支持。 bonus： 决策支持：数据仓库中的数据可以用于支持实时决策和预测分析。通过对存储的数据进行分析和挖掘，可以提取有关业务趋势、行为模式和预测模型的信息，以辅助决策和优化业务流程。 ","link":"https://kimokcheon.github.io/post/hu-lian-wang-ji-zhu-cun-dang/"},{"title":"PhotoShop","content":"PS 中的图像处理技术 一、混合透明模式 声明 以下公式描述中： 0代表纯黑色 0x000 1代表纯白色 0xFFF a 表示当前图层 (activity layer)，取值范围 0 ~ 1 b 表示背景图层 (background layer)，取值范围 0 ~ 1 a，b 图层如果为同一张图像，那么结果就是对同一图像的明暗做出了修改 1. 普通 Normal 1.1 正常 Normal 公式：f(a,b)=af(a,b) = af(a,b)=a 1.2 溶解 Dissolve 上层中随机抽取一些像素作为透明，使其可以看到下层，随着上层透明度越低，可看到的下层区域越多（不是真正的溶解） 公式：f(a,b)=random(a,b)f(a,b) = random(a,b)f(a,b)=random(a,b) 2. 加深 Darken 2.1 变暗 Darken 比较上下层像素后取相对较暗的像素作为输出（与变暗 Lighten 效果相反） RGB 每个色彩通道分别比较取最小 公式：f(a,b)=min(a,b)f(a,b) = min(a,b)f(a,b)=min(a,b) 2.2 深色 Darker Color 比较上下层像素后取相对较暗的像素作为输出（与浅色 Lighter Color 效果相反） 比较 RGB 三个色彩通道数值之和取最小 公式：f(a,b)=min(ar+ag+ab, br+bg+bb)f(a,b) = min(a_r + a_g + a_b, \\space b_r + b_g + b_b)f(a,b)=min(ar​+ag​+ab​, br​+bg​+bb​) 2.3 正片叠底 Multiply 该效果将两层像素的标准色彩值相乘后输出 其效果可以形容成：两个幻灯片叠加在一起然后放映，透射光需要分别通过这两个幻灯片，从而被削弱了两次 公式：f(a,b)=abf(a,b) = abf(a,b)=ab 2.3 颜色加深 Color Burn 如果上层越暗，则下层获取的光越少（与颜色加深 Color Dodge 相反） 上层为全黑色，则下层越黑 上层为全白色，则根本不会影响下层：结果最亮的地方不会高于下层的像素值 公式：f(a,b)=1−1−baf(a,b) = 1-{1-b \\over a}f(a,b)=1−a1−b​ 2.4 线性加深 Linear Burn 如果上下层的像素值之和小于 1，输出结果将会是纯黑色（与线性减淡 Linear Dodge 相反） 如果将上层反相，结果将是纯粹的数学减 公式：f(a,b)=a+b−1f(a,b) = a+b-1f(a,b)=a+b−1 3. 减淡 Lighten 3.1 变亮 Lighten 比较上下层像素后取相对较亮的像素作为输出（与变暗 Darken 相反） RGB 每个色彩通道分别比较取最大 公式：f(a,b)=max(a,b)f(a,b) = max(a,b)f(a,b)=max(a,b) 3.5 浅色 Lighter Color 比较上下层像素后取相对较暗的像素作为输出（与深色 Darker Color 效果相反） 比较 RGB 三个色彩通道数值之和取最大 公式：f(a,b)=max(ar+ag+ab, br+bg+bb)f(a,b) = max(a_r + a_g + a_b, \\space b_r + b_g + b_b)f(a,b)=max(ar​+ag​+ab​, br​+bg​+bb​) 3.2 滤色 Screen 上下层像素的标准色彩值反相后相乘后输出，输出结果比两者的像素值都将要亮 就好像两台投影机分别对其中一个图层进行投影后，然后投射到同一个屏幕上 如果两个图层反相后，采用 Multiply 模式混合，则将和对这两个图层采用 Screen 模式混合后反相的结果完全一样 公式：f(a,b)=1−(1−a)(1−b)1−f(a,b)=(1−a)(1−b)f(a,b)=1-(1-a)(1-b)\\\\ 1-f(a,b)=(1-a)(1-b)f(a,b)=1−(1−a)(1−b)1−f(a,b)=(1−a)(1−b) 3.3 颜色减淡 Color Dodge 该模式下，上层的亮度决定了下层的暴露程度（与颜色加深 Color Burn 相反） 如果上层越亮，下层获取的光越多，也就是越亮 公式：f(a,b)=b1−af(a,b) = {b \\over 1-a}f(a,b)=1−ab​ 3.4 线性减淡 Linear Dodge 将上下层的色彩值相加，结果将更亮（与线性加深 Linear Burn 相反） 公式：f(a,b)=a+bf(a,b) = a+bf(a,b)=a+b 4. 对比 Contrast 4.1 叠加 Overlay 依据下层色彩值的不同，该模式可能是 Multiply，也可能是 Screen 模式 上层决定了下层中间色调偏移的强度 公式：f(a,b)={2ab,if a&lt;0.51−2(1−a)(1−b),otherwisef(a,b)=\\begin{cases}2ab, &amp; if \\space a &lt; 0.5\\\\ 1-2(1-a)(1-b), &amp; otherwise \\end{cases}f(a,b)={2ab,1−2(1−a)(1−b),​if a&lt;0.5otherwise​ 4.2 柔光 Soft Light 叠加模式下，过上层的颜色高于 50% 灰，则下层越亮，反之越暗 以 Gamma 值范围为 2.0 到 0.5 的方式来调制下层的色彩值，结果将是一个非常柔和的组合 公式：f(a,b)={2ab+a2(1−2b),if a&lt;0.52a(1−b)+a(2b−1),otherwisef(a,b) =\\begin{cases}2ab+a^2(1-2b), &amp; if \\space a &lt; 0.5\\\\ 2a(1-b)+ \\sqrt{a}(2b-1), &amp; otherwise \\end{cases}f(a,b)={2ab+a2(1−2b),2a(1−b)+a​(2b−1),​if a&lt;0.5otherwise​ 4.3 强光 Hard Light 叠加模式下，过上层的颜色高于 50% 灰，则下层越亮，反之越暗 公式：f(a,b)={2ab,if a&lt;0.51−2(1−a)(1−b),otherwisef(a,b) =\\begin{cases}2ab, &amp; if \\space a &lt; 0.5\\\\ 1-2(1-a)(1-b), &amp; otherwise \\end{cases}f(a,b)={2ab,1−2(1−a)(1−b),​if a&lt;0.5otherwise​ 4.4 亮光 Vivid Light 非常强烈的增加了对比度，特别是在高亮和阴暗处 阴暗处应用颜色加深 Color Burn 高亮处应用颜色减淡 Color Dodge 公式：f(a,b)={1−1−b2a,if a≤0.5b2(1−a),otherwisef(a,b) =\\begin{cases}1-{1-b \\over 2a}, &amp; if \\space a \\leq 0.5\\\\ {b \\over 2(1-a)}, &amp; otherwise \\end{cases}f(a,b)={1−2a1−b​,2(1−a)b​,​if a≤0.5otherwise​ 4.5 线性光 Linear Light 增加了对比度，特别是在高亮和阴暗处（比亮光 Vivid Light 对比度增加的少） 类似于线性加深 Linear Burn，只不过是加深了上层的影响力 公式：f(a,b)=b+2a−1f(a,b) = b+2a-1f(a,b)=b+2a−1 4.6 点光 Pin Light 中间调几乎是不变的下层，但是两边是变暗 Darken 和变亮 Light 模式的组合 公式：f(a,b)={2a−1,if 2a−1&gt;bb,if 2a−1&lt;b&lt;2a2a,if b&gt;2af(a,b) = \\begin{cases}2a-1, &amp; if \\space 2a-1&gt;b\\\\ b, &amp; if \\space 2a-1&lt;b&lt;2a\\\\ 2a, &amp; if \\space b&gt;2a\\end{cases}f(a,b)=⎩⎪⎨⎪⎧​2a−1,b,2a,​if 2a−1&gt;bif 2a−1&lt;b&lt;2aif b&gt;2a​ 4.7 实色混合 Hard mix 最终结果仅包含 6 种基本颜色，每个通道要么就是 0，要么就是 1 公式：f(a,b)={0,if a&lt;1−b1,if a&gt;1−bf(a,b) =\\begin{cases}0, &amp; if \\space a&lt;1-b\\\\ 1, &amp; if \\space a&gt;1-b \\end{cases}f(a,b)={0,1,​if a&lt;1−bif a&gt;1−b​ 5. 差集 Inversion/Cancelation 5.1 差值 Difference 用于比较两个不同版本的图片：如果两者完全一样，则结果为全黑 公式：f(a,b)=abs(b−a)f(a,b) = abs(b-a)f(a,b)=abs(b−a) 5.2 排除 Exclusion 亮的图片区域将导致另一层的反相，很暗的区域则将导致另一层完全没有改变 公式：f(a,b)=a+b−2abf(a,b) = a+b-2abf(a,b)=a+b−2ab 5.3 减去 Subtract 公式：f(a,b)=b−af(a,b) = b-af(a,b)=b−a 5.4 划分 Divide 公式：f(a,b)=b/af(a,b) = b/af(a,b)=b/a 6. 色彩模型 Component 6.1 色相 Hue 在 HSB 色彩模型中，使用当前图层的色相，使用背景图层的饱和度和明度 公式：HcScBc=HaSbBbH_cS_cB_c = \\color{red}{H_a}S_bB_bHc​Sc​Bc​=Ha​Sb​Bb​ 6.2 颜色 Color 在 HSB 色彩模型中，使用当前图层的色相和饱和度，使用背景图层的明度 公式：HcScBc=HaSaBbH_cS_cB_c = \\color{red}{H_aS_a}B_bHc​Sc​Bc​=Ha​Sa​Bb​ 6.3 饱和度 Saturation 在 HSB 色彩模型中，使用当前图层的饱和度，使用背景图层的色相和明度 公式：HcScBc=HbSaBbH_cS_cB_c = H_b\\color{red}{S_a}B_bHc​Sc​Bc​=Hb​Sa​Bb​ 6.4 明度 Luminosity 在 HSB 色彩模型中，使用当前图层的明度，使用背景图层的色相和饱和度（与颜色相反） 公式：HcScBc=HbSbBaH_cS_cB_c = H_bS_b\\color{red}{B_a}Hc​Sc​Bc​=Hb​Sb​Ba​ Reference Photoshop Blend Modes Explained Wiki: Blend modes Adobe blending-modes stackoverflow: how-does-photoshop-blend-two-images-together ","link":"https://kimokcheon.github.io/post/photoshop/"},{"title":"Colors","content":"一、彩色图像处理 人眼对明暗比颜色更加敏感，RGB 色光三原色中人眼对绿色比较敏感 1. 颜色的特性 1.1 颜色的心理学特征：人对光的感觉而产生的光的特性 色彩 Hue： 光谱（一定电磁频谱范围内）中的主频率/主波长 纯度 Purity / 饱和度 Satruation： 一种颜色混合白色的比例（100% 是无白光混合，纯度最高），纯度高了色彩会鲜亮 色度 Chromaticity： 代表了光的纯度和色彩这两种特征的组合 亮度 Brightness： 光源的强度/振幅，物体表面的反光率（实际上不能度量，人眼对亮度的敏感 &gt; 色彩） Luminance(Y)：物理度量，没有具体的大小范围，是某个方向上行进的每单位面积光的发光强度 Luma(Y')：通过将物理度量的亮度伽马矫正后，具有固定大小范围的相对亮度 1.2 直观的颜色概念 明暗 Shades： 纯色颜料里添加黑色颜料 色泽 Tints： 纯色颜料里添加白色颜料 色调 Tones： 纯色颜料里同时添加黑色和白色颜料 补色 Complementary Color： 两个颜色相加是白色，则互为补色（在色环上，与一个色调直接相对的另一端） 让颜色变亮不是加白，是减去补色，这样色调才不会改变（用于增强图像暗区细节） 2. 色彩模型 颜色模型是在某种情况下对颜色的特征和行为的解释，没有哪种颜色模型能解决所有的颜色问题 较少的颜色比使用较多的颜色能产生更令人满意的显示，淡色和暗色的混合比纯色彩更柔和 2.1 RGB 色彩模型 特点：基于三刺激理论，适合色彩生成，适合硬件设备对于色彩的实现 加色混色模型：颜色混在一起亮度增大，Red、Green、Blue 三种颜色的取值范围是 [0, 255] 使用 RGB 色彩模型的应用： 3D LUT 的 Unity 实现 3D LUT Creator Tutorials 2.2 CMY 和 CMYK 色彩模型 特点：适合色彩生成，适合硬件设备对于色彩的实现 减色混色模型：颜色混在一起亮度降低，Cyan (青)、Magenta (品红)、Yellow(黄)、BlacK(黑)，加入黑色是因为打印时由品红、黄、青构成的黑色不够纯粹 2.2.1 RGB 与 CMY 的转换 公式：假设所有彩色值都归一化到了 [0, 1] 的范围内 ​[CMY]=[111]−[RGB]\\begin{bmatrix} C\\\\ M\\\\ Y \\end{bmatrix} = \\begin{bmatrix} 1\\\\ 1\\\\ 1 \\end{bmatrix} - \\begin{bmatrix} R\\\\ G\\\\ B \\end{bmatrix} ⎣⎡​CMY​⎦⎤​=⎣⎡​111​⎦⎤​−⎣⎡​RGB​⎦⎤​ 2.3 HSI、HSL 和 HSV 色彩模型 特点：适合色彩描述、电脑绘画、图像算法的处理，人能观察的色彩并不是由 RGB 三种颜色混合而成，而是取决于颜色的亮度、色调、饱和度。HSI、HSL、HSV 方便和RGB 进行互相转换 HSI、HSL 和 HSV 更多的是一种色彩模型，并不是一个绝对不变的色彩空间，它的取值范围，取决于来自于 RGB 输入的取值范围 2.3.1 关键概念 Hue：色相，决定什么颜色，对应 红 (0°) 绿(120°) 蓝(240°) 首尾相接的色相环值，取值范围 [0, 360) Saturation：饱和度，决定颜色浓淡，一种颜色混合白光的比例（100% 是无白光混合），物体反射的颜色，饱和度高了色彩会鲜亮 Value：饱和度值 Lightness：明度，光源的明暗，人们所感知到的色彩明暗度 Brightness/Luminance/Intensity：亮度，光的振幅，物体表面的反光率，表面色彩白色的多少 Chroma：色度 = 色相(方向) + 饱和度(大小)，一种颜色混合白光的比例（100% 是无白光混合） 2.3.2 各自的特点 HSI 主要用于方便处理图片色彩，而非用于修改和选择颜色 HSL 和 HSV 有相同的灰度定义，但在 饱和度 和 亮度的定义方面是不同的： 亮度：HSL 最大为 0.5，HSV 最大为 1 饱和度：饱和度为 1 时，HSL 亮度为 0.5，HSV 亮度为 1 明度和亮度：都决定照射在颜色上的白光有多亮，亮度与颜色的辐射能量有关，但能量高的颜色不一定明度高。例，蓝色的能量很高，但其明度却低 more HSL、HSV、HSI缺点： 在高色度上的亮度相对于 YUV 偏离过多 在选择颜色和配色方案上存在问题 2.3.3 转换公式推导 从 RGB 到 HSI 或 HSL 或 HSV 的 Hue 是由 RGB 的如下整投影得到的： M：max(R, G, B) 、m：min(R, G, B)、C：色度 = M - m I: HSI 里的 I，Y'：YUV 里的灰度值 2.3.4 RGB 与 HSL 的互相转换 RGB 转 HSL 公式： 如果 R = G = B 时，颜色是非彩色的，H (色相) 无定义，H = S = 0 max 是 R、G、B 中的最大值 min 是 R、G、B 中的最小值 R∈[0,1],G∈[0,1],B∈[0,1]R \\in [0,1], G \\in [0,1], B \\in [0,1]R∈[0,1],G∈[0,1],B∈[0,1] H∈[0,360),S∈[0,1],L∈[0,1]H \\in [0, 360), S \\in [0,1], L \\in [0,1]H∈[0,360),S∈[0,1],L∈[0,1] ​ H={0,if max = minG−Bmax−min×60,if max = R and G ≥ BG−Bmax−min×60+360,if max = R and G &lt; BB−Rmax−min×60+120,if max = GR−Gmax−min×60+240,if max = BL=12(max+min)S={0,if max = min or L = 1max−min1−∣2L−1∣,otherwise\\begin{aligned} H &amp;= \\begin{cases} 0, &amp;\\text{if max = min}\\\\ {G - B \\over max - min} \\times 60 , &amp;\\text{if max = R and G $\\geq$ B} \\\\ {G - B \\over max - min} \\times 60 + 360, &amp;\\text{if max = R and G $\\lt$ B}\\\\ {B - R \\over max - min} \\times 60 + 120, &amp;\\text{if max = G}\\\\ {R - G \\over max - min} \\times 60 + 240, &amp;\\text{if max = B} \\\\ \\end{cases} \\\\\\\\ L &amp;= \\frac 12(max + min) \\\\\\\\ S &amp; = \\begin{cases} 0 , &amp;\\text{if max = min or L = 1}\\\\ {max - min \\over 1 - |2L - 1|} , &amp;\\text{otherwise} \\end{cases} \\end{aligned} HLS​=⎩⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎧​0,max−minG−B​×60,max−minG−B​×60+360,max−minB−R​×60+120,max−minR−G​×60+240,​if max = minif max = R and G ≥ Bif max = R and G &lt; Bif max = Gif max = B​=21​(max+min)={0,1−∣2L−1∣max−min​,​if max = min or L = 1otherwise​​ 代码： // GLSL vec3 RGBToHSL(vec3 color) { float minRGB = min(min(color.r, color.g), color.b); float maxRGB = max(max(color.r, color.g), color.b); float sum = maxRGB + minRGB; float chroma = maxRGB - minRGB; float luminance = 0.5 * sum; vec3 hsl = vec3(0.0, 0.0, luminance); if (chroma == 0.0) return hsl; // R = G = B, 颜色是非彩色的 S = 0，这是色相无定义 H = 0 // Saturation hsl.y = luminance == 1.0 ? 0.0 : chroma / (1.0 - abs(2.0 * luminance - 1.0)); // Hue 原来范围是 [0, 360), 这里默认输入的范围是 [0, 1] /** 尽管这样并不一定能真的提高效率，但是这个规避 if else 的思想值得思考 vec3 comp; comp.rg = vec2(equal(rgb.rg, vec2(maxRGB))); float invertR = 1.0 - comp.r; // 0 or 1 comp.g *= invertR; // g = invertR * g comp.b = invertR * (1.0 - comp.g); // b = invertR * invertG hsl.x = dot(comp, vec3((color.g - color.b) / chroma, (color.b - color.r) / chroma + 2.0, (color.r - color.g) / chroma + 4.0)); hsl.x /= 6.0; */ if (color.r == maxRGB) { hsl.x = (color.g - color.b) / chroma / 6.0; } else if (color.g == maxRGB) { hsl.x = ((color.b - color.r) / chroma + 2.0) / 6.0; } else { hsl.x = ((color.r - color.g) / chroma + 4.0) / 6.0; } // Optimize // hsl.x += 1.0 - step(0.0, hsl.x); if (hsl.x &lt; 0.0) hsl.x += 1.0; return hsl; } HSL 转 RGB 公式： 如果 S (饱和度) = 0，则颜色是非彩色的。H (色相)无意义， R = G = B = L (亮度) 如果 S (饱和度) != 0，有如下公式 R∈[0,1],G∈[0,1],B∈[0,1]R \\in [0,1], G \\in [0,1], B \\in [0,1]R∈[0,1],G∈[0,1],B∈[0,1] H∈[0,360),S∈[0,1],L∈[0,1]H \\in [0, 360), S \\in [0,1], L \\in [0,1]H∈[0,360),S∈[0,1],L∈[0,1] H' 取整数时，两边计算结果相同 H′=H60C=(1−∣2L−1∣)×SX=(1−∣H′(mod2)−1∣)×Cm=L−12C(R,G,B)={(C+m,X+m,m),if 0≤H′≤1(X+m,C+m,m),if 1≤H′≤2(m,C+m,X+m),if 2≤H′≤3(m,X+m,C+m),if 3≤H′≤4(X+m,m,C+m),if 4≤H′≤5(C+m,m,X+m),if 5≤H′&lt;6\\begin{aligned} H&#x27; &amp;= {H \\over 60}\\\\ C &amp;= (1 - |2L - 1|) \\times S \\\\ X &amp;= (1 - |H&#x27; \\pmod 2 - 1|)\\times C \\\\ m &amp;= L - \\frac 12 C \\\\\\\\ (R, G, B) &amp;= \\begin{cases} (C + m, X + m, m), &amp;\\text{if $0 \\leq H&#x27; \\leq 1$}\\\\ (X + m, C + m, m), &amp;\\text{if $1 \\leq H&#x27; \\leq 2$} \\\\ (m, C + m, X + m), &amp;\\text{if $2 \\leq H&#x27; \\leq 3$} \\\\ (m, X + m, C + m), &amp;\\text{if $3 \\leq H&#x27; \\leq 4$} \\\\ (X + m, m, C + m), &amp;\\text{if $4 \\leq H&#x27; \\leq 5$} \\\\ (C + m, m, X + m), &amp;\\text{if $5 \\leq H&#x27; \\lt 6$} \\\\ \\end{cases}\\\\ \\end{aligned} H′CXm(R,G,B)​=60H​=(1−∣2L−1∣)×S=(1−∣H′(mod2)−1∣)×C=L−21​C=⎩⎪⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎪⎧​(C+m,X+m,m),(X+m,C+m,m),(m,C+m,X+m),(m,X+m,C+m),(X+m,m,C+m),(C+m,m,X+m),​if 0≤H′≤1if 1≤H′≤2if 2≤H′≤3if 3≤H′≤4if 4≤H′≤5if 5≤H′&lt;6​​ 代码： vec3 HSLToRGB(vec3 color) { if (color.y == 0.0) return vec3(color.z); // Luminance float hue = color.x; hue *= 6.0; // Hue 默认范围是 [0, 1] float chroma = (1.0 - abs(2.0 * color.z - 1.0)) * color.y; float m = color.z - 0.5 * chroma; // Lightness float x = (1.0 - abs(mod(hue, 2.0) - 1.0)) * chroma; if (hue &lt; 1.0){ return vec3(chroma + m, x + m, m); } else if (hue &lt; 2.0){ return vec3(x + m, chroma + m, m); } else if (hue &lt; 3.0){ return vec3(m, chroma + m, x + m); } else if (hue &lt; 4.0){ return vec3(m, x + m, chroma + m); } else if (hue &lt; 5.0){ return vec3(x + m, m, chroma + m); } else { return vec3(chroma + m, m, x + m); } } 2.3.5 RGB 与 HSV 的互相转换 RGB 转 HSV 公式： 如果 R = G = B 时，颜色是非彩色的，H (色相) 无定义，H = S = 0 max 是 R、G、B 中的最大值 min 是 R、G、B 中的最小值 R∈[0,1],G∈[0,1],B∈[0,1]R \\in [0,1], G \\in [0,1], B \\in [0,1]R∈[0,1],G∈[0,1],B∈[0,1] H∈[0,360),S∈[0,1],V∈[0,1]H \\in [0, 360), S \\in [0,1], V \\in [0,1]H∈[0,360),S∈[0,1],V∈[0,1] H={0,if max = minG−Bmax−min×60,if max = R and G ≥ BG−Bmax−min×60+360,if max = R and G &lt; BB−Rmax−min×60+120,if max = GR−Gmax−min×60+240,if max = BS={0,if max = 0max−minmax,if max ≠0V=max\\begin{aligned} H &amp;= \\begin{cases} 0, &amp;\\text{if max = min}\\\\ {G - B \\over max - min} \\times 60 , &amp;\\text{if max = R and G $\\geq$ B} \\\\ {G - B \\over max - min} \\times 60 + 360, &amp;\\text{if max = R and G $\\lt$ B}\\\\ {B - R \\over max - min} \\times 60 + 120, &amp;\\text{if max = G}\\\\ {R - G \\over max - min} \\times 60 + 240, &amp;\\text{if max = B} \\\\ \\end{cases} \\\\\\\\ S &amp; = \\begin{cases} 0 , &amp;\\text{if max = 0}\\\\ {max - min \\over max}, &amp;\\text{if max $\\neq 0$} \\end{cases} \\\\\\\\ V &amp;= max \\end{aligned} HSV​=⎩⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎧​0,max−minG−B​×60,max−minG−B​×60+360,max−minB−R​×60+120,max−minR−G​×60+240,​if max = minif max = R and G ≥ Bif max = R and G &lt; Bif max = Gif max = B​={0,maxmax−min​,​if max = 0if max ​=0​=max​ 代码： // GLSL vec3 RGBToHSV(vec3 color) { float minRGB = min(min(color.r, color.g), color.b); float maxRGB = max(max(color.r, color.g), color.b); float sum = maxRGB + minRGB; float chroma = maxRGB - minRGB; // V = maxRGB; vec3 hsv = vec3(0.0, 0.0, maxRGB); if (chroma == 0.0) return hsv; // Saturation hsv.y = maxRGB == 0.0 ? 0.0 : chroma / maxRGB; // Hue 原来范围是 [0, 360), 这里默认输入的范围是 [0, 1] if (color.r == maxRGB) { hsv.x = (color.g - color.b) / chroma / 6.0; } else if (color.g == maxRGB) { hsv.x = ((color.b - color.r) / chroma + 2.0) / 6.0; } else { hsv.x = ((color.r - color.g) / chroma + 4.0) / 6.0; } // Optimize // hsv.x += 1.0 - step(0.0, hsv.x); if (hsv.x &lt; 0.0) hsv.x += 1.0; return hsv; } HSV 转 RGB 公式： 如果 S (饱和度) = 0，则颜色是非彩色的。H (色相)无意义， R = G = B = L (亮度)如果 S (饱和度) != 0，有如下公式 R∈[0,1],G∈[0,1],B∈[0,1]R \\in [0,1], G \\in [0,1], B \\in [0,1]R∈[0,1],G∈[0,1],B∈[0,1] H∈[0,360),S∈[0,1],V∈[0,1]H \\in [0, 360), S \\in [0,1], V \\in [0,1]H∈[0,360),S∈[0,1],V∈[0,1] H′=H60C=V×SX=(1−∣H′(mod2)−1∣)×Cm=V−C(R,G,B)={(C+m,X+m,m),if 0≤H′≤1(X+m,C+m,m),if 1≤H′≤2(m,C+m,X+m),if 2≤H′≤3(m,X+m,C+m),if 3≤H′≤4(X+m,m,C+m),if 4≤H′≤5(C+m,m,X+m),if 5≤H′&lt;6\\begin{aligned} H&#x27; &amp;= {H \\over 60}\\\\ C &amp;= V \\times S \\\\ X &amp;= (1 - |H&#x27; \\pmod 2 - 1|)\\times C \\\\ m &amp;= V - C \\\\\\\\ (R, G, B) &amp;= \\begin{cases} (C + m, X + m, m), &amp;\\text{if $0 \\leq H&#x27; \\leq 1$}\\\\ (X + m, C + m, m), &amp;\\text{if $1 \\leq H&#x27; \\leq 2$} \\\\ (m, C + m, X + m), &amp;\\text{if $2 \\leq H&#x27; \\leq 3$} \\\\ (m, X + m, C + m), &amp;\\text{if $3 \\leq H&#x27; \\leq 4$} \\\\ (X + m, m, C + m), &amp;\\text{if $4 \\leq H&#x27; \\leq 5$} \\\\ (C + m, m, X + m), &amp;\\text{if $5 \\leq H&#x27; \\lt 6$} \\\\ \\end{cases}\\\\ \\end{aligned} H′CXm(R,G,B)​=60H​=V×S=(1−∣H′(mod2)−1∣)×C=V−C=⎩⎪⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎪⎧​(C+m,X+m,m),(X+m,C+m,m),(m,C+m,X+m),(m,X+m,C+m),(X+m,m,C+m),(C+m,m,X+m),​if 0≤H′≤1if 1≤H′≤2if 2≤H′≤3if 3≤H′≤4if 4≤H′≤5if 5≤H′&lt;6​​ ⌊ ⌋ Floor 向下取整： 比自己小的最大整数，舍弃小数位 ⌈ ⌉ Ceiling 向上取整： 比自己大的最小整数，有小数位就进 1 ≡\\equiv≡ ： 恒等号 一般用于一些参变量恒为一个常数或恒定表达式时，总等于关系与变量无关。例 f(x)≡k，f(x)f(x) \\equiv k，f(x)f(x)≡k，f(x) 的值始终为 k 而与 x 无关 同余符号，例 a≡b(modc)a \\equiv b \\pmod ca≡b(modc) ，a 和 b 分别除以 c 得到的余数相同 代码： // GLSL vec3 HSVToRGB(vec3 color) { if (color.y == 0.0) return vec3(color.z); // Luminance float hue = color.x; hue *= 6.0; // Hue 默认范围是 [0, 1] float chroma = color.z * color.y; float m = color.z - chroma; // Lightness float x = (1.0 - abs(mod(hue, 2.0) - 1.0)) * chroma; if (hue &lt; 1.0){ return vec3(chroma + m, x + m, m); } else if (hue &lt; 2.0){ return vec3(x + m, chroma + m, m); } else if (hue &lt; 3.0){ return vec3(m, chroma + m, x + m); } else if (hue &lt; 4.0){ return vec3(m, x + m, chroma + m); } else if (hue &lt; 5.0){ return vec3(x + m, m, chroma + m); } else { return vec3(chroma + m, m, x + m); } } 2.3.6 RGB 与 HSI 的互相转换 RGB 转 HSI 公式： 如果 R = G = B 时，颜色是非彩色的，H (色相) 无定义，H = S = 0 max 是 R、G、B 中的最大值 min 是 R、G、B 中的最小值 R∈[0,1],G∈[0,1],B∈[0,1]R \\in [0,1], G \\in [0,1], B \\in [0,1]R∈[0,1],G∈[0,1],B∈[0,1] H∈[0,360),S∈[0,1],I∈[0,1]H \\in [0, 360), S \\in [0,1], I \\in [0,1]H∈[0,360),S∈[0,1],I∈[0,1] H={0,if max = minG−Bmax−min×60,if max = R and G ≥ BG−Bmax−min×60+360,if max = R and G &lt; BB−Rmax−min×60+120,if max = GR−Gmax−min×60+240,if max = BI=13(R+G+B)S={0,if I = 01−minI,if I≠0\\begin{aligned} H &amp;= \\begin{cases} 0, &amp;\\text{if max = min}\\\\ {G - B \\over max - min} \\times 60 , &amp;\\text{if max = R and G $\\geq$ B} \\\\ {G - B \\over max - min} \\times 60 + 360, &amp;\\text{if max = R and G $\\lt$ B}\\\\ {B - R \\over max - min} \\times 60 + 120, &amp;\\text{if max = G}\\\\ {R - G \\over max - min} \\times 60 + 240, &amp;\\text{if max = B} \\\\ \\end{cases} \\\\\\\\ I &amp;= \\frac 1 3 (R+G+B)\\\\\\\\ S &amp; = \\begin{cases} 0 , &amp;\\text{if $I$ = 0}\\\\ 1 - {min \\over I}, &amp;\\text{if $I \\neq 0$} \\end{cases} \\\\ \\end{aligned} HIS​=⎩⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎧​0,max−minG−B​×60,max−minG−B​×60+360,max−minB−R​×60+120,max−minR−G​×60+240,​if max = minif max = R and G ≥ Bif max = R and G &lt; Bif max = Gif max = B​=31​(R+G+B)={0,1−Imin​,​if I = 0if I​=0​​ 代码： // GLSL vec3 RGBToHSI(vec3 color) { float minRGB = min(min(color.r, color.g), color.b); float maxRGB = max(max(color.r, color.g), color.b); float sum = maxRGB + minRGB; float chroma = maxRGB - minRGB; // Intensity; float intensity = dot(vec3(0.3333), color); vec3 hsi = vec3(0.0, 0.0, intensity); if (chroma == 0.0) return hsi; // Saturation hsi.y = intensity == 0.0 ? 0.0 : 1.0 - minRGB / intensity; // Hue 原来范围是 [0, 360), 这里默认输入的范围是 [0, 1] if (color.r == maxRGB) { hsi.x = (color.g - color.b) / chroma / 6.0; } else if (color.g == maxRGB) { hsi.x = ((color.b - color.r) / chroma + 2.0) / 6.0; } else { hsi.x = ((color.r - color.g) / chroma + 4.0) / 6.0; } // Optimize // hsi.x += 1.0 - step(0.0, hsi.x); if (hsi.x &lt; 0.0) hsi.x += 1.0; return hsi; } HSI 转 RGB 公式： 如果 S (饱和度) = 0，则颜色是非彩色的。H (色相)无意义， R = G = B = L (亮度) 如果 S (饱和度) != 0，有如下公式 R∈[0,1],G∈[0,1],B∈[0,1]R \\in [0,1], G \\in [0,1], B \\in [0,1]R∈[0,1],G∈[0,1],B∈[0,1] H∈[0,360),S∈[0,1],I∈[0,1]H \\in [0, 360), S \\in [0,1], I \\in [0,1]H∈[0,360),S∈[0,1],I∈[0,1] ​ H′=H60Z=1−∣H′(mod2)−1∣C=3⋅S⋅I1+ZX=C⋅Zm=(1−S)⋅I(R,G,B)={(C+m,X+m,m),if 0≤H′≤1(X+m,C+m,m),if 1≤H′≤2(m,C+m,X+m),if 2≤H′≤3(m,X+m,C+m),if 3≤H′≤4(X+m,m,C+m),if 4≤H′≤5(C+m,m,X+m),if 5≤H′&lt;6\\begin{aligned} H&#x27; &amp;= {H \\over 60}\\\\ Z &amp;= 1 - |H&#x27; \\pmod 2 - 1| \\\\ C &amp;= {3 \\cdot S \\cdot I \\over 1 + Z} \\\\ X &amp;= C \\cdot Z\\\\ m &amp;= (1 - S) \\cdot I \\\\\\\\ (R, G, B) &amp;= \\begin{cases} (C + m, X + m, m), &amp;\\text{if $0 \\leq H&#x27; \\leq 1$}\\\\ (X + m, C + m, m), &amp;\\text{if $1 \\leq H&#x27; \\leq 2$} \\\\ (m, C + m, X + m), &amp;\\text{if $2 \\leq H&#x27; \\leq 3$} \\\\ (m, X + m, C + m), &amp;\\text{if $3 \\leq H&#x27; \\leq 4$} \\\\ (X + m, m, C + m), &amp;\\text{if $4 \\leq H&#x27; \\leq 5$} \\\\ (C + m, m, X + m), &amp;\\text{if $5 \\leq H&#x27; \\lt 6$} \\\\ \\end{cases}\\\\ \\end{aligned} H′ZCXm(R,G,B)​=60H​=1−∣H′(mod2)−1∣=1+Z3⋅S⋅I​=C⋅Z=(1−S)⋅I=⎩⎪⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎪⎧​(C+m,X+m,m),(X+m,C+m,m),(m,C+m,X+m),(m,X+m,C+m),(X+m,m,C+m),(C+m,m,X+m),​if 0≤H′≤1if 1≤H′≤2if 2≤H′≤3if 3≤H′≤4if 4≤H′≤5if 5≤H′&lt;6​​ 代码： // GLSL vec3 HSIToRGB(vec3 color) { if (color.y == 0.0) return vec3(color.z); // Luminance float hue = color.x; hue *= 6.0; // Hue 默认范围是 [0, 1] float tmp = 1.0 - abs(mod(hue, 2.0) - 1.0); float chroma = 3.0 * color.y * color.z / (1.0 + tmp); float x = chroma * tmp; float m = (1 - chroma) * color.z; // Lightness if (hue &lt; 1.0){ return vec3(chroma + m, x + m, m); } else if (hue &lt; 2.0){ return vec3(x + m, chroma + m, m); } else if (hue &lt; 3.0){ return vec3(m, chroma + m, x + m); } else if (hue &lt; 4.0){ return vec3(m, x + m, chroma + m); } else if (hue &lt; 5.0){ return vec3(x + m, m, chroma + m); } else { return vec3(chroma + m, m, x + m); } } 3. 色彩编码 YUV 和 YCbCr YUV 和 YCbCr 更多的是一种色彩模型，并不是一个绝对不变的色彩空间，它的取值范围，取决于来自于 RGB 输入的取值范围 特点：适合电视系统，数码摄影的色彩压缩和传输 3.1 区分 YUV、YCbCr、Y'CbCr YUV、YCbCr、Y'CbCr 相似之处 Y 表示亮度，Y' 表示经过伽马矫正后的亮度 U 和 Cb 代表蓝色与亮度差 V 和 Cr 代表红色与亮度差 YUV、YCbCr 不同之处 YUV：处理模拟信号的数据格式 Y 的范围是 [0, 1]，UV 的范围是 [-0.5, 0.5] YCbCr (又称 YPbPr)：处理数字信号的数据格式，YUV 色彩空间被缩放和偏移后是 YCbCr 当使用 8 位存储单个分量时，Y 的范围是 [16, 235]，UV 的范围是 [16, 240] 3.2 YUV 的采样方式和存储格式 数字信号通常被压缩以减少文件大小并节省传输时间。由于人类视觉系统对亮度的变化比颜色更敏感，因此，视频系统可以通过向亮度分量 Y，赋予更多的带宽来优化，而不是在色差分量UV中 more 采样方式 采样通常为YUV J:A:B 三部分的比率，采样都从图片的左上角第一行逐行开始 J：单行水平方向的采样像素总个数，通常为 4 A：在两行采样像素矩形中，每行采样像素中色彩样本的个数 B：在两行采样像素矩形中，每列竖直方向色彩样本不同个数之和 存储格式 打包格式（packed）：YUV 存储在一个数组中（YUV 数据相邻） 平面格式（planar）：Y、U、V 或 Y 、UV 分别作为不同的平面存储（YUV 数据互相独立） 采样方式 + 存储方式，实例 以下存储，一个像素点对应一个 Y，四个像素点根据采样比例不同对应不同个数的 UV 采样方式 4:4:4 每像素 32 位（打包格式） 采样方式 4:2:2 每像素 16 位（打包格式） 采样方式 4:2:0 每像素 16 位（平面格式） IMC2：在同一行数组中，先有 V 数据，再有 U 数据 YV12：在同一行数组中，只有 V 数据，当所有的 V 数据读取完后，才会只有紧跟的 U 数据 假设一个分辨率为 6X4 的 YUV420 格式图像，采样方式和存储方式如下图 假设一个分辨率为 8X4 的 YUV420 格式图像 YUV422p：Y(行X列) + U(行X列 / 2) + V(行X列 / 2) I420（打包格式：YV12）：Y(行X列) + V(行X列 / 4) + U(行X列 / 4) YUV420p：Y(行X列) + U(行X列 / 4) + V(行X列 / 4) YUV420sp（打包格式：NV12）：Y(行X列) + UV(行X列 / 2) 3.3 RGB 与 YUV 的互相转换 模拟信号格式的 YUV 转换基本公式，其中 $K_R+K_G+K_B = 1 $ \\begin{align} Y &amp;= K_R \\cdot R + K_G \\cdot G + K_B \\cdot B \\\\ C_B &amp;= {1 \\over 2} \\cdot {B - Y \\over 1 - K_B}\\\\ C_R &amp;= {1 \\over 2} \\cdot {R - Y \\over 1 - K_R} \\end{align} RGB∈[0,1]、Y∈[0,1]、U∈[−0.436,0.436]、V∈[−0.615,0.615]RGB \\in [0,1]、Y \\in [0,1]、U \\in [-0.436,0.436]、V \\in [-0.615,0.615]RGB∈[0,1]、Y∈[0,1]、U∈[−0.436,0.436]、V∈[−0.615,0.615]，more 以下转换为 RGB 到 SDTV / BT.601 的转换 vec3 RGBToYUVBT601(vec3 rgb) { // mat3(列向量1，列向量2，列向量3) return rgb * mat3( 0.299, 0.587, 0.114, -0.14713, -0.2886, 0.436, 0.615, -0.51499, -0.10001 ); } vec3 YUVBT601ToRGB(vec3 yuv) { return yuv * mat3( 1.0, 1.0, 1.0, 0.0, -0.39465, 2.03211, 1.13983, -0.5806, 0.0 ); } 以下转换为 RGB 到 HDTV / BT.709 的转换 vec3 RGBToYUVBT709(vec3 rgb) { // mat3(列向量1，列向量2，列向量3) return rgb * mat3( 0.2126, 0.7152, 0.0722, -0.09991, -0.33609, 0.436, 0.615, -0.55861, -0.05639 ); } vec3 YUVBT709ToRGB(vec3 yuv) { return yuv * mat3( 1.0, 0.0, 1.28033, 1.0, -0.21482, -0.38059, 1.0, 2.12798, 0.0 ); } 3.4 更多色彩模型的转换 YY Color Convertor Reference Lumiance 计算性能优化 Luminance 和 Luma 的区别 Fast branchless RGB to HSV conversion in GLSL YUV 维基百科 YUV 的采样方式 YUV 的打包方式 YUV 420 数据格式详解 IJKPlayer ","link":"https://kimokcheon.github.io/post/colors/"},{"title":"Filtering","content":"一、图像处理基本 1. 光谱即是电磁波谱 波长：从红光到紫光，波长不断变短（对于可见光，波长不同，颜色不同） 灰度级：从黑到白的单色光度量范围 单色光：无色光，没有颜色的光 强度：即灰度，单色光的唯一属性 发光强度：光源流出的能量总和 光通量：观察者从光源感受到的能量，单位：流明 lumen （LM） 亮度：物体表面的反光率，实际上不能度量，色彩的强度（人眼对亮度的敏感 &gt; 色彩） 2. 数字图像 2.1 图像属性 图像的本质：一个二维数组（矩阵） 原点：左上角 动态范围：图中最大灰度 / 图中最小灰度 噪声：图中多余的干扰信息，低于图中最小灰度，便会出现 饱和度：即图中最大灰度，高于这个值，图中的灰度将会被剪裁掉（彩图中是灰度和色调的比例，0% 灰色 ～ 100% 完全饱和） 对比度：图中最大灰度 - 图中最小灰度 图像分辨率（空间分辨率）：每单位距离的点个数 相关单位：dpi(点每英寸）、lpi（线每英寸）和ppi（像素每英寸) PPI=像素长2+像素宽2屏幕长2+屏幕宽2PPI = {\\sqrt{像素长^2 + 像素宽^2} \\over \\sqrt{屏幕长^2 + 屏幕宽^2}} PPI=屏幕长2+屏幕宽2​像素长2+像素宽2​​ 2.2 像素 邻接性： 有时候也用非矩形的邻域（比如：圆形），但矩形邻域是目前为止最好的邻域，因为它在计算上更为容易 像素通路：从起点像素到终点像素相邻像素的连线 必须保证唯一，创建通路前要确定使用哪种邻接 像素间距离计算：例，求 A(xa,ya)、B(xb,yb)A(x_a, y_a)、B(x_b, y_b)A(xa​,ya​)、B(xb​,yb​) 间的距离 欧式距离：最短距离 De(A,B)=(xb−xa)2+(yb−ya)2D_e(A, B) = \\sqrt{(x_b - x_a)^2+ (y_b - y_a)^2}De​(A,B)=(xb​−xa​)2+(yb​−ya​)2​ D4 距离：每次只能横、竖、走 4 邻接像素 D4(A,B)=∣xb−xa∣,∣yb−ya∣D_4(A,B) = |x_b - x_a|, |y_b - y_a|D4​(A,B)=∣xb​−xa​∣,∣yb​−ya​∣ D8 距离：每次只能横、竖、斜走 8 邻接像素 D8(A,B)=max(∣xb−xa∣,∣yb−ya∣)D_8(A,B) = max(|x_b - x_a|, |y_b - y_a|)D8​(A,B)=max(∣xb​−xa​∣,∣yb​−ya​∣) 3. 图像处理 3.1 图像的收缩和放大 线性插值（nearest）：例，根据 Q(x0,y0)，R(x1,y1)⇒P插值后(x,y)Q(x_0,y_0)，R(x_1,y_1) \\Rightarrow P_{插值后}(x, y)Q(x0​,y0​)，R(x1​,y1​)⇒P插值后​(x,y) y−y0x−x0=y1−y0x1−x0{y - y_0 \\over x - x_0} = {y_1 - y_0 \\over x_1 - x_0} x−x0​y−y0​​=x1​−x0​y1​−y0​​ 双线性插值（bilinear）：结果与插值的 X、Y 方向先后顺序无关 缺点：对角线过渡不平滑，细节退化 计算方法： X 方向线性插值：根据 4 个 Q 点分别求出 R1，R2 Y 方向线性插值：根据 R1，R2 求出 P 双三次内插值（bicubic）：双线性插值的三维拓展 3.2 图像的线性操作 阵列操作：表示图像的矩阵中每个对应元素之间的操作 例，阵列相乘 [a11a21a12a22][b11b21b12b22]=[a11b11a21b21a12b12a22b22]\\begin{bmatrix} \\color{red}{a_{11}} &amp; \\color{red}{a_{21}} \\\\ a_{12} &amp; a_{22} \\\\ \\end{bmatrix} \\begin{bmatrix} \\color{green}{b_{11}} &amp; b_{21} \\\\ \\color{green}{b_{12}} &amp; b_{22} \\\\ \\end{bmatrix} = \\begin{bmatrix} \\color{red}{a_{11}}\\color{green}{b_{11}} &amp; \\color{red}{a_{21}}b_{21} \\\\ a_{12}\\color{green}{b_{12}} &amp; a_{22}b_{22} \\\\ \\end{bmatrix} [a11​a12​​a21​a22​​][b11​b12​​b21​b22​​]=[a11​b11​a12​b12​​a21​b21​a22​b22​​] 符合线性代数的条件下使用线性代数公式 例，矩阵相乘：行 X 列 [a11a21a12a22][b11b21b12b22]=[a11b11+a21b12a11b21+a21b22a12b11+a22b12a12b21+a22b22]\\begin{bmatrix} \\color{red}{a_{11}} &amp; \\color{red}{a_{21}} \\\\ a_{12} &amp; a_{22} \\\\ \\end{bmatrix} \\begin{bmatrix} \\color{green}{b_{11}} &amp; b_{21} \\\\ \\color{green}{b_{12}} &amp; b_{22} \\\\ \\end{bmatrix} = \\begin{bmatrix} \\color{red}{a_{11}}\\color{green}{b_{11}}+\\color{red}{a_{21}}\\color{green}{b_{12}} &amp; \\color{red}{a_{11}}b_{21}+\\color{red}{a_{21}}b_{22} \\\\ a_{12}\\color{green}{b_{11}}+a_{22}\\color{green}{b_{12}} &amp; a_{12}b_{21}+a_{22}b_{22} \\\\ \\end{bmatrix} [a11​a12​​a21​a22​​][b11​b12​​b21​b22​​]=[a11​b11​+a21​b12​a12​b11​+a22​b12​​a11​b21​+a21​b22​a12​b21​+a22​b22​​] 其他线性代数问题 3.3 图像的概率方法 基本概率：概率 = 符合条件事件数 / 事件总数 期望值：概率加权后的和 当事件总数不可知（或者无法求得），但是知道概率分布（符合条件的每个概率值），从而求得的整体的平均值 方差：随机变量和期望的偏离程度 方差公式：σ2=∑1n(X−μ)2n,σ标准差、X随机变量、μ期望、n随机变量总量\\sigma^2 = {\\sum_1^n(X - \\mu)^2 \\over n}, \\sigma 标准差、X 随机变量、\\mu期望、n随机变量总量σ2=n∑1n​(X−μ)2​,σ标准差、X随机变量、μ期望、n随机变量总量 概率密度函数（PDF）：连续随机变量存在随机变量 xxx 与其出现的概率 f(x)f(x)f(x)，求规定 xxx 范围内的可能性，就是求概率密度函数 f(x)f(x)f(x) 在这个范围的积分 累积分布函数（CDF）：概率密度函数的积分，能完整描述一个实随机变量 XXX 的概率分布 3.4 图像的灰度变换函数 图像反转：$ s = (L-1) -r $ 突出图像暗区域中白色或灰色部分 对数变换：s=c⋅log(1+r)，c常数s = c \\cdot log(1 + r)，c 常数s=c⋅log(1+r)，c常数 主要用来压缩像素值变化较大的动态范围 伽马变换：s=c⋅rγ，c常数s = c \\cdot r^\\gamma，c 常数s=c⋅rγ，c常数 又称幂律变换，当 c = 1 时，显著提高暗部亮度，可以提高亮部的亮度，如图下所示 3.5 图像的直方图处理 作用：通过在单张灰度图中统计 0 - 255 每个灰度级出现的总次数（概率），作为图像增强或图像阈值判断标准 限制：直方图只能测量一种强度值（R、G、B、A、Gray）的分布概率范围 特点：暗的图像直方图主要分布在灰度级低的位置，高对比度的图像直方图分布均匀，低对比度的直方图主要分布在灰度级的中间位置 直方图的生成 int pixelCount = width * height; for (int i = 0; i &lt; pixelCount; ++i ) { histogram[imageData[i]]++; // 计算单张图中每个灰度级出现的总次数 } 累加直方图：在单张灰度图中统计 0 - 255 每个灰度等级，小于等于该灰度的等级出现总次数之和 生成累加直方图 // build a cumulative histogram as LUT (Look Up Table) int sum = 0; for (int i=0; i &lt; HISTOGRAM_SIZE; ++i ) { sum += histogram[i]; sumHistogram[i] = sum; } 直方图均衡：利用图像直方图 对 对比度进行调整的方法 作用：用于作为增强局部对比度而不影响整体对比度的自适应工具 方法：原始直方图 =&gt; 累加直方图 =&gt;将最大强度通过出现概率平滑过度到每个像素 =&gt; 均衡后的直方图 // 一、直接对图像进行直方图均衡 // transform image using sum histogram as a LUT (Look Up Table) for (int i = 0; i &lt; pixelCount; ++i ) { // 通过这张图的最大强度和当前像素的累加出现概率来求出修改后的像素值 outImage[i] = sumHistogram[image[i]] * MAX_INTENSITY / pixelCount; } // 二、由于 pixelCount 远大于 HISTOGRAM_SIZE 这种固定值 // 通过提前制作的查找表来做直方图均衡（减少计算量，提高效率） // build a LUT containing scale factor for (int i=0; i &lt; HISTOGRAM_SIZE; ++i ) { sum += histogram[i]; lut[i] = sum * MAX_INTENSITY / pixelCount; } // transform image using sum histogram as a LUT for (int i = 0; i &lt; pixelCount; ++i ) { outImage[i] = lut[image[i]]; } 效果对比：均衡后的累加直方图几乎是线性增长的 直方图匹配：处理图像使其得到指定的概率密度 作用：通过得到指定概率密度的 灰度变换函数使图像局部增强 方法：不需要求得 灰度变换函数，只需要存储 灰度变换函数对应的 输入输出表格用查表法来得到相应的数据 二、空间域滤波 空间域技术：直接在图像像素上操作，针对图像本身，可用于非线性滤波，这在频率域中无法做到 滤波：接受/拒绝 一定的频率分量 低通滤波器：通过低频的滤波器处理结果模糊（平滑）的图像 空间滤波器（也称为，空间掩膜、核、模版、窗口） 1. 空间滤波基础 空间滤波方法：通过中心像素和其邻域执行特定的方法生成新像素 空间滤波器（模版）：通过特定的方法得到的对应像素的权重集合 线性空间滤波器：执行特定的方法是线性操作的空间滤波器（对于边缘像素的计算结果，根据纹理的环绕方式的不同而不同） 空间相关/卷积：滤波器移过图像，计算每个位置乘积之和得出对应像素值的处理方法 离散单位冲激：包含单个 1 其余都是 0 的函数/矩阵 处理方法，空间相关： 输入图像[0000000000001000000000000]⇒滤波器w[123456789]逐像素处理⇒全部相关结果[000000000000000000000000000000987000000654000000321000000000000000000000000000000]剪裁⇒输出图像[0000009870065400321000000]输入图像 \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; \\color{red}1 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} \\Rightarrow 滤波器 w \\begin{bmatrix} 1 &amp; 2 &amp; 3\\\\ 4 &amp; 5 &amp; 6\\\\ 7 &amp; 8 &amp; 9 \\end{bmatrix} {逐像素处理 \\over \\Rightarrow} 全部相关结果 \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; \\color{red}9 &amp; \\color{red}8 &amp; \\color{red}7 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp;0 &amp; \\color{red}6 &amp; \\color{red}5 &amp; \\color{red}4 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp;0 &amp; \\color{red}3 &amp; \\color{red}2 &amp; \\color{red}1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} { 剪裁 \\over \\Rightarrow} 输出图像 \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; \\color{red}9 &amp; \\color{red}8 &amp; \\color{red}7 &amp; 0\\\\ 0 &amp; \\color{red}6 &amp; \\color{red}5 &amp; \\color{red}4 &amp; 0\\\\ 0 &amp; \\color{red}3 &amp; \\color{red}2 &amp; \\color{red}1 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} 输入图像⎣⎢⎢⎢⎢⎡​00000​00000​00100​00000​00000​⎦⎥⎥⎥⎥⎤​⇒滤波器w⎣⎡​147​258​369​⎦⎤​⇒逐像素处理​全部相关结果⎣⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎡​000000000​000000000​000000000​000963000​000852000​000741000​000000000​000000000​000000000​⎦⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎤​⇒剪裁​输出图像⎣⎢⎢⎢⎢⎡​00000​09630​08520​07410​00000​⎦⎥⎥⎥⎥⎤​ 处理方法，空间卷积： 输入图像[0000000000001000000000000]180度翻转w⇒滤波器wT[987654321]逐像素处理⇒全部卷积结果[000000000000000000000000000000123000000456000000789000000000000000000000000000000]剪裁⇒输出图像[0000001230045600789000000]输入图像 \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; \\color{red}1 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} {180 度翻转 w \\over \\Rightarrow} 滤波器 w^T \\begin{bmatrix} 9 &amp; 8 &amp; 7\\\\ 6 &amp; 5 &amp; 4\\\\ 3 &amp; 2 &amp; 1 \\end{bmatrix} {逐像素处理 \\over \\Rightarrow} 全部卷积结果 \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; \\color{red}1 &amp; \\color{red}2 &amp; \\color{red}3 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; \\color{red}4 &amp; \\color{red}5 &amp; \\color{red}6 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; \\color{red}7 &amp; \\color{red}8 &amp; \\color{red}9 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} { 剪裁 \\over \\Rightarrow} 输出图像 \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; \\color{red}1 &amp; \\color{red}2 &amp; \\color{red}3 &amp; 0\\\\ 0 &amp; \\color{red}4 &amp; \\color{red}5 &amp; \\color{red}6 &amp; 0\\\\ 0 &amp; \\color{red}7 &amp; \\color{red}8 &amp; \\color{red}9 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} 输入图像⎣⎢⎢⎢⎢⎡​00000​00000​00100​00000​00000​⎦⎥⎥⎥⎥⎤​⇒180度翻转w​滤波器wT⎣⎡​963​852​741​⎦⎤​⇒逐像素处理​全部卷积结果⎣⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎡​000000000​000000000​000000000​000147000​000258000​000369000​000000000​000000000​000000000​⎦⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎤​⇒剪裁​输出图像⎣⎢⎢⎢⎢⎡​00000​01470​02580​03690​00000​⎦⎥⎥⎥⎥⎤​ 2. 平滑空间滤波器 作用：用于模糊处理，降低噪声 使用 3 X 3、5 X 5 或更大的空间滤波器，效果更明显 2.1 平滑线性滤波器（均值滤波器） 方法：中心像素的值为滤波器模版邻域内像素简单的加权平均值 特点：滤波器个系数加权之和为 1 缺点：出现边缘模糊 例： 19×[111111111]116×[121242121]均值滤波器A均值滤波器B\\begin{array}{rr} { 1 \\over 9 } \\times \\begin{bmatrix} 1 &amp; 1 &amp; 1\\\\ 1 &amp; 1 &amp; 1\\\\ 1 &amp; 1 &amp; 1 \\end{bmatrix} &amp; { 1 \\over 16 } \\times \\begin{bmatrix} 1 &amp; 2 &amp; 1\\\\ 2 &amp; 4 &amp; 2\\\\ 1 &amp; 2 &amp; 1 \\end{bmatrix} \\\\ 均值滤波器 A &amp; 均值滤波器 B \\end{array} 91​×⎣⎡​111​111​111​⎦⎤​均值滤波器A​161​×⎣⎡​121​242​121​⎦⎤​均值滤波器B​ 2.2 统计排序（非线性）滤波器 方法：中心像素的值为滤波器模版邻域内像素值安一定规则排序后，从统计排序结果中选取的 缺点：非线性滤波器可能改变图像的性质，这在医学是不能接受的 例：中值滤波，中心像素的值为滤波器模版邻域内像素值从小到大排列后，位置排在中间的像素的值 3. 锐化空间滤波器 作用：突出灰度过渡的部分 锐化空间滤波器的关键数学工具：微分 微分：函数 f(x)f(x)f(x) 在 dxdxdx 的微分是，函数 f(x)f(x)f(x) 在 dxdxdx 处的极限，具体意义如下 直线 T 为 曲线 f(x)f(x)f(x) 上 P 点的切线，是 dfdx{df \\over dx}dxdf​ 的图像 曲线 L 为 曲线 f(x)f(x)f(x) 的图像 当增量 dxdxdx 趋于无穷小时， f(x)−dff(x) - dff(x)−df 的差别也趋于无穷小，所以在 P 点附近可以用 切线 T 来的代替曲线 L 的值 一维的微分公式 一阶微分：dfdx=f(x+1)−f(x)(x+1)−x=f(x+1)−f(x){df \\over dx} = {f(x+1) - f(x) \\over (x+1) -x} = f(x+1) - f(x)dxdf​=(x+1)−xf(x+1)−f(x)​=f(x+1)−f(x) 二阶微分：d2fdx2=d(dfdx)dx=f(x+1)+f(x−1)−2f(x){d^2f \\over dx^2} = {d({df \\over dx})\\over dx} = f(x+1) +f(x-1) - 2f(x)dx2d2f​=dxd(dxdf​)​=f(x+1)+f(x−1)−2f(x) 3.1 梯度（一阶微分） 特点：边缘增强 方法： 具有旋转不变的特性（各向同性），根据对一阶微分 dfdx{df \\over dx}dxdf​ 的计算不同而不同，基本思路是： g中心(x,y)=(dfdx)2+(dfdy)2g_{中心}(x,y) = \\sqrt{({df \\over dx})^2 + ({df \\over dy})^2}g中心​(x,y)=(dxdf​)2+(dydf​)2​ 具有旋转改变的特性（各向异性），为了方便计算： g中心(x,y)≈∣dfdx∣+∣dfdy∣g_{中心}(x,y) \\approx |{df \\over dx}| + |{df \\over dy}|g中心​(x,y)≈∣dxdf​∣+∣dydf​∣ 为不影响其他像素的值，滤波器个系数加权和为 0 3.2 拉普拉斯算子（二阶微分） 特点：增强图像细节，增强灰度的突变，减弱灰度的缓慢变化区 缺点：比梯度操作产生更多的噪点 拉普拉斯算子是二维的二阶微分，公式为：Δ2f(x,y)=f(x+1,y)+f(x−1,y)+f(x,y+1)+f(x,y−1)−4f(x,y)\\Delta^2f(x, y) = f(x+1,y) +f(x-1,y)+f(x,y+1) +f(x,y-1)-4f(x,y)Δ2f(x,y)=f(x+1,y)+f(x−1,y)+f(x,y+1)+f(x,y−1)−4f(x,y) 使用方法： g中心(x,y)=f中心(x,y)+滤波器中心系数的符号⋅Δ2f(x,y)g_{中心}(x,y) = f_{中心}(x,y)+滤波器中心系数的符号\\cdot \\Delta^2f(x,y)g中心​(x,y)=f中心​(x,y)+滤波器中心系数的符号⋅Δ2f(x,y) 为不影响其他像素的值，滤波器个系数加权和为 0 3.3 非锐化掩蔽和高提升滤波（不用微分） 方法：原图像 A 模糊⇒{模糊 \\over \\Rightarrow}⇒模糊​ 模糊图像 G A−G⇒{A - G \\over \\Rightarrow}⇒A−G​ 差值图像 D A+D⇒{A + D \\over \\Rightarrow}⇒A+D​ 锐化图像 3.4 多种滤波的混合使用举例 锐化图像：原图像 →\\rightarrow→ 梯度滤波 →\\rightarrow→ 平滑线性滤波 →\\rightarrow→ 拉普拉斯滤波 →\\rightarrow→ 锐化后的图像 4. 模糊技术 作用：为处理不严密信息提供了一种形式 模糊集合：集合中的某元素 A 在集合中的隶属度（符合集合定义的程度，一般介于 0 ～ 1）组成的有序对 集合操作与数学计算： 集合 A 的补集：1−A1 - A1−A 集合 AB 的并集：max(A,B)max(A, B)max(A,B) 集合 AB 的交集： min(A,B)min(A, B)min(A,B) 方法： 找到处理图像的各个影响因素和其对应的隶属度的关系 A、B、C... 将各个关键关系 A、B、C… 进行集合操作得到模糊集合 将模糊集合通过一种计算方法（以下几个例子都用了计算集合中心的方法）得出一个计算方程 4.1 模糊技术处理灰度 根据 黑、灰、白 和 其隶属度的关系 的模糊集合，使用重心的计算方法得到灰度处理方法 v输出=f黑(x隶属度)×v黑+g灰(x隶属度)×v灰+h白(x隶属度)×v白f黑(x隶属度)+g灰(x隶属度)+h白(x隶属度)v_{输出} = { f_黑(x_{隶属度}) \\times v_黑 + g_灰(x_{隶属度}) \\times v_灰 + h_白(x_{隶属度}) \\times v_白 \\over f_黑(x_{隶属度}) + g_灰(x_{隶属度}) + h_白(x_{隶属度}) } v输出​=f黑​(x隶属度​)+g灰​(x隶属度​)+h白​(x隶属度​)f黑​(x隶属度​)×v黑​+g灰​(x隶属度​)×v灰​+h白​(x隶属度​)×v白​​ 4.2 模糊技术进行空间滤波 假设 黑色 == 平滑，白色 == 边缘，则边缘检测如下 图 4.2.A 为：灰度差为 0 和其集合隶属关系 图 4.2.B 为：黑色 和 白色与其集合隶属关系 根据图 4.2.A、B 构成的模糊集合通过边缘提取的计算方法（只要与中心像素 4邻接的两个相邻灰度差均为 0 时，中间点为白色） 三、频率域滤波 傅立叶概念：任何周期函数=(系数1×正弦)和/或(系数2×余弦)任何周期函数 = (系数 1 \\times 正弦) 和/或 (系数2 \\times 余弦)任何周期函数=(系数1×正弦)和/或(系数2×余弦) 常用数学公式 \\begin{align} 复数 &amp;= 实数_{实部} + 实数_{虚部}\\cdot i_{虚数单位}, (i_{虚数单位} = \\sqrt{-1} )\\\\ 复数的共轭 &amp;= 实数_{实部} - 实数_{虚部}\\cdot i\\\\ f(x)_{复数} &amp;= R(x)_{实部} + J(x)_{虚部} \\cdot i\\\\ f(x)_{复数的共轭} &amp;= R(x)_{实部} - J(x)_{虚部} \\cdot i\\\\ 复数_{极坐标下} &amp;= \\sqrt{实部^2 + 虚部^2}(cos\\theta + i \\cdot sin\\theta)\\\\ 复数_{极坐标下} &amp;= \\sqrt{实部^2 + 虚部^2}e^{i\\theta},(欧拉公式: e^{\\theta i} = cos\\theta + i\\cdot sin\\theta，e = 2.71828 …)\\\\ f(x)_{傅立叶级数} &amp;= \\sum_{n = -\\infty}^\\infty c_n e^{i{2\\pi n\\over T_{周期}}x},(i = \\sqrt{-1}, c_n = {1 \\over T}\\int_{-{T \\over 2}}^{T \\over 2} f(x)e^{-i{2\\pi n\\over T}x}dx, n = 0, \\pm1, \\pm2...) \\end{align} 1. 频率域滤波基础 1.1 基本概念 1.2 傅立叶变换 1.2.1 取样函数的傅立叶变换 1.2.2 单变量的离散傅立叶变换(DTF) 1.2.3 二维离散傅里叶变换的性质 2. 频率域滤波平滑图像 3. 频率域滤波锐化图像 4. 选择性滤波 5. 滤波器实现 Reference Histogram ","link":"https://kimokcheon.github.io/post/filtering/"},{"title":"Singals&Systems","content":"一、信号与系统 信号可以来自于很多外部设备：录音机、温度计、相机 信号处理的方向：并不关心数据以怎样自然规律产生，而是重点放在如何改变输入的信号数据 模拟信号：连续不断的，针对具体外界做出的具体测量值，没有取值范围 数字信号：离散采样的，具有时间和幅度两个分量，将模拟信号限定在一个固定的测量范围后，表示局部模拟信号波动的值，在传输时具有较强的抗干扰能力 1. 信号的系统 信号的系统指一系列处理信号的方法 1.1 系统的分类 以下系统类型可以组合为多个系统类型 线性转换 Linear / 非线性转换 Non-linear 线性：输入信号与输出信号满足可加性和同质性（缩放一致） α⋅x(t)→[Linear System]→α⋅y(t)x1(t)+x2(t)→[Linear System]→y1(t)+y2(t)α⋅x1(t)+β⋅x2(t)→[Linear System]→α⋅y1(t)+β⋅y2(t)\\alpha \\cdot x(t) \\rarr [Linear \\space System] \\rarr \\alpha \\cdot y(t) \\\\ x_1(t) + x_2(t) \\rarr [Linear \\space System] \\rarr y_1(t) + y_2(t) \\\\ \\alpha \\cdot x_1(t) + \\beta \\cdot x_2(t) \\rarr [Linear \\space System] \\rarr \\alpha \\cdot y_1(t) + \\beta \\cdot y_2(t) \\\\ α⋅x(t)→[Linear System]→α⋅y(t)x1​(t)+x2​(t)→[Linear System]→y1​(t)+y2​(t)α⋅x1​(t)+β⋅x2​(t)→[Linear System]→α⋅y1​(t)+β⋅y2​(t) 时不变 time-inveriant / 时变 time-varying 时不变：同样的时间偏移，输入和输出的值是对应的 x(t−t0)→[Time−Invariant System]→y(t−t0)x(t-t_0) \\rarr [Time-Invariant \\space System] \\rarr y(t-t_0)\\\\ x(t−t0​)→[Time−Invariant System]→y(t−t0​) 因果系统 Causal 根据现在和过去的输入输出值推出输出值 1.2 对信号分析和表达的作用域 时域：从时间的角度分析信号 频率域：从信号频率角度分析信号 空间域：从信号发生空间位置角度分析信号 2. 信号的分类 信号在离散和连续时有相同也有不同的特性，比如：一个正弦信号，如果周期不是整数，那虽然在连续信号里它具有周期性，但是在离散信号里，没有周期性 脉冲信号：一种离散信号（即，离散时间信号，指信号在时间这个轴上是离散的），波形之间在 Y 轴不连续，具有一定周期性 2.1 单位脉冲信号 一维信号中的单位脉冲信号 Originalδ(n)={1,n=00,otherwiseOffsetδ(n−n′)={1,n=n′0,otherwise2D Discreteδ(n)=f1(n1)⋅f2(n2)\\begin{array}{rrl} Original &amp; \\delta(n) =&amp; \\begin{cases} 1,&amp; n=0\\\\ 0,&amp; otherwise \\end{cases}\\\\ Offset &amp; \\delta(n-n&#x27;) =&amp; \\begin{cases} 1,&amp; n=n&#x27;\\\\ 0,&amp; otherwise \\end{cases}\\\\\\\\ 2D \\space Discrete &amp; \\delta(n) =&amp; f_1(n_1)\\cdot f_2(n_2) \\end{array} OriginalOffset2D Discrete​δ(n)=δ(n−n′)=δ(n)=​{1,0,​n=0otherwise​{1,0,​n=n′otherwise​f1​(n1​)⋅f2​(n2​)​ 二维信号中的单位脉冲信号 Originalδ(m,n)={1,m=n=00,otherwiseOffsetδ(m−m′,n−n′)={1,m=m′,n=n′0,otherwise\\begin{array}{rrl} Original &amp; \\delta(m,n) =&amp; \\begin{cases} 1,&amp; m=n=0\\\\ 0,&amp; otherwise \\end{cases}\\\\ Offset &amp; \\delta(m-m&#x27;,n-n&#x27;) =&amp; \\begin{cases} 1,&amp; m=m&#x27;,n=n&#x27;\\\\ 0,&amp; otherwise \\end{cases} \\end{array} OriginalOffset​δ(m,n)=δ(m−m′,n−n′)=​{1,0,​m=n=0otherwise​{1,0,​m=m′,n=n′otherwise​​ 2.2 单位跃阶信号 Originalu(n)={1,n≥00,otherwiseOffsetu(n−n′)={1,n≥n′0,otherwise2D Discreteu(n1,n2)=u1(n1)⋅u2(n2)\\begin{array} {rrl} Original &amp; u(n) =&amp; \\begin{cases} 1,&amp; n\\geq0\\\\ 0,&amp; otherwise \\end{cases}\\\\ Offset &amp; u(n-n&#x27;) =&amp; \\begin{cases} 1,&amp; n \\geq n&#x27;\\\\ 0,&amp; otherwise \\end{cases}\\\\\\\\ 2D \\space Discrete &amp; u(n_1, n_2) =&amp; u_1(n_1)\\cdot u_2(n_2) \\end{array} OriginalOffset2D Discrete​u(n)=u(n−n′)=u(n1​,n2​)=​{1,0,​n≥0otherwise​{1,0,​n≥n′otherwise​u1​(n1​)⋅u2​(n2​)​ 2.3 正弦信号 A 振幅，ω0\\omega_0ω0​ 频率，ϕ\\phiϕ 相位（指偏移量），T0=2πω0T_0 = {2 \\pi \\over \\omega_0}T0​=ω0​2π​ 周期 u(t)=A cos(ω0t+ϕ)u(t) = A \\space cos(\\omega_0 t + \\phi) u(t)=A cos(ω0​t+ϕ) 2.4 指数信号 指数信号 u(t)=Ceat，(C 和 a 是实数)u(t) = C e^{at}，(C \\space 和 \\space a \\space 是实数) u(t)=Ceat，(C 和 a 是实数) 复指数信号 \\begin{align} u(t) &amp;= C e^{at}，(C \\space 和 \\space a \\space 是复数)\\\\ u(t) &amp;= |C|e^{rt}e^{(j\\omega_0t+ \\theta)} \\end{align} 二、卷积 1. 信号的拆解 一般来说，一个脉冲信号可以被分解为多个单位脉冲信号加权之和 1.1 傅立叶级数 傅立叶级数：任何周期函数，都可以用一系列的 sin 函数 和 cos 函数的和来表示 1.2 离散信号序列的拆解 以下图的一维 xxx 信号序列为例： 已知单位脉冲信号序列 δ[n]\\delta[n]δ[n]： δ(n)={1,n=00,otherwise\\delta(n) = \\begin{cases} 1,&amp; n=0\\\\ 0,&amp; otherwise \\end{cases}\\\\ δ(n)={1,0,​n=0otherwise​ 则脉冲信号序列 x[n]x[n]x[n]： x[0]=2=2⋅δ[n−0]=x[0]⋅δ[n−0]x[1]=3=3⋅δ[n−1]=x[1]⋅δ[n−1]x[2]=1=1⋅δ[n−2]=x[2]⋅δ[n−2]当 n∈[1,2,3] 时x[n]=x[0]+x[1]+x[2]=x[0]⋅δ[n−0]+x[1]⋅δ[n−1]+x[2]⋅δ[n−2]当 n∈(−∞,∞) 时x[n]=∑k=−∞∞x[k]⋅δ[n−k]\\begin{array}{lll} x[0] &amp;= 2 &amp;= 2 \\cdot \\delta[n - 0] &amp;= x[0] \\cdot \\delta[n - 0] \\\\ x[1] &amp;= 3 &amp;= 3 \\cdot \\delta[n - 1] &amp;= x[1] \\cdot \\delta[n - 1] \\\\ x[2] &amp;= 1 &amp;= 1 \\cdot \\delta[n - 2] &amp;= x[2] \\cdot \\delta[n - 2] \\\\ \\\\ \\end{array} \\\\ \\begin{array}{llll} 当 \\space n \\in [1,2,3] \\space 时 &amp; x[n] &amp;= x[0] + x[1] + x[2] \\\\ &amp; &amp;= x[0] \\cdot \\delta[n - 0] + x[1] \\cdot \\delta[n - 1] + x[2] \\cdot \\delta[n - 2]\\\\ \\\\ 当 \\space n \\in (-\\infin, \\infin) \\space 时 &amp; x[n] &amp;= \\sum_{k = - \\infin}^\\infin x[k] \\cdot \\delta[n - k] \\end{array} x[0]x[1]x[2]​=2=3=1​=2⋅δ[n−0]=3⋅δ[n−1]=1⋅δ[n−2]​=x[0]⋅δ[n−0]=x[1]⋅δ[n−1]=x[2]⋅δ[n−2]​当 n∈[1,2,3] 时当 n∈(−∞,∞) 时​x[n]x[n]​=x[0]+x[1]+x[2]=x[0]⋅δ[n−0]+x[1]⋅δ[n−1]+x[2]⋅δ[n−2]=∑k=−∞∞​x[k]⋅δ[n−k]​ 同理，二维离散信号序列也可以拆解为： 当 n∈[1,2,3] 时x[m][n]=x[0][0]⋅δ[m][n]+x[1][2]⋅δ[m−1][n−2]+...+x[m][n]⋅δ[0][0]当 n∈(−∞,∞) 时x[m][n]=∑i=−∞∞∑j=−∞∞x[i][j]⋅δ[m−i][n−j]\\begin{array}{lll} 当 \\space n \\in [1,2,3] \\space 时 &amp; x[m][n] &amp;= x[0][0] \\cdot \\delta[m][n] + x[1][2] \\cdot \\delta[m-1][n-2] + ... + x[m][n]\\cdot \\delta[0][0]\\\\ 当 \\space n \\in (-\\infin, \\infin) \\space 时 &amp; x[m][n] &amp;= \\sum_{i = - \\infin}^\\infin \\sum_{j = - \\infin}^\\infin x[i][j] \\cdot \\delta[m - i][n - j] \\end{array} 当 n∈[1,2,3] 时当 n∈(−∞,∞) 时​x[m][n]x[m][n]​=x[0][0]⋅δ[m][n]+x[1][2]⋅δ[m−1][n−2]+...+x[m][n]⋅δ[0][0]=∑i=−∞∞​∑j=−∞∞​x[i][j]⋅δ[m−i][n−j]​ 2. 单位脉冲响应 单位脉冲响应：通过单位脉冲信号输入线性时不变系统后，得到的输出信号，一般用 h[n]h[n]h[n] 表示 一般作为卷积的参数之一，使得全部的信号能通过该方法处理 2.1 单位脉冲响应的特性 以下特性，适用于一维和二维等信号 系统以时间为变量时，输入单位脉冲会得到对应时间偏移的单位脉冲响应 系统为线性变换系统时，单位脉冲响应结果也满足对应输入的线性变换 多个单位脉冲输入时，在经过系统处理后也会得到相应数目个单位响应脉冲 结合单位脉冲响应的性质和离散信号的拆解方式后的处理过程，就是卷积 2.2 二维的单位脉冲响应（卷积核） 一般来说二维的脉冲响应（卷积核）多以中心为起点排列，如下图**（具体原理参考数值积分）** 注意：输入信号的排列方式与二维脉冲响应信号的排列无关 为了减少计算量，我们可以通过将一个二维脉冲响应（卷积核）拆解为两个一维脉冲响应分别依次（顺序可以颠倒）做卷积 这样假如原本为 3X3 的卷积核，9 个输入要做 9 X 9 = 81 次乘法，拆分后只需要做 9 + 9 =18 次乘法 作用：通过拆解来降低二维脉冲响应的计算量 例，其中 * 表示卷积： ∵y[m,n]=x[m,n]∗h[m,n]=∑j=−∞∞∑i=−∞∞x[i,j]⋅h[m−i,n−j]=h[m,n]∗x[m,n]=∑j=−∞∞∑i=−∞∞h[i,j]⋅x[m−i,n−j]=(h1[m]⋅h2[n])∗x[m,n],(线性代数中对矩阵的向量拆分)=∑j=−∞∞∑i=−∞∞(h1[i]⋅h2[j])⋅x[m−i,n−j]=∑j=−∞∞h2[j]⋅(∑i=−∞∞h1[i]⋅x[m−i,n−j])=h2[j]∗(h1[i]∗x[m−i,n−j])or=h1[i]∗(h2[j]∗x[m−i,n−j])∴[A⋅aA⋅bA⋅cB⋅aB⋅bB⋅cC⋅aC⋅bC⋅c]=[ABc]⋅[abc]x[m,n]∗[A⋅aA⋅bA⋅cB⋅aB⋅bB⋅cC⋅aC⋅bC⋅c]=x[m,n]∗([ABc]⋅[abc])=(x[m,n]∗[ABc])∗[abc]\\begin{array}{lrl} \\because &amp; y[m,n] =&amp; x[m,n] * h[m,n] = \\sum_{j = - \\infin}^\\infin \\sum_{i = - \\infin}^\\infin x[i,j] \\cdot h[m-i,n-j] \\\\ &amp;=&amp; h[m,n] * x[m,n] = \\sum_{j = - \\infin}^\\infin \\sum_{i = - \\infin}^\\infin h[i,j] \\cdot x[m-i,n-j] \\\\ &amp;=&amp; (h_1[m] \\cdot h_2[n]) * x[m,n],(线性代数中对矩阵的向量拆分) \\\\ &amp;=&amp; \\sum_{j = - \\infin}^\\infin \\sum_{i = - \\infin}^\\infin (h_1[i] \\cdot h_2[j]) \\cdot x[m-i,n-j] \\\\ &amp;=&amp; \\sum_{j = - \\infin}^\\infin h_2[j] \\cdot(\\sum_{i = - \\infin}^\\infin h_1[i] \\cdot x[m-i,n-j]) \\\\ &amp;=&amp; h_2[j] * (h_1[i] * x[m-i,n-j]) \\\\\\\\ or &amp;=&amp; h_1[i] * (h_2[j] * x[m-i,n-j]) \\\\ \\\\ \\therefore &amp; \\begin{bmatrix} A \\cdot a &amp; A \\cdot b &amp; A \\cdot c \\\\ B \\cdot a &amp; B \\cdot b &amp; B \\cdot c \\\\ C \\cdot a &amp; C \\cdot b &amp; C \\cdot c \\end{bmatrix} =&amp; \\begin{bmatrix}A \\\\ B \\\\ c\\end{bmatrix} \\cdot \\begin{bmatrix}a &amp; b &amp; c\\end{bmatrix} \\\\ &amp; x[m,n] * \\begin{bmatrix} A \\cdot a &amp; A \\cdot b &amp; A \\cdot c \\\\ B \\cdot a &amp; B \\cdot b &amp; B \\cdot c \\\\ C \\cdot a &amp; C \\cdot b &amp; C \\cdot c \\end{bmatrix} =&amp; x[m,n] * \\begin{pmatrix} \\begin{bmatrix}A \\\\ B \\\\ c\\end{bmatrix} \\cdot \\begin{bmatrix}a &amp; b &amp; c\\end{bmatrix} \\end{pmatrix}\\\\ &amp;=&amp; \\begin{pmatrix} x[m,n] * \\begin{bmatrix}A \\\\ B \\\\ c\\end{bmatrix} \\end{pmatrix} * \\begin{bmatrix}a &amp; b &amp; c\\end{bmatrix} \\end{array} ∵or∴​y[m,n]=======⎣⎡​A⋅aB⋅aC⋅a​A⋅bB⋅bC⋅b​A⋅cB⋅cC⋅c​⎦⎤​=x[m,n]∗⎣⎡​A⋅aB⋅aC⋅a​A⋅bB⋅bC⋅b​A⋅cB⋅cC⋅c​⎦⎤​==​x[m,n]∗h[m,n]=∑j=−∞∞​∑i=−∞∞​x[i,j]⋅h[m−i,n−j]h[m,n]∗x[m,n]=∑j=−∞∞​∑i=−∞∞​h[i,j]⋅x[m−i,n−j](h1​[m]⋅h2​[n])∗x[m,n],(线性代数中对矩阵的向量拆分)∑j=−∞∞​∑i=−∞∞​(h1​[i]⋅h2​[j])⋅x[m−i,n−j]∑j=−∞∞​h2​[j]⋅(∑i=−∞∞​h1​[i]⋅x[m−i,n−j])h2​[j]∗(h1​[i]∗x[m−i,n−j])h1​[i]∗(h2​[j]∗x[m−i,n−j])⎣⎡​ABc​⎦⎤​⋅[a​b​c​]x[m,n]∗⎝⎛​⎣⎡​ABc​⎦⎤​⋅[a​b​c​]​⎠⎞​⎝⎛​x[m,n]∗⎣⎡​ABc​⎦⎤​​⎠⎞​∗[a​b​c​]​ 3. 离散时阈下的卷积 卷积公式（一维信号），其中 y 为输出信号序列（卷积结果） x 为输入信号序列 h 当前输入信号对应的脉冲响应结果（信号系统处理后的到的值） n 当前输入信号的序列号 y[n]=∑k=−∞∞x[k]⋅h[n−k]y[n] = \\sum_{k = -\\infin}^\\infin x[k]\\cdot h[n - k] y[n]=k=−∞∑∞​x[k]⋅h[n−k] 4. 卷积 4.1 一维信号的卷积过程 假设： 信号序列 x[n]={3,4,5}x[n] = \\{ 3, 4, 5 \\}x[n]={3,4,5} 当 n 取 0 - 2 之外的值时信号均为 0 单位脉冲信号随着时间变化后的响应脉冲为 h[n]={2,1}h[n] = \\{ 2, 1 \\}h[n]={2,1} 当 n 取 0 - 1 之外的值时脉冲响应均为 0 求卷积： y[0]=x[0]⋅h[0]需要采样 x0y[1]=x[1]⋅h[0]+x[0]⋅h[1]需要采样 x0,x1y[2]=x[2]⋅h[0]+x[1]⋅h[1]需要采样 x1,x2y[3]=x[3]⋅h[0]+x[2]⋅h[1]需要采样 x2,x3\\begin{array}{lll} y[0] &amp;= x[0]·h[0] &amp; 需要采样 \\space x_0 \\\\ y[1] &amp;= x[1]·h[0] + x[0]·h[1] &amp; 需要采样 \\space x_0,x_1 \\\\ y[2] &amp;= x[2]·h[0] + x[1]·h[1] &amp; 需要采样 \\space x_1,x_2 \\\\ y[3] &amp;= x[3]·h[0] + x[2]·h[1] &amp; 需要采样 \\space x_2,x_3 \\\\ \\end{array} y[0]y[1]y[2]y[3]​=x[0]⋅h[0]=x[1]⋅h[0]+x[0]⋅h[1]=x[2]⋅h[0]+x[1]⋅h[1]=x[3]⋅h[0]+x[2]⋅h[1]​需要采样 x0​需要采样 x0​,x1​需要采样 x1​,x2​需要采样 x2​,x3​​ 归纳可得，其中 i 表示 信号序号，k 表示 响应脉冲序号 y[i]={x[0]⋅h[0]k=0x[i]⋅h[0]+x[i−1]⋅h[1]+x[i−2]⋅h[2]+...+x[i−(k−1)]⋅h[k−1]k&gt;0y[i] = \\begin{cases} x[0]·h[0] &amp; k = 0 \\\\ x[i]·h[0] + x[i - 1]·h[1] + x[i - 2]·h[2] + ...+x[i - (k-1)]·h[k-1] &amp; k \\gt 0 \\end{cases} y[i]={x[0]⋅h[0]x[i]⋅h[0]+x[i−1]⋅h[1]+x[i−2]⋅h[2]+...+x[i−(k−1)]⋅h[k−1]​k=0k&gt;0​ CPU 代码计算示例 注意：卷积后的结果可能会超出原来数值的范围，即使原来的数值都在范围内 // 1D convolution // We assume input and kernel signal start from t=0. bool convolve1D(float* in, float* out, int dataSize, float* kernel, int kernelSize) { int i, j, k; // check validity of params if(!in || !out || !kernel || dataSize &lt;=0 || kernelSize &lt;= 0) return false; // start convolution from out[kernelSize-1] to out[dataSize-1] (last) for(i = kernelSize-1; i &lt; dataSize; ++i) { out[i] = 0; // init to 0 before accumulate for(j = i, k = 0; k &lt; kernelSize; --j, ++k) out[i] += in[j] * kernel[k]; } // convolution from out[0] to out[kernelSize-2] for(i = 0; i &lt; kernelSize - 1; ++i) { out[i] = 0; // init to 0 before sum for(j = i, k = 0; j &gt;= 0; --j, ++k) out[i] += in[j] * kernel[k]; } return true; } 4.2 二维信号的卷积过程 二维信号的卷积是一维信号卷积的扩展，根据二维的单位脉冲响应和二维的信号拆解可得 注意：二维响应信号（卷积核）在最后使用的时候和原来左右上下都颠倒 例：在采样（输入）是（1，1）位置的卷积计算为 卷积的输入、卷积核、卷积输出如下 CPU 代码计算示例 注意：卷积后的结果可能会超出原来数值的范围，即使原来的数值都在范围内 bool convolve2D(int* in, int* out, int dataSizeX, int dataSizeY, float* kernel, int kernelSizeX, int kernelSizeY) { int i, j, m, n; int *inPtr, *inPtr2, *outPtr; float *kPtr; int kCenterX, kCenterY; int rowMin, rowMax; // to check boundary of input array int colMin, colMax; // float sum; // temp accumulation buffer // check validity of params if(!in || !out || !kernel) return false; if(dataSizeX &lt;= 0 || kernelSizeX &lt;= 0) return false; // find center position of kernel (half of kernel size) kCenterX = kernelSizeX &gt;&gt; 1; kCenterY = kernelSizeY &gt;&gt; 1; // init working pointers // note that it is shifted (kCenterX, kCenterY) inPtr = inPtr2 = &amp;in[dataSizeX * kCenterY + kCenterX]; outPtr = out; kPtr = kernel; // start convolution for(i= 0; i &lt; dataSizeY; ++i) // number of rows { // compute the range of convolution // the current row of kernel should be between these rowMax = i + kCenterY; rowMin = i - dataSizeY + kCenterY; for(j = 0; j &lt; dataSizeX; ++j) // number of columns { // compute the range of convolution, // the current column of kernel should be between these colMax = j + kCenterX; colMin = j - dataSizeX + kCenterX; sum = 0; // set to 0 before accumulate // flip the kernel and traverse all the kernel values // multiply each kernel value with underlying input data for(m = 0; m &lt; kernelSizeY; ++m) // kernel rows { // check if the index is out of bound of input array if(m &lt;= rowMax &amp;&amp; m &gt; rowMin) { for(n = 0; n &lt; kernelSizeX; ++n) { // check the boundary of array if(n &lt;= colMax &amp;&amp; n &gt; colMin) sum += *(inPtr - n) * *kPtr; ++kPtr; // next kernel } } else kPtr += kernelSizeX; // out of bound, move to next row of kernel inPtr -= dataSizeX; // move input data 1 raw up } // convert integer number if(sum &gt;= 0) *outPtr = (int)(sum + 0.5f); else *outPtr = (int)(sum - 0.5f); kPtr = kernel; // reset kernel to (0,0) inPtr = ++inPtr2; // next input ++outPtr; // next output } } return true; } 三、傅立叶变换 Reference 正弦信号，指数信号 跃阶信号 单位脉冲响应、单位阶跃响应的作用是什么？ Fundamentals of Digital Image and Video Processing Signals and Systems Convolution Proof of Separable Convolution 2D ","link":"https://kimokcheon.github.io/post/singalsandsystems/"},{"title":"HTML5的Ruby标签：为文字加注拼音","content":"ruby 标签 在 HTML5 中，可以使用 ruby 标签来对文字进行旁注，实现给文字加注拼音。 代码： &lt;ruby&gt; 注&lt;rp&gt;(&lt;/rp&gt;&lt;rt&gt;zhù&lt;/rt&gt;&lt;rp&gt;)&lt;/rp&gt; 音&lt;rp&gt;(&lt;/rp&gt;&lt;rt&gt;yīn&lt;/rt&gt;&lt;rp&gt;)&lt;/rp&gt; &lt;/ruby&gt; 效果： 注(zhù) 音(yīn) 在不支持 ruby 标签的浏览器中，显示效果大致为：注(zhù)音(yīn) 因Markdown支持所有HTML标记，因此可用于在Markdown文件中实现汉语拼音加注。 Markdown中表示拼音调号 格式 效果 一声 &amp;amacr; ā 二声 &amp;aacute; á 三声 &amp;ecaron; ě 四声 &amp;agrave; à u音 &amp;ouml; ö 转载自：Html5 的旁注标记，markdown如何打印拼音 ","link":"https://kimokcheon.github.io/post/html5-de-ruby-biao-qian-wei-wen-zi-jia-zhu-pin-yin/"},{"title":"Python图片转字符画","content":"突然好奇怎么把一张图片转为字符画 上网搜了一下，找到了这么一段代码[1]： #-*- coding:utf-8 -*- from PIL import Image IMG='D:\\Code\\python\\\\test1\\\\ascii_dora.png' WIDTH=60 HEIGHT=45 ascii_char = list(&quot;$@B%8&amp;WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/\\|()1{}[]?-_+~&lt;&gt;i!lI;:,\\&quot;^`'. &quot;) #将256灰度映射到70个字符上 def get_char(r,g,b,alpha=256):#alpha透明度 if alpha==0: return ' ' length=len(ascii_char) gray=int(0.2126*r+0.7152*g+0.0722*b)#计算灰度 unit=(256.0+1)/length # 字符对应的灰度区间宽度 return ascii_char[int(gray/unit)]#不同的灰度对应着不同的字符 #通过灰度来区分色块 if __name__=='__main__': im=Image.open(IMG) im=im.resize((WIDTH,HEIGHT),Image.NEAREST) txt=&quot;&quot; for i in range(HEIGHT): for j in range(WIDTH): txt+=get_char(*im.getpixel((j,i))) txt+='\\n' print (txt) #写入文件 with open(&quot;output.txt&quot;,'w') as f: f.write(txt) 核心挺容易理解的，就是先把彩色图像转换为灰度图像，再将不同的灰度对应到不同的字符上，然后输出。 有些挺有趣的小知识点的，在这篇博客里记录一下。 有关图像处理的一些概念 灰度(grayscale) In digital photography, computer-generated imagery, and colorimetry, a grayscale image is one in which the value of each pixel is a single sample representing only an amount of light; that is, it carries only intensity information.（灰度图像指的是每一个像素点仅有一个描述亮度的参数的图像。）[2] RGB图像灰度计算：0.2126*r+0.7152*g+0.0722*b。（字符画核心步骤之一） 图像重采样(resampling) 对图像进行缩放，实际上就是旧图像到新图像的映射，有多种映射算法，如Nearest Neighbour Resampling, Bicubic Resampling, Lanczos Resampling 等。这些不同的映射方式被称为图像重采样。 python的pillow库 Pillow是PIL的一个派生分支，但如今已经发展成为比PIL本身更具活力的图像处理库。pillow可以说已经取代了PIL，将其封装成python的库（pip即可安装），且支持python2和python3，目前最新版本是3.0.0。[3]使用命令pip install pillow即可安装。 用pillow库可以更改、裁剪图片，获得图片的RGB值，进行一些图像处理（如模糊、浮雕、获得轮廓）等等。使用说明手册：Handbook — Pillow (PIL Fork) 9.0.1 documentation resize()函数 pillow库里的resize()函数定义 def resize(self, size, resample=None, box=None, reducing_gap=None) 作用：缩放图像。 参数：size - 希望缩放到的大小，是一个二元组(width, height) resample - 可选参数，图像重采样方式。PIL库提供了多种filter，可参阅此处。 box - 可选参数，表示欲缩放的区域，是一个四元组。 reducing_gap - 没看明白，暂时也不关心。 返回值：缩放后的图像。 if __name__=='__main__'有什么用？ 可以看这篇文章：Python if __name__ == __main__ Explained with Code Examples。但是它写的有点啰嗦，扼要地解释一下： __name__是什么变量？ Python解释器(interpreter)读取一个Python文件时，会首先声明一些特殊的变量，然后再去执行文件中的代码。__name__就是其中一个特殊的变量。 __name__的值 Python文件被称为模块(module)，以.py作为文件后缀。模块中可以定义方法（函数）、类和变量。一个模块中可以导入其它模块，就是import语句。 当解释器正在执行的是本模块时，__name__的值为__main__；当解释器正在执行的是导入的模块时，__name__的值为该模块的模块名。 例如，编写一个模块file_one.py： # Python file one module print(&quot;File one __name__ is set to: {}&quot; .format(__name__)) 再编写一个模块file_two.py： # Python file two module import file_one print(&quot;File two __name__ is set to: {}&quot; .format(__name__)) 运行模块file_two.py，运行结果为： File one __name__ is set to: file_one File two __name__ is set to: __main__ if __name__=='__main__'有什么用？ 当我们只想在运行本模块时执行某些语句，就可以将这些语句编写到if __name__=='__main__'分支中。 这样，其他模块导入这个模块时，并不会运行这些语句。 在可迭代对象前加*号 unpacking operator * 注意到程序中有这么一行： txt += get_char(*im.getpixel((j,i))) 这里的*被称作unpacking operator，它的作用是解包(unpack)可迭代对象(iteratable object)[4]，通俗地说，就是将列表、字典等拆分成多个参数。[5]例如，下面的程序 a = [1, 2, 4] print(a) print(*a) print('------------------') a = {'a': 1, 'b': 2} print(a) print(*a) print(*a.values()) print('------------------') a = &quot;hello&quot; print(a) print(*a) 运行结果为 [1, 2, 4] 1 2 4 ------------------ {'a': 1, 'b': 2} a b 1 2 ------------------ hello h e l l o 注意，字典解包后，如果不使用values()函数，得到的是键，而不是值。 转字符画代码中，im.getpixel((j, i))得到了(j, i)位置像素点的RGB参数，并以元组的形式返回，前面加*后将元组分裂成三个变量，再用get_char()函数接受，事实上就是将这三个参数分别对应传给了get_char()函数的r, g, b三个参数。 *args与**kwargs 这篇文章作了详细的解释：Python args and kwargs: Demystified。 简单地说，二者作为函数的参数，用于向函数中传递任意数量的参数。其中*args将得到的参数打包成元组，**kwargs将得到的参数打包成字典（当然你也可以起其它的名字，比如*numbers，**dic等，习惯上使用*args与**kwargs）。 下面的例子使用了*args： # sum_integers_args.py def my_sum(*args): result = 0 # Iterating over the Python args tuple for x in args: result += x return result print(my_sum(1, 2, 3)) 运行结果： 6 下面的例子使用了**kwargs： # concatenate.py def concatenate(**kwargs): result = &quot;&quot; # Iterating over the Python kwargs dictionary for arg in kwargs.values(): result += arg return result print(concatenate(a=&quot;Real&quot;, b=&quot;Python&quot;, c=&quot;Is&quot;, d=&quot;Great&quot;, e=&quot;!&quot;)) 运行结果： RealPythonIsGreat! 更多介绍（如用*来分裂(split)列表、传参顺序等）请参看节首文章。 记事本字符大小不一致导致字符画无法对齐 Windows系统下用记事本打开输出的字符画，可能会遇到问题。 这是因为不同的字符大小不一致，导致无法对齐。解决方式很简单，更换字体（格式 - 字体）为Consolas即可，这是一种代码风格字体。 python实现图片转字符画 ↩︎ Grayscale - Wikipedia ↩︎ python pillow模块用法 ↩︎ 可迭代对象（Iteratable Object）是能够一次返回其中一个成员的对象，通常使用for 循环来完成此操作，如字符串、列表、元组、集合、字典等等之类的对象都属于可迭代对象。简单来理解，任何你可以循环遍历的对象都是可迭代对象。[6] ↩︎ python 在列表，元组，字典变量前加*号 - CSDN ↩︎ Python 中的可迭代对象、迭代器与生成器 ↩︎ ","link":"https://kimokcheon.github.io/post/python-tu-pian-zhuan-zi-fu-hua/"},{"title":"计算机体系结构","content":"第1章 引言 1.1 计算机体系结构的研究内容 按下键盘到幻灯片翻页：键盘传信号到南桥，南桥保存键盘编号并发出外部中断，中断信号附在指令上进入ROB，当执行到该条指令时清空流水线，然后设置系统状态为核心态（RISCV就是修改sstatus）、保存异常时PC值（RISCV就是sepc）、例外原因（RISCV就是scause）。然后置PC为中断服务程序入口，跳转过去。跳转之后保存上下文，向CPU读例外原因（中断），然后向南桥读中断原因（敲空格键），之后找到一个PowerPoint进程正处于阻塞态，等待空格键，于是唤醒这个进程。随后PowerPoint准备下一张幻灯片内容，再给一个中断，把待显示内容传给显存，并让GPU刷新屏幕。 如果翻页过程中卡顿，可能是什么原因？ 打开进程过多。 CPU主频低（可能性较小，因为翻页并不需要太高的性能）。 矢量图较多，GPU性能低。 要显示的数据量比较大，内存带宽不足。 通用计算机系统的结构层次：-------------------------- | 应用程序 | -------------------------- API -------------------------- | 操作系统 | -------------------------- ISA -------------------------- | 硬件系统 | -------------------------- 工艺模型 -------------------------- | 晶体管 | -------------------------- 冯诺依曼结构： 构成：控制器、运算器、存储器、输入设备、输出设备。 指令和数据存储在存储器中，CPU从内存中取出指令和数据进行运算，并把运算结果存在内存中。 本质特征：存储程序和指令驱动执行 1.2 衡量计算机的指标 性能、价格和功耗是衡量一台计算机好坏的三个重要指标。 1.2.1 性能 影响性能的因素： 指令数：算法、编译器、指令系统设计 CPI：指令系统设计、微结构 每周期用时（主频）：微结构、电路设计和工艺 1.2.2 价格 性价比： 高性能计算机：首要考虑性能 嵌入式应用：为追求低功耗低成本，可以牺牲一部分性能 介于二者之间：性价比 影响成本的因素：芯片成本为主，含一次性成本（研发成本）和制造成本（生产量上来了，生产技艺就会改良，次品率少了，成本也会下降）。 1.2.3 功耗 动态功耗 开关功耗：电压变换（0/1），电容充放电 短路功耗：电压翻转过程中，N管和P管暂时性同时打开，产生短暂的短路 静态功耗 漏电功耗：源极、栅极、漏极、衬底之间都有可能发生漏电，产生漏电功耗 降低电容、电压，降低频率，改进工艺；结构和逻辑设计上降低翻转率等。 1.3 计算机体系结构的发展 计算机体系结构发展的动力： 工艺技术的发展：半导体工艺技术和计算机体系结构技术互为动力；摩尔定律在逐渐失效，工艺技术对体系结构的影响在降低。 应用需求的提高：网络计算、游戏等；将成为首要动力。 摩尔定律： 常规表述：晶体管数目每18-24个月翻一番。 不是客观规律，是主观经验。 摩尔电路与计算机结构进步： 第一代：电子管计算机 第二代：晶体管计算机 第三代：中小规模IC计算机 第四代：大规模IC计算机 “墙”： 存储墙：CPU和存储器速度的剪刀差 功耗墙：高主频设计带来过高的功耗 成本墙：越来越贵 复杂度墙：芯片设计复杂度越来越高，难以设计 ... 1.4 体系结构设计的基本原则 平衡性、局部性、并行性、虚拟化。 平衡性：统筹兼顾。木桶原理，各结构应平衡设计，避免某个结构性能过低制约整个系统。例如CPU的计算性能和访存带宽的平衡；Amdahl定律。 局部性：重点突出。利用局部性进行系统性能优化；RISC的二八定律；访存局部性（时间、空间）产生Cache、TLB、预取等结构和设计。 并行性：开发各个层次的并行性。 虚拟化：“用起来是这样，实际上是那样”。比如虚拟内存、多线程、虚拟机、Cache的提出、Cache一致性协议等。 第2章 指令系统 2.1 指令系统简介 是软硬件的界面，不仅与指令功能有关，还涉及到运行环境（Cache管理、存储管理、安全管理、异常和中断处理……）。 2.2 指令系统设计原则 指令系统设计的基本原则： 兼容性：关键特性，对软件向前兼容，支持过时指令。 通用性：各种应用的需求，例如视频解码相关指令等。 高效性：便于CPU硬件结构的设计优化，提升性能。 安全性：考虑不同的安全要求，提供保护等。 指令系统设计的影响因素： 工艺技术：片内可集成晶体管数目增多，功能集成度提高，可支持更多功能。 计算机体系结构：直接影响；指令系统兼容性与体系结构发展之间的矛盾。 操作系统：异常和中断、安全等级、多进程和虚拟内存的支持等（例如专用控制寄存器操作）。 编译技术：使编译器有效地调度指令，增加编译灵活性等。 应用程序：算法支持、应用需求。 2.3 指令系统发展历程 2.3.1 指令内容的演变 根据指令长度的不同，可分为CISC（复杂指令系统）、RISC（精简指令系统）和VLIW（超长指令字）。 CISC变长；RISC定长；VLIW本质上是多条同时执行的指令的组合。 2.3.2 存储管理的演变 段式、页式、段页式。 三种存储管理方式的地址转换过程。 2.3.3 运行级别的演变 无管理-&gt;增加保护模式（权限）-&gt;增加调试模式-&gt;增加客户模式（又称虚拟化支持） 不同运行级别下可访问的资源不同，一般是包含关系。 2.4 指令系统的组成 操作码和操作数。 2.4.1 地址空间 处理器可访问的地址空间包括立即数、寄存器空间和系统内存空间。 寄存器空间：通用寄存器、专用寄存器、控制状态寄存器； 系统内存空间：内存空间、IO空间。 使用相同的load/store指令访问内存空间和IO空间。 处理器对IO空间的访问不能经过Cache，因此需要有标记，指明访存是否经过Cache。 根据指令使用数据的方式，指令系统可分为堆栈型、累加器型、寄存器-存储器型、寄存器-寄存器型。 堆栈型：操作数都在栈顶，运算结果默认存回栈顶，通过PUSH和POP改变栈的内容。 累加器型：一个操作数隐含在累加器中，另一个操作数由指令指定，可以是内存中的值，也可以是寄存器中的值。 寄存器-存储器型：跟累加器型比较像，但是没有隐含操作数，操作数为寄存器和内存单元，须显式指定。 寄存器-寄存器型：除了访存指令之外，其他指令只能操作寄存器。 早期多用堆栈型和累加器型，主要目的是降低硬件实现的复杂度；现在多用寄存器-寄存器型，目的在于提高访存速度以及充分利用局部性原理。另外，寄存器-寄存器型的优势是容易判断相关。 2.4.2 操作数 大尾端和小尾端：小尾端起始地址在一个字的最后一个字节，大尾端反之。 寻址方式：寄存器寻址、立即数寻址、偏移量寻址、寄存器间接寻址等。 2.4.3 指令操作和编码 从功能上看，可分为四大类：运算指令、访存指令、转移指令、特殊指令。 运算指令：加减乘除、移位运算、逻辑运算等； 访存指令：load/store，取数长度、寻址方式等； 转移指令：相对/绝对、直接/间接、条件/无条件； 特殊指令：TLB管理、Cache管理、异常管理、安全管理等。 最常用的指令是一些简单指令，把这些加快可有效提升性能，其它的慢一点没关系（局部性原理）。“常用的做得快，少用的只要对。” 转移指令确定转移条件的方式：判断条件码和比较寄存器的值。 判断条件码：采用运算指令计算条件，置条件码，条件指令使用条件码判断是否转移。 比较寄存器的值：转移指令直接比较寄存器判断是否转移。 2.5 RISC指令集比较 比较的RISC指令集：MIPS、PA-RISC、PowerPC、SPARC v9、LoongArch。 RISCV也是常用的RISC指令集。 指令格式：主要组成元素基本相同，只是摆放位置存在差别。 寻址方式：都支持四种基本的寻址方式——寄存器寻址、立即数寻址、偏移量寻址、变址寻址。PA-RISC和PowerPC支持的寻址方式更多一些。 指令功能：区别较大。 2.5.1 不同指令的特色 MIPS：非对齐访存。LWL读取访存地址所在的字并将访存地址到该字中最低位的字节拼接到目标寄存器的高位；LWR读取访存地址所在的字并将访存地址到该字中最高位的字节拼接到目标寄存器的低位。依尾端而不同： SPARC：寄存器窗口。 PowerPC：Link和Count寄存器。 PA-RISC：Nullification。 2.6 C语言的机器表示 过程调用（函数调用）：bl和jr指令。用栈或寄存器保存参数，保存和恢复现场。 哪些情况下需要保留和恢复现场？ 函数调用：sp和ra寄存器需要保存，简单的调用不需要保存。 线程切换：几乎全部通用寄存器（除了部分操作系统专用的）。 进程切换：几乎全部通用寄存器（除了部分操作系统专用的），其它现场。 例外处理：例外处理要用的寄存器要保留。 虚拟机切换：所有通用寄存器，部分控制操作系统用的寄存器。 第3章 特权指令系统 3.1 特权指令系统简介 用户程序能看到的：用户态指令系统结构、操作系统提供的系统调用（合称ABI）。 操作系统能看到的：用户态指令系统结构、特权态指令系统结构。 编译器编译不出特权态指令，其为操作系统专用。 特权态指令作用： 定义和切换运行模式 异常与中断处理 虚拟存储管理 用户态可见的寄存器： 通用寄存器（含浮点寄存器） 部分控制状态寄存器（如X86的EFLAG，LoongArch的FCSR） 3.2 异常与中断 3.2.1 异常分类 异常定义：使软件从正常执行流中脱离的事件。 分类：根据来源，分为外部事件、指令执行中的错误、数据完整性问题、地址转换异常、系统调用和陷入、需要软件修正的运算。 外部事件：来自CPU流水线外部的事件，也称中断。例如键盘输入。 指令执行中的错误：指令未定义、用户态无权访问的指令或地址、除零异常、地址不对齐、整数运算溢出等。 数据完整性问题：ECC（检二纠一）或奇偶校验错误，来源于存储器软错误。 地址转换异常：虚实地址转换时，没有有效的TLB项。 系统调用和陷入 需要软件修正的运算：通常来源于浮点运算指令，硬件实现过于复杂而不支持，交给软件。 3.2.2 异常处理 精确异常：发生异常时，被异常打断的指令前的所有指令都已经执行完，该指令之后的所有指令都像没执行一样。 异常处理流程：异常处理准备、确定异常来源、保存执行状态、执行异常处理、恢复执行状态并返回。 异常处理准备：① 记录EPTR，LoongArch将EPTR存储到CSR.ERA寄存器（RISCV：sepc寄存器）；② 调整权限等级，LoongArch将CSR.PLV置0以进入最高权限等级；③ 屏蔽所有中断，LoongArch将CSR.CRMD的IE域置0。④ 保存异常发生现场的部分信息，例如将CSR.CRMD的PLV和IE域记录到CSR.PRMD的PPLV和LIE域中，供异常返回时使用。 确定异常来源：主要有两种方式：① 发生异常时进入同一个异常处理程序，然后查询异常编号，进入相应的处理函数入口；② 发生异常时根据异常来源进入不同的异常处理程序，这样就自动知晓异常来源。 保存执行状态：将通用寄存器和部分CSR压栈。 处理异常 恢复执行状态：从栈中取出通用寄存器和部分CSR。 异常处理返回：同时完成权限等级的切换和返回地址恢复。LoongArch中是ertn指令，x86是iret指令。 异常嵌套：将异常分为多个优先级，更高优先级的异常可以抢占处理。 3.2.3 中断 有两类异常非常容易出现，地址转换异常（访问地址不在TLB中）和中断（外部事件想要获得CPU）。 中断传递机制：从中断源传递到CPU的方式，主要有中断线和消息中断。 中断线：中断源不多时，直接从中断源连线到处理器引脚（LoongArch，电平中断）；也可以先把连线汇总到中断控制器（这时采用边沿中断），然后转发汇总到（可能是不同的）CPU。但是这样会占用CPU引脚，因此一般只在SoC上使用。 消息中断：消息中断以数据(消息) 的方式在系统总线上传递。发中断就是向指定的地址写一个指定的数。 向量化中断：嵌入式CPU对中断处理实时性要求较高，因此为每个中断设置独立的入口，进入后直接处理。这样就省去了进入中断处理程序后识别中断源的开销，加速处理。 中断使能控制位的原子修改：修改CSR.CRMD中断使能位时，操作必须是原子的，不然也可能被中断打断。方式有：禁用中断、添加专门的位原子修改指令、不允许中断处理程序修改SR、使用通用的方法保证程序段的原子性等。LoongArch中添加了csrxchg指令，专门用来原子地修改中断使能位。 3.3 存储管理 ipad 第4章 软硬件协同 4.1 ABI ABI定义了应用程序二进制代码中相关数据结构和函数模块的格式及其访问方式，使得不同的二进制模块之间的交互成为可能。 内容： 数据表示和对齐要求 寄存器使用约定 函数调用约定 栈布局 目标文件和可执行文件格式 函数调用规范 进程虚拟地址空间布局 栈帧布局 4.2 六种常见的上下文切换场景 函数调用 异常和中断 系统调用 进程切换 线程切换 虚拟机：虚拟机无法独立处理内部的上下文切换时，会退出虚拟机的状态，借助宿主机的虚拟化管理软件来完成任务。虚拟机和宿主机之间的切换需要保存和恢复所有可能被修改的虚拟机相关状态信息。 4.3 同步机制 自旋锁（自旋等待）、互斥锁（阻塞与唤醒） 读-改-写指令、LL/SC指令 事务内存：非阻塞的同步机制，核心思想是通过尝试性地执行事务代码，在程序执行过程中动态检测事务间的冲突，并根据冲突检测结果提交或取消事务。 第5章 计算机组成原理和结构 5.1 冯诺依曼结构 组成： 逻辑上：运算器、控制器、存储器、输入设备、输出设备。五大部分 物理上：CPU（运算器、控制器、Cache）、内存、IO设备。三大部分 存储程序和指令驱动执行。 5.2 计算机的组成部件 5.2.1 运算器 运算器包括：ALU（算术和逻辑运算部件）、移位部件、FPU（浮点运算部件）、向量运算部件、寄存器等。 运算器支持的运算类型经历了由简单到复杂的过程。 随着晶体管集成度的不断提升，处理器中所集成的运算器的数量也在持续增加。 5.2.2 控制器 含程序计数器和指令寄存器。 指令通过译码产生控制信号，这些控制信号可以由硬连线产生，可以由微程序产生，也可以由两者结合产生。 常采用指令流水线、超标量、转移预测、乱序执行，预取及高速缓存等技术来提高指令吞吐率。 体系结构研究的一个永恒的主题就是加速指令执行周期，从而提高计算机运行程序的效率。 乱序执行：缓解由于指令相关引起的阻塞。 译码后，执行指令前，判断操作数是否准备好。若已准备好，直接执行；否则就进入保留站（又称发射队列）等待。 乱序执行，但有序结束。指令执行前，按顺序进入ROB；然后乱序执行，将结果写入重命名寄存器；指令执行后，按照在ROB中的顺序，将重命名寄存器中的结果逐条提交到目标寄存器或存储器中。 重命名寄存器可有效地避免不同运算访问同一个结构寄存器所带来的并行化瓶颈。 超标量技术： 超标量技术使得寄存器、保留站、ROB的端口数，以及功能部件的个数都要增加。 超标量技术还会带来同一拍中多条指令间的相关。 转移预测： 根据转移历史，在转移指令的取指或译码阶段预测转移方向和地址。 转移指令的执行阶段需要判定预测结果是否正确。若错误，则需要取消流水线中的后续指令。 常见的技术有转移历史表BHT、分支目标缓冲BTB、返回地址栈RAS等。 5.2.3 存储器 三个层次：Cache、主存储器（内存）、辅助存储器。 Cache：SRAM（比DRAM容量小，但速度快） 内存：DRAM 辅助存储器：磁盘、SSD 少量ROM（只读存储器），存放引导程序和BIOS。 MMU负责虚实地址转换。 存储介质： SRAM：易失、快、贵 DRAM：易失、慢、便宜 闪存：非易失、快、贵（U盘、SSD，在变多变便宜） 磁性存储介质：磁盘、硬盘、磁带 Cache： 缓解内存速度与处理器速度的剪刀差。 利用访存的空间局部性和时间局部性。 现代处理器普遍在片内集成多级Cache。 AMAT = HitTime + MissRate × MissPenalty 内存：SDRAM实现 基本单元：由MOS管（打开/关闭本单元）和电容（存储逻辑值） 组成。 读：位线预充到Vcc2\\frac{V_{cc}}{2}2Vcc​​，字线打开MOS管，感应放大器放大数据（此时C中的电容被破坏）；写：字线上提供更大的电流，重置感应放大器和位线的值。 电容会漏电，周期刷新，通过读操作完成。 读写速度影响因素：行缓冲局部性和Bank级并行度 行缓冲局部性：读操作后，数据被存到感应放大器（即行缓冲，读写延迟低一些）中，电容被破坏。Close Page：每次读写完之后都从行缓冲写回存储体；Open Page：先不写回，下次读写时，如果命中直接从行缓冲中取出，如果不命中就先写回再到新地址访存。局部性好就用Open Page，不好就用Close Page。 Bank级并行度：不同Bank可以并行访问。 5.2.4 IO设备 GPU： 显示过程：CPU把要显示的数据放到内存，通知GPU通过DMA方式读取这些数据，GPU解析和运算后，把结果写到显存中，再由显示控制器读取显存数据并输出显示。 集显的CPU和GPU距离近，内存一致性维护开销和数据传输延迟会大幅降低。但是系统内存要承担显存的作用，访存压力大幅增加。 硬盘： 性能指标：延迟和带宽。 访问时间：寻道时间（找磁道）、旋转时间（找扇区）和传输时间（传数据）。 闪存：U盘、SD卡、SSD固态硬盘都是闪存。 5.3 计算机硬件结构演进 CPU GPU 北桥：离CPU最近，控制显卡、内存与CPU之间的数据交换。向上连接处理器，向下连接南桥。 南桥：硬盘、键盘以及带宽要求低的IO接口与内存、CPU之间的数据交换。 5.3.1 CPU-GPU-北桥-南桥四片结构 CPU、南桥、北桥在主板上，GPU以显卡的形式插在主板插槽上。 CPU通过系统总线连接北桥，GPU以显卡的形式连接北桥。北桥通过南北桥总线连接南桥。 内存控制器集成在北桥中，GPU以显卡的形式连接北桥；硬盘接口、USB接口、网络接口、音频接口、键鼠接口（这都是低速IO）在南桥中。 北桥还会提供扩展接口，连接其它功能卡。北桥是系统连接的枢纽。 5.3.2 CPU-北桥-南桥三片结构 与四片结构的最大区别：三片结构的GPU被集成到北桥中。 CPU通过系统总线连接北桥，北桥通过南北桥总线连接南桥。 内存控制器、显示功能、高速IO（如PCIE等）集成在北桥中；硬盘接口、USB接口、网络接口、音频接口、键鼠接口（这都是低速IO）在南桥中。 5.3.3 CPU-弱北桥-南桥三片结构 随CPU性能提高，访存速率对整体性能制约越来越大（存储墙问题），访存速率要求超过CPU与北桥之间的系统总线带宽。因此将内存控制器从北桥转移到CPU中。 北桥不再有内存控制器，剩下显示功能、高速IO。 5.3.4 CPU-南桥两片结构 GPU越来越猛，也从北桥脱离进入CPU。北桥越来越弱，直接和南桥合并（还叫南桥）。 CPU集成处理器核、内存控制器和GPU，通过系统总线和南桥相连。 南桥包含硬盘、USB、网络控制器，以及PCIE/PCI、LPC等总线接口。 GPU和CPU在一块，会带来访存冲突。一般GPU优先级高一些，一定程度上会影响CPU性能。 5.3.5 SoC单片结构 单片计算机系统，集成了处理器、内存控制器、GPU以及硬盘USB、网络等IO接口。 小型化、低功耗。面向中低端和嵌入式。 5.4 处理器和IO设备通信 IO设备由设备控制器控制。设备控制器提供一组IO寄存器接口。寄存器内容改变会引起设备控制器执行一系列复杂的动作。 处理器通过向IO寄存器写入命令字（即修改IO寄存器的值）来控制IO设备。 5.4.1 IO寄存器寻址 两种方式：内存映射IO和特殊IO指令。 5.4.2 处理器和IO设备的同步 两种方式：查询和中断。 查询：又称轮询，处理器向IO设备发出访问请求后，就不断读取IO设备的状态寄存器，直到满足访问条件。大多数IO设备比较慢，因此查询容易造成性能浪费。 中断：处理器让设备开始干活后，就转而做其他事。设备完成任务后，产生中断信号中断处理器的执行。中断的一般过程： 中断源产生中断信号，到中断控制器 中断控制器产生中断请求，到CPU CPU产生中断响应，读取中断类型码 CPU根据中断类型码执行对应的中断服务程序 CPU从中断服务程序返回，执行结束 5.4.2 存储器和IO设备的通信 两种方式：PIO和DMA。 CPU访问IO设备都是Uncache访问。 PIO：经由CPU，以通用寄存器做中介。存储器向IO设备搬运数据时，处理器先把数据从存储器搬到通用寄存器中，然后再从通用寄存器写到IO设备中，反之则反。 PIO方式访问延迟大，且IO访问之间需要严格的顺序关系。 PIO有两种同步方式：查询和中断。 一般用于低速IO设备的工作，如键盘、鼠标。 DMA：在存储器和IO设备之间专门开辟通道，由DMA控制器控制传输。 一般过程为：① 处理器为DMA请求分配一段地址空间，并为DMA控制器配置参数；② DMA控制器开始传输，CPU转而做其他事；③ DMA控制器完成后向CPU发中断，通知执行情况（完成or出错，出错还得有错误信息）；④ 处理器完成本次DMA请求。 一般用于高速IO设备的工作，如网卡收发包、硬盘传输等。 第6章 计算机总线接口技术 6.1 总线概述 本质作用：完成数据交换。 层次： 机械层：接口的外形尺寸等。 电气层：信号描述、电源电压、电平标准、信号质量等。 协议层：信号时序、握手规范、命令格式、出错处理等。 架构层：硬件模型、软件架构等。 6.2 总线分类（※） 按数据传送方向： 单向总线：VGA 双向总线 半双工：USB 2.0 全双工：UART 按总线使用的信号类型（数据组织方式）： 并行总线：PCI 串行总线：PCIe、SATA、HT 按数据握手方式： 无握手：DVI、APB Vlid-Ready：PCI、AXI Credit：PCIe、HT 按连接方式： 共享信号（通过仲裁决定占有总线）：PCI 点对点（专用的交换节点）：PCIe 按时钟实现方式： 全局时钟（时钟源到各部件路径等长）：PCI 源同步： 时钟随数据一起发送，二者路径等长：HT 时钟嵌入到数据中发送：PCIe 按总线所处的位置： 片上总线：AXI、AHB、ASB、APB等 内存总线：内存控制器和内存条之间的接口 系统总线：QPI、FSB、HT 设备总线：PCI、PCIe 6.3 片上总线 嵌入式SoC芯片上的功能模块称为IP。IP间通过片上总线互连。 主流片上总线是ARM公司的AMBA系列总线，包括AXI、AHB、ASB、APB等总线。 片上总线的特点（与片外实现相比）：高并行性（最大特点）；引线资源丰富；全局时钟相对容易实现；不需要复杂的物理层转换；不使用三态信号。 片上总线的性能：频率（能否加流水级）、数据位宽、带宽利用率（总线事务中数据传输时间占总时间的比例）。 AXI特点：支持不对齐访问；读写分离。 6.4 内存总线 内存总线规范由JEDEC组织制定，包含总线的三个层级：机械层、电气层、协议层。 内存总线信号分类： 时钟信号 地址命令信号 数据及数据采样信号 对DRAM的寻址是按照bank地址、行地址和列地址来进行的。 对内存总线的控制是通过内存控制器实现的。内存控制器负责管理内存条的初始化、读写、低功耗控制等操作。 6.5 系统总线 所处的位置：处理器与桥片之间、多处理器之间。 串行总线、点对点传输、全双工传输。 HT的流控机制、虚通道。 6.6 设备总线（IO总线） PCI和PCIe。 PCIe兼容PCI软件架构，基本取代PCI。 第10章 并行编程基础 计算机体系结构是描述计算机各组成部分及其相互关系的一组规则和方法，是程序员所看到的计算机属性。 计算机体系结构主要研究内容包括指令系统结构(ISA) 和 计算机组织结构(CO)。 微体系结构是微处理器的组织结构，并行体系结构是并行计算机的组织结构。 冯诺依曼结构的存储程序和指令驱动执行是现代计算机体系结构的基础。 10.1 程序的并行行为 程序的并行行为包括：指令级并行、数据级并行、任务级并行。 10.1.1 指令级并行 只有RAW数据相关 和 控制相关真正制约指令级并行执行。 实现方式：微结构设计技术。例如指令流水线、多发射、动态调度、寄存器重命名、转移猜测等。 喂饱“饥饿”的运算器：转移猜测（提供足够的指令）、存储管理（提供足够的数据）。 10.1.2 数据级并行 数据级并行是指对集合或者数组中的元素同时执行相同的操作。 实现方式：现代处理器的向量功能部件、向量处理器、多处理器中SPMD编程。 10.1.3 任务级并行 任务级并行是将不同的任务（进程或线程）分布到不同的处理单元上执行。 分类：进程级并行、线程级并行。 实现方式：让不同处理器执行不同的进程或线程。 应用：商业应用领域、多道程序工作负载(Multiprogramming Workload)。 10.2 并行编程模型 分为单任务和多任务并行模型。单任务并行模型包括单任务数据并行模型；多任务并行模型包括多任务共享存储编程模型 和 多任务消息传递编程模型。 10.2.1 单任务数据并行模型 数据级并行在SIMD计算机上实现，着重开发指令级并行，为单任务数据并行；在SPMD计算机上实现，着重开发子程序级并行，为多任务数据并行。 特点：单线程、同构并行、全局命名空间、隐式相互作用、隐式数据分配。 10.2.2 多任务共享存储编程模型 运行在各处理器上的进程/线程通过读写共享存储器上的共享变量来进行通信。 特点：多线程异步执行、单一的全局名字空间、隐式数据分配、显式或隐式负载分配、显式同步。 常见模型：Pthreads、OpenMP等。 10.2.3 多任务消息传递编程模型 不同处理器上的进程/线程拥有独立的地址空间，通过网络传递消息来相互通信。 特点：多进程异步执行、独立的地址空间、显式相互作用、显式分配。 常见模型：MPI、PVM。 10.2.4 共享存储与消息传递编程模型的编程复杂度 共享存储中，所有处理器共享同一个主存储器，统一编址；消息传递中，每个处理器有一个它自己才能访问的局部存储器，每个存储器单独编址。 共享存储中，程序员只需要对计算任务进行划分；消息传递中，程序员需要对计算任务、数据进行划分，并安排进程间的所有通信。 10.3 典型并行编程环境 数据并行：SIMD 共享存储编程模型：Pthreads和OpenMP 消息传递编程模型：MPI 10.3.1 数据并行SIMD编程 向量指令（vld, vadd.b, vst等），利用向量寄存器实现。龙芯的向量寄存器复用了浮点寄存器。 10.3.2 Pthreads C语言的一套函数库。利用pthread_create, pthread_join, pthread_exit, pthread_self管理线程，利用pthread_yield, pthread_cancel调度线程，利用pthread_mutex_init, pthread_mutex_lock/unlock, pthread_cond_init, pthread_cond_wait/signal/broadcast等同步线程。 10.3.3 OpenMP 主要 API：制导指令、运行库、环境变量。 常见子句： 共享：shared(var1, var2, ...) 私有：private(var1, var2, ...) 归约：reduction(op:var) 例如，#pragma omp parallel for private(i, x), reduction(+:sum)语句表示在接下来的循环中，使用多个线程并行执行，并设置i和x变量为私有，sum变量为归约变量。 10.3.4 MPI 主要API：6个基本函数： 序号 函数名 含义 1 MPI_Init 初始化MPI执行环境 2 MPI_Finalize 结束MPI执行环境 3 MPI_Comm_size 确定进程数 4 MPI_Comm_rank 确定自己的进程标识符 5 MPI_Send 发送一条消息 6 MPI_Recv 接收一条消息 comm代表communicator，通信域。通信域包含进程组和通信上下文。 点对点通信方式：阻塞方式和非阻塞方式。前者等消息从本地送出后才继续执行，保证缓冲区等资源可再用；后者不等消息从本地送出就继续执行，不保证缓冲区等资源可再用。 四种通信模式： 标准模式：由MPI决定后面三种模式选哪一种； 缓冲模式：使用缓存存储消息，发送与接收无关； 同步模式：等接收开始后，发送才能返回； 就绪模式：等接收启动后，发送才能开始。 集体通信(Collective Communication)： 栅障(MPI_Barrier) 广播(MPI_Bcast) 收集(MPI_Gather) 散播(MPI_Scatter) 归约(MPI_Reduce, MPI_Allreduce) 第11章 多核处理结构 11.1 多核处理器的发展演化 提出背景 半导体工艺：摩尔定律放慢、面临失效。且工艺提升对性能带来的红利在缩小。 功耗墙：提高单核性能功耗开销比多核大。 并行结构的发展：SIMD、SMP、CC-NUMA、MPP结构…… GPU采用什么结构？ GPU（图形处理器）采用流水线结构来实现并行化。流水线结构包括一组处理器，每个处理器都有一个特定的角色，它们协同工作，按照一定顺序处理数据。SM（Streaming Multiprocessor）是 GPU 中的一种基本组成单元，通常称为“流处理器”。SM 包含多个处理器核心，用于执行并行计算。 流水线结构是将一个大任务分解成若干个小任务，并将这些小任务分配给不同的流水线处理器来实现并行化，而 SM 就是这样的一个流水线处理器。 分类方式 按照从核数量：多核处理器和众核处理器（一般指多于64核的处理器）； 按照处理器核结构：同构和异构； 按照适用应用：通用和专用（GPU可以看作是一种专用多核处理器，具有很高的浮点峰值运算性能）。 流行的CPU结构 多核+向量处理 众核（GPU是其中一种，同构） 带有协处理器的异构多核 存储结构：通用多核处理器一般采用共享存储结构。 11.2 多核处理器的访存结构 需要关心的问题： 存储一致性：多核处理器的访存指令次序如何约定？ 片上Cache结构：Cache结构采用私有还是共享？集中式还是分布式？ Cache一致性：一个数据可能在多个处理器的私有Cache中和内存中存在备份，如何保证数据一致性？ 11.2.1 片上Cache结构 主流结构：片内共享LLC，片间共享内存。 共享LLC结构中，主要有UCA和NUCA结构。 11.2.2 存储一致性模型 顺序一致性模型；在顺序一致性约束下，多处理机的表现与对应的单处理机多进程表现一致（和OS中研究的那种表现一致）。 处理器一致性模型：在任意load开始执行前，先于它的load操作都要完成；在任意store开始执行前，先于它的load和store操作都已完成。换句话说，可以在某个load执行时，先于它的store操作还没有执行或没有执行完。也就是允许load越过store操作执行。实际上是把write buffer变得让用户可见。 弱一致性模型：同步操作和访存操作满足顺序一致性，也就是说，同步操作执行前的访存操作都已完成，访存操作执行前的同步操作都已完成。 释放一致性模型：把同步操作拆分成acquire和release操作。同步操作满足顺序一致性。release操作执行前的访存操作都已完成（收工之后才能释放锁），访存操作执行前的acquire操作都已完成（可以进到临界区）。 11.2.3 Cache一致性协议 定义：一种把新写的值传播到其它处理器核的机制。 分类： 如何传播：写无效(Write Invalidate)和写更新(Write Update); 向谁传播：侦听协议(Snoopy)和目录协议(Directory)。 写无效协议与写更新协议： 写无效协议：某个处理器Cache值更新时，先令其它处理器中相应单元的值标记为无效，等其他处理器要用到该单元时，再更新为新值。 写更新协议：某个处理器Cache值更新时，即把新值更新到其它处理器的Cache中。 侦听协议与目录协议： 侦听协议：写数的处理机把新写的值或要读取的地址广播出去；其它处理机侦听广播，广播中内容与自己有关时接受新值或提供数据。适用于总线互连结构。 目录协议：每个Cache存储行都维护一个目录项，目录项记录了每个处理器核是否含有该行的备份。目录项另有一个改写位，记录是否有某个处理器改写了改行。可以避免广播，但是存储开销大，需要动态维护。 Cache状态：Cache一致性协议是通过维护每个Cache行的一致性状态来实现的。具体有ESI、MESI和MOESI，其中ESI最简单，MESI较常见。 ESI：（※ESI状态转换重要） E（Exclusive，独占）：对应Cache行被当前处理器核独占。其它处理器核需要等当前处理器释放； S（Shared，共享）：多处理器核共享，因此是只读的。 I（Invalid，无效）：当前Cache行无效。 MESI：增加M状态。这时，E状态修改为，当前Cache行虽然被独占，但是还没有被修改；M状态自然表示被独占且已经被修改。 存储一致性与Cache一致性：Cache一致性都是针对某种存储一致性设计的。常用弱一致性模型。 11.3 互连结构 常见片上互连结构：片上总线、交叉开关、片上网络。 连接处理器核、Cache、内存控制器、IO接口等模块。 11.3.1 片上总线 由一组信号线连接各功能模块。 包括数据总线、地址总线、控制总线等。 优点：实现简单-&gt;利于广播通信。 缺点：独立资源-&gt;可伸缩性差。 结点间采用握手方式建立直通链路。 11.3.2 交叉开关 以矩阵形式组织的开关，任意输入端口可以接上任意输出端口。 具有非阻塞特性，在不冲突的前提下可以建立多个输入输出连接。 优点：并行非阻塞通信-&gt;高带宽。 缺点：复杂度为O(mn)-&gt;可伸缩性有限。 结点间采用握手方式建立直通链路。 11.3.3 片上网络 概念 数据封装成数据包，通过路由器之间的分组交换和存储转发机制实现处理器核间通信。 抽象成节点、互连网络、网络接口。 研究内容：拓扑结构、路由算法、流量控制。 拓扑结构 环(ring)、网格(mesh)。 路由算法 环的路由方法：只有唯一一种。 Mesh网的路由方法：维序路由（一路走到头）、全局自适应路由（优选负载较轻方向）。 路由器结构 路由器由寄存器、交叉开关、功能单元和控制逻辑组成。 适合Mesh结构的路由器：输入端口连接buffer；分配器管理buffer和交叉开关；buffer连接到交叉开关，从而连接到输出上。 分配器作用：路由计算、虚通道分配、交叉开关分配。 数据包传输有四个流水级：路由计算(RC)、虚通道分配(VA)、交叉开关分配(SA)、交叉开关上传输(ST)。head flit经过四个流水级，body flit经过后两个流水级。 流量控制 片上网络的主要资源：信道和缓冲区。 好的流量控制策略：公平性和无死锁。 每个结点都有向相邻节点发送数据的缓冲区Buffer，和记录相邻节点缓冲区使用量的计数器S[0-3]。流量控制方法详见课本。 11.4 多核处理器的同步机制 对共享变量需要进行同步，否则同一个并行程序可能在不同的运行中产生不同的结果。 三种常见的同步机制：锁、栅障、事务内存。 常用硬件同步指令实现上述同步机制。 11.4.1 硬件同步指令 主要是“读-改-写”指令和“LL/SC”指令。 读-改-写 名称 含义 Test_and_Set 取出对应地址上的值，并为其赋一个新值。 Swap 交换两个地址上的值。 Compare_and_Swap 如果对应地址上的值和A相等，则把B赋给这个地址，否则这个地址的值不动。 Fetch_and_Op 取出对应地址上的值，进行某种运算Op，然后存回去。 LL/SC LL指令将某个地址上的值读取到寄存器中，并将LLbit置为1。 LL执行完但SC指令尚未执行时，如果该地址上的值被其他处理器访问，或者执行了eret操作，则将LLbit置为0。 SC指令检查LLbit，如果是1，则将寄存器的值更新到该地址上，并且把寄存器的值重新设为1，表示成功；否则不更新该地址上的值，并把寄存器的值重新设为0，表示失败。 如果失败，一般需要回到开头LL处，重新执行。 11.4.2 锁 使用Test_and_Set实现，是一种基本的实现方式。 缺点：获取锁失败时要循环访问，产生大量片上互连通信。 解决方式：可以在相邻两次循环访问之间引入延迟。 11.4.3 栅障 使用Fetch_and_Inc实现： barrier(){ Fetch_and_Inc(count); while(count != Max) ; } 缺点：与自旋锁相同，有大量通信。 11.4.4 事务内存 事务：事务内存中，访问共享变量的代码区域声明为一个事务。 事务的性质： 原子性：这个代码区域中的所有指令要么都执行要么都不执行。 一致性：任何时刻内存一致。 隔离性：不同事务内部对象状态互不可见。事务执行结束后，如果执行成功，将所有结果提交到内存中；如果执行失败，中止并取消所有结果。 实现方式： 软件事务内存：库函数或编程语言； 硬件事务内存：主要对多核处理器的Cache结构进行改造。例如Intel TSX新增了三条指令XBEGIN, XEND和XABORT，以Cache行为单位跟踪事务的读集和写集。 11.5 典型多核处理器 第12章 计算机系统评价和性能分析 性能最本质的定义：完成一个任务所需要的时间。 性能分析方法：分析、模拟、测量。 12.1 计算机系统性能评价指标 不同系统所关注的性能： 桌面计算机：大文件压缩、音视频播放…… Web服务器：每秒所完成的Web请求数，衡量指标是吞吐率（每秒完成的交易事务）。 高性能计算机：衡量指标是完成一个大的并行任务的速度。 影响性能的因素：应用（影响最大，不同系统各有所长各有所短）、算法、编译系统、指令系统、微结构（影响IPC、主频）、工艺（主要影响主频）。 常见性能指标：CPI、 MIPS、 MFLOPS、 TPS、 FPS、 MBPS、 MHz 名称 全称 含义 CPI Cycles Per Instruction 每条指令的时钟周期数 MIPS Millon Instructions Per Second 每秒执行百万条指令数 MFLOPS Mllion Floating Point Operations Per Second 每秒执行 百万浮点运算数 TPS Transactions Per Second 每秒执行的事务数 FPS Frames Per Second 每秒帧数 MBPS MB Per Second 每秒完成多少MB的访存操作，带宽的单位 MHz - 兆赫兹，主频的单位 CPU时间 = 指令数 × IPC × 主频 指令数：算法、编译器、ISA IPC：微结构、编译器、ISA 主频：微结构、工艺技术、逻辑设计（如串行进位和并行进位加法器）、物理设计（如动态电路的使用） 并行系统的评价指标：可扩展性、加速比。 阿姆达尔定律：系统中对某一部分改进后获得的整体性能提升程度，取决于部分被使用的频率，或所占总执行时间的比例。 12.2 测试程序集（黑盒法） 特点： 公平性：拿程序来测，看看实际性能表现，而不是只看个别技术指标。 侧重性：不同计算机侧重点不同，需要不同的测试程序。 全面性：测试程序要有代表性，覆盖面足够广。 公开性：测试报告要详细，便于查阅。 常见基准测试程序类型： 微基准测试程序：Sim-alpha的microbench, LMbench, STREAM, CoreMark, UnixBench等。 串行CPU基准测试程序：SPEC CPU, EEMBC。 并行CPU基准测试程序：SPLASH-2（测并行加速比）, PARSEC（测并行加速比）, Linpack（测并行浮点峰值）。 专项基准测试程序：SPEC jvm, SPEC jbb, SPECSFS, SPEC viewperf, TPC。 微（基准）测试程序：小的测试程序，能在短时间内跑完，可以用于处理器某些模块的专门优化。 12.3 性能分析方法（白盒法） 分类： 性能建模 分析建模：概率模型、队列模型、马尔可夫模型、Petri网模型。 模拟建模：踪迹驱动模拟、执行驱动模拟、全系统模拟、事件驱动模拟、统计方法模拟。 性能测量：片上硬件监测器（如性能计数器）、片外硬件监测器、软件监测器、微码插桩。 基于分析和统计的建模（分析建模）：基于对处理器结构和程序特性的分析，建立处理器的性能公式，通过数学公式计算出处理器的性能信息。 基于模拟的建模（模拟建模）：用高级语言编写模拟器，模拟CPU进行建模。是处理器设计中用得最为广泛的方法。 常用的模拟器：SimpleScalar, SimOS, GEM5, IBM的Mambo和Turandot, AMD的SimNow等。有两种分类： 系统模拟器和部件模拟器 全系统模拟器和用户态模拟器 模拟加速技术：在模拟速度和精度之间折中。代表性技术是采样模拟技术和统计模拟技术。 采样模拟技术：截取程序的一小部分进行模拟，近似代表整个程序的模拟结果。SMART：周期采样；SimPoint：采样能够代表每个相位的部分。 统计模拟技术：用统计方法分析工作负载，得出多种类型的统计信息，由此生成合成的程序踪迹，包含有工作负载抽象提炼出的信息，因此能在模拟器上很快地收敛。 模拟器和真实系统的绝对误差是无法避免的，但是模拟结果和真是系统的偏差是稳定的，可以用同一个模拟器模拟多个不同的系统来进行相对比较。 性能计数器的优势：可以统计复杂应用的行为，实时监测系统行为（模拟器办不到，只能运行简单的程序）。 Perf性能分析工具：集成在Linux系统中的性能分析工具，基于事件采样原理，采样硬件事件、软件事件、tracepoint触发的事件。 ","link":"https://kimokcheon.github.io/post/ji-suan-ji-ti-xi-jie-gou/"},{"title":"Python","content":"第1章 变量和简单数据类型 第一个Python程序： print(&quot;Hello world!&quot;) 只有一行，作用是打印输出“Hello world!”，语句末尾不要用分号。值得注意的是，print()函数打印完毕后自动换行，如果不想换行请使用end=&quot;&quot;编写： print(&quot;Hello world!&quot;, end=&quot;&quot;) 1.1 变量 变量定义格式：变量名 = 变量内容，如massage = 12。（注意，不需要指定数据类型） 1.2 数据类型 字符串 字符串用引号括起来，引号可以是单引号也可以是双引号。字符串之间可以使用+拼接。 方法调用格式：变量名.方法名(参数列表)。字符串常用方法如下： title()：使字符串中各单词首字母大写 upper()：使字符串字母全部大写 lower()：使字符串字母全部小写 rstrip()：删除字符串尾部的空白 lstrip()：删除字符串头部的空白 strip()：删除字符串首尾的空白 数字 除常见的加、减、乘、除、模运算外，Python还使用两个乘号**表示乘方运算，a ** b即为a的b次方。 使用str()方法避免类型错误： age = 23 # message = 'Happy' + age + 'rd birthday!' # 上面报错，因为Python不知道这里的age是想处理为数值还是字符。 message = 'Happy' + str(age) + 'rd birthday' 第2章 列表 2.1 列表是什么 列表和C语言中的数组比较相似。请见下例： # 定义列表 bicycles = ['trek', 'cannondale', 'redline', 'specialized'] # 打印列表 print(bicycles) # 访问列表元素 print(bicycles[0]) print(bicycles[-1].title()) 运行结果： ['trek', 'cannondale', 'redline', 'specialized'] trek Speciaized 列表的索引从0开始，比较特殊的是列表倒数第一个元素可以用-1来访问（如上例所示），倒数第二个用-2来访问，依次类推。 2.2 元素的修改、添加和删除 修改 直接修改即可，如 motorcycles = ['honda', 'yamaha', 'suzuki'] motorcycles[0] = 'ducati' print(motorcycles) 运行结果： ['honda', 'yamaha', 'suzuki'] ['ducati', 'yamaha', 'suzuki'] 添加 append(str)方法：将变量str添加到列表的最后。 insert(i, str)方法：将变量str添加到列表的索引i处。 删除 del语句：“del list[i]”可以删除列表list中索引i处的元素。 pop()方法：弹出列表中的最后一个元素，可以用一个变量来接收。 remove(str)：将第一次出现的值为str的元素删除。 2.3 组织列表 用sort()方法永久排序 sort()方法可以改变列表中元素的原始排列顺序，按字母序由a到z排列。添加参数reverse=True可改为倒序由z至a排列。 cars = ['bmw', 'audi', 'toyota', 'subaru'] cars.sort() print(cars) cars.sort(reverse=True) print(cars) 运行结果： ['audi', 'bmw', 'subaru', 'toyota'] ['toyota', 'subaru', 'bmw', 'audi'] 用sorted()方法临时排序 sorted()方法可返回排好序的列表，但不影响列表原始排列顺序。使用该方法时，要传入的参数是列表。 cars = ['bmw', 'audi', 'toyota', 'subaru'] print(&quot;Here is the original list:&quot;) print(cars) print(&quot;\\nHere is the sorted list:&quot;) print(sorted(cars)) print(&quot;\\nHere is the original list again:&quot;) print(cars) 运行结果： Here is the original list: ['bmw', 'audi', 'toyota', 'subaru'] Here is the sorted list: ['audi', 'bmw', 'subaru', 'toyota'] Here is the original list again: ['bmw', 'audi', 'toyota', 'subaru'] 用reverse()方法逆序打印列表 这个逆序打印是从后往前打印列表，而不是按照字母顺序倒序打印。它会永久改变列表元素的排列顺序。 cars = ['bmw', 'audi', 'toyota', 'subaru'] cars.reverse() print(cars) 运行结果： ['subaru', 'toyota', 'audi', 'bmw'] 用len()方法确定列表的长度 对于上例中的列表cars，len(cars)为4。 2.4 遍历列表 用for循环遍历列表： magicians = ['alice', 'david', 'carolina'] for magician in magicians: print(magician.title()+ &quot;, that was a great trick!&quot;) print(&quot;I can't wait to see your next trick, &quot;+ magician.title() +&quot;.\\n&quot;) print('Thank you, everyone. That was a great magic show!') 运行结果： Alice, that was a great trick! I can't wait to see your next trick, Alice. David, that was a great trick! I can't wait to see your next trick, David. Carolina, that was a great trick! I can't wait to see your next trick, Carolina. Thank you, everyone. That was a great magic show! 注意，Python对缩进有很严格的要求。for循环:后指示循环体，循环体必须另起一行且缩进，循环体结束的标志是下一行不缩进（即与for循环首行对齐）。 2.5 创建数值列表 2.5.1 range()函数 Python函数range()可以生成一系列的数字，如： for value in range(1, 5): print(value) 运行结果： 1 2 3 4 注意到上面没有打印数字5，range打印的参数范围是左闭右开的，是常见的差一行为。 可以用range()函数来创建一个列表： numbers = list(range(1, 5)) print(numbers) 运行结果： [1, 2, 3, 4] 使用range()时还可以在最后一个参数指定步长。如下例： numbers = list(range(2, 11, 2)) print(numbers) 运行结果： [2, 4, 6, 8, 10] 2.5.2 简单的统计计算 min(list)：返回列表list的最小元素的值。 max(list)：返回列表list的最大元素的值。 sum(list)：返回列表list的各元素值的和。 2.5.3 列表解析 将for循环和创建新元素的代码合并成一行，并自动附加新元素： square = [value**2 for value in range(1, 11)] print(square) 运行结果： [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 2.6 使用列表的一部分：切片 2.6.1 切片的使用 切片使用示例： players = ['charles', 'martina', 'michael', 'florence', 'eli'] print(players[0:3]) print(players[1:4]) print(players[:4]) print(players[2:]) print(players[-3:]) 运行结果： ['charles', 'martina', 'michael'] ['martina', 'michael', 'florence'] ['charles', 'martina', 'michael', 'florence'] ['michael', 'florence', 'eli'] ['michael', 'florence', 'eli'] 注意依然是左闭右开，与range()一样，除非右边没有写数。 2.6.2 切片的遍历 players = ['charles', 'martina', 'michael', 'florence', 'eli'] for player in players[:3]: print(player.title()) 运行结果： Charles Martina Michael 2.6.3 用切片实现列表的复制 现有列表a，想把它的内容原封不动复制给列表b，可以这样写：b = a[:]。因为切片创建的是列表的副本，所以b和a是两个不同的列表。倘若这样写：b = a，那么b和a是同一个列表，对这个列表的操作会同时影响a和b的内容。请见下例： my_foods = ['pizza', 'falafel', 'carrot cake'] friend_foods = my_foods # 事实上是让Python将新变量friend_foods关联到包含在my_foods中的列表 # 因此这两个变量都指向同一个列表 my_foods.append('cannoli') friend_foods.append('ice cream') print(&quot;My favorite foods are:&quot;) print(my_foods) print(&quot;\\nMy friend's favorite foods are:&quot;) print(friend_foods) 运行结果： My favorite foods are: ['pizza', 'falafel', 'carrot cake', 'cannoli', 'ice cream'] My friend's favorite foods are: ['pizza', 'falafel', 'carrot cake', 'cannoli', 'ice cream'] 2.7 元组 元组就是不可变的列表，列表中的元素的值不可修改。元组用圆括号来定义：dimensions = (200, 50)，除值不可变外其余操作与列表用法一致。 值得注意的是，虽然元组中某个元素的值不可修改，但是整个元组可重新定义： dimensions = (200, 50) print('Original dimensions:') for dimension in dimensions: print(dimension) dimensions = (400, 100) print('\\nModified dimensions:') for dimension in dimensions: print(dimension) 运行结果： Original dimensions: 200 50 Modified dimensions: 400 100 第3章 if语句 3.1 条件测试 一个普通的含有if的程序： cars=['audi', 'bmw', 'subaru', 'toyota'] for car in cars: if car == 'bmw': print(car.upper()) else: print(car.title()) 运行结果： Audi BMW Subaru Toyota if后面跟的条件表达式被称为条件测试。注意逻辑关系“与”和“或”分别用and和or表示，其余的逻辑表达式编写都与C语言相同。 另外，in和not in用于检查某元素是否在特定列表中，请见下例： requested_toppings = ['mushrooms', 'onions', 'pineapple'] print('mushrooms' in requested_toppings) print('pineapple' not in requested_toppings) 运行结果： True False 3.2 if语句的结构 常用的是if-elif-else结构，其中可以不写else分支。 age = 12 if age &lt; 4: price = 0 elif age &lt; 18: price = 5 else: price = 10 print(&quot;Your admission cost is $&quot;+str(price)+&quot;.&quot;) 运行结果： Your admission cost is $5. 第4章 字典 4.1 字典的定义 字典是一系列键值对的集合，可以使用键来访问其对应的值。字典用大括号定义： alien_0 = {'color': 'green', 'points': 5} print(alien_0['color']) print(alien_0['points']) 运行结果： green 5 字典也可以用多行定义： favorite_languages = { 'jen': 'python', 'sarah': 'c', 'edward': 'ruby', 'phil': 'python', # 这里可以加逗号也可以不加，但是为以后添加键值对方便，最好加一个逗号 } print(&quot;Sarah's favorite language is &quot;+ favorite_languages['sarah'].title()+'.') 运行结果： Sarah's favorite language is C. 4.2 键值对的添加、修改和删除 添加、修改键值对：直接添加、修改即可。 alien_0 = {'color': 'green', 'points': 5} print(alien_0) # 添加键值对 alien_0['x_position']=0 alien_0['y_position']=25 print(alien_0) # 修改键值对 alien_0['color']='yellow' print(alien_0) 运行结果： {'color': 'green', 'points': 5} {'color': 'green', 'points': 5, 'x_position': 0, 'y_position': 25} {'color': 'yellow', 'points': 5, 'x_position': 0, 'y_position': 25} 删除键值对：del语句 alien_0 = {'color': 'green', 'points': 5} print(alien_0) # 删除键值对 del alien_0['points'] print(alien_0) 运行结果： {'color': 'green', 'points': 5} {'color': 'green'} 4.3 遍历字典 字典中的items()方法代表键值对，keys()方法代表键，values()方法代表值。 favorite_languages = { 'jen': 'python', 'sarah': 'c', 'edward': 'ruby', 'phil': 'python', } # 遍历键值对 for name, language in favorite_languages.items(): print(name.title() + &quot;'s favorite language is &quot; + language.title() + &quot;.&quot;) # 遍历键 print('--------------------') for name in favorite_languages.keys(): print(name.title()) # 遍历值 print('--------------------') for language in favorite_languages.values(): print(language.title()) 运行结果： Jen's favorite language is Python. Sarah's favorite language is C. Edward's favorite language is Ruby. Phil's favorite language is Python. -------------------- Jen Sarah Edward Phil -------------------- Python C Ruby Python 有时候我们希望按一定顺序遍历键，sorted()方法可按字母顺序遍历所有键。 有时候我们希望遍历值的时候剔除重复的值，set()方法可以剔除重复值。 下面的例子用到了sorted()和set()方法： favorite_languages = { 'jen': 'python', 'sarah': 'c', 'edward': 'ruby', 'phil': 'python', } for name in sorted(favorite_languages.keys()): print(name.title()+&quot;, thank you for taking the poll.&quot;) print('--------------------') for language in set(favorite_languages.values()): print(language.title()) 运行结果： Edward, thank you for taking the poll. Jen, thank you for taking the poll. Phil, thank you for taking the poll. Sarah, thank you for taking the poll. -------------------- Python Ruby C 4.4 嵌套 4.4.1 字典列表 字典可以作为列表的元素，如： aliens = [alien_0, alien_1, alien_2] 这里alien_0, alien_1, alien_2都是字典。 我们也可以使用range()来创建包含多个字典的列表： aliens = [] for alien_number in range(30): new_alien = {'color': 'green', 'points': 5, 'speed': 'slow', 'num': alien_number} aliens.append(new_alien) 4.4.2 在字典中存储列表 pizza = { 'crust': 'thick', 'toppings': ['mushrooms', 'extra cheese'], } print(&quot;You ordered a &quot; + pizza['crust'] + &quot;-crust pizza &quot; + &quot;with the following toppings:&quot;) for topping in pizza['toppings']: print('\\t' + topping) 运行结果： You ordered a thick-crust pizza with the following toppings: mushrooms extra cheese 4.4.3 在字典中存储字典 users = { 'aeinstein': { 'first': 'albert', 'last': 'einstein', 'location': 'princeton', }, 'mcurie': { 'first': 'marie', 'last': 'curie', 'location': 'paris', }, # 一般要求这些字典格式一致 } for username, user_info in users.items(): print(&quot;\\nUsername: &quot; + username) full_name = user_info['first'] + &quot; &quot; + user_info['last'] location = user_info['location'] print('\\tFull name: ' + full_name.title()) print('\\tLocation: ' + location.title()) 运行结果： Username: aeinstein Full name: Albert Einstein Location: Princeton Username: mcurie Full name: Marie Curie Location: Paris 第5章 用户输入和while循环 5.1 用户输入input() 函数input(str)会在屏幕上打印字符串str，然后等待用户输入。用户输入的内容被看作字符串，作为其返回值。 prompt = &quot;If you tell us who you are, we can personalize the messages you see.&quot; prompt += &quot;\\nWhat is your first name? &quot; name = input(prompt) print(&quot;Hello, &quot; + name + &quot;!&quot;) 运行结果（反引号``内为键盘输入内容）： If you tell us who you are, we can personalize the messages you see. What is your first name? `Eric` Hello, Eric! 注意，用户输入内容会被解读成字符串，想要作为其它数据类型使用则需要进行类型转换： age = input (&quot;How old are you? &quot;) age = int(age) print(age &gt;= 18) 运行结果： How old are you? `12` False 5.2 while循环 while循环和多数高级语言思想是一样的，我们来看一个使用while循环在列表之间移动元素的例子： unconfirmed_users = ['alice', 'brian', 'candace'] confirmed_users = [] while unconfirmed_users: current_user = unconfirmed_users.pop() print(&quot;Verifying user: &quot; + current_user.title()) confirmed_users.append(current_user) print(&quot;\\nThe following users have been confirmed:&quot;) for confirmed_user in confirmed_users: print(confirmed_user.title()) 运行结果： Verifying user: Candace Verifying user: Brian Verifying user: Alice The following users have been confirmed: Candace Brian Alice Python中也有break语句和continue语句，其用法与C语言是一致的。 第6章 函数 6.1 函数的定义 def greet_user(username): &quot;&quot;&quot;显示简单的问候语&quot;&quot;&quot; print(&quot;Hello, &quot; + username.title() + &quot;!&quot;) greet_user('jesse') 运行结果： Hello, Jesse! 这里三引号中的内容被称为文档字符串，描述了函数是做什么的。Python使用它们来生成有关程序中函数的文档。 6.2 函数的参数 我们首先定义一个函数describe_pet： def describe_pet(animal_type, pet_name): &quot;&quot;&quot;显示宠物的信息&quot;&quot;&quot; print(&quot;\\nI have a &quot; + animal_type + &quot;.&quot;) print(&quot;My &quot; + animal_type + &quot;'s name is &quot; + pet_name.title() + &quot;.&quot;) 调用函数时，需要传递参数。传参有两种方式，分别是位置实参和关键字实参： # 位置实参 describe_pet('hamster', 'harry') describe_pet('dog', 'willie') # 关键字实参 print('-----------------') describe_pet(animal_type='hamster', pet_name='harry') describe_pet(pet_name='willie', animal_type='dog') 运行结果： I have a hamster. My hamster's name is Harry. I have a dog. My dog's name is Willie. ----------------- I have a hamster. My hamster's name is Harry. I have a dog. My dog's name is Willie. 看代码就知道这两种传参方式的异同了，注意关键字实参就不需要实参与形参的位置一一对应了。 有时候，一个函数中某个参数常常是某值，我们就可以把它设为默认值，这样当不给这个参数传参时，这个参数就取默认值。具体请见下例： def describe_pet(pet_name, animal_type='dog'): # 这里最后一个参数的默认值为'dog'，如果主程序中没有给animal_type传参，就默认它的值为'dog' &quot;&quot;&quot;显示宠物的信息&quot;&quot;&quot; print(&quot;\\nI have a &quot; + animal_type + &quot;.&quot;) print(&quot;My &quot; + animal_type + &quot;'s name is &quot; + pet_name.title() + &quot;.&quot;) describe_pet('willie') # 这里使用位置实参，因此pet_name置于前部 describe_pet('willie', 'cat') describe_pet(pet_name='harry', animal_type='hamster') 运行结果： I have a dog. My dog's name is Willie. I have a cat. My cat's name is Willie. I have a hamster. My hamster's name is Harry. 列表也可以作为参数进行传递。 可以传递任意数量的参数，仅需在参数前面加上*即可： def make_pizza(*toppings): &quot;&quot;&quot;概述要制作的比萨&quot;&quot;&quot; print(&quot;\\nMaking a pizza with the following toppings:&quot;) for topping in toppings: print(&quot;- &quot; + topping) make_pizza('pepperoni') make_pizza('mushrooms', 'green peppers', 'extra cheese') 运行结果： Making a pizza with the following toppings: - pepperoni Making a pizza with the following toppings: - mushrooms - green peppers - extra cheese *toppings中的*让Python创建一个名为toppings的空元组，并将收到的所有值都封装到这个元组中，这样可以传入任意多数量的参数。 有时候，需要接受任意数量的实参，但预先不知道传递给参数的会是什么样的信息。这时可将函数编写成能够接受任意数量的键值对，调用语句提供多少就接受多少，用两个星号即可： def build_profile(first, last, **user_info): &quot;&quot;&quot;创建一个字典，其中包含我们知道的有关用户的一切&quot;&quot;&quot; profile = {} profile['first_name'] = first profile['last_name'] = last for key, value in user_info.items(): profile[key] = value return profile user_profile = build_profile('albert', 'einstein', location='princeton', field='physics') print(user_profile) 运行结果： {'first_name': 'albert', 'last_name': 'einstein', 'location': 'princeton', 'field': 'physics'} 6.3 函数的返回值 用return来返回函数的返回值。主程序中一般应有变量接收返回值。 def add(a, b): &quot;&quot;&quot;对a和b求和&quot;&quot;&quot; return a+b sum = add(1, 2) print(sum) 运行结果： 3 6.4 将函数保存到模块中 假设模块pizza.py中编写了如下的代码： # pizza.py def make_pizza(size, *toppings): &quot;&quot;&quot;概述要制作的比萨&quot;&quot;&quot; print(&quot;\\nMaking a &quot; + str(size) + &quot;-inch pizza with the following toppings:&quot;) for topping in toppings: print(&quot;- &quot; + topping) 我们在pizza.py所在的目录中另建一个文件，不妨取名为making_pizza.py。这个文件要导入模块pizza.py并使用其中的函数。 下面几个代码的运行结果均为 Making a 16-inch pizza with the following toppings: - pepperoni Making a 12-inch pizza with the following toppings: - mushrooms - green peppers - extra cheese （1）导入整个模块 import 模块名 # making_pizza.py import pizza pizza.make_pizza(16, 'pepperoni') pizza.make_pizza(12,'mushrooms', 'green peppers', 'extra cheese') （2）导入模块中的特定函数 from 模块名 import 函数名1, 函数名2, ... # making_pizza.py from pizza import make_pizza make_pizza(16, 'pepperoni') make_pizza(12, 'mushrooms', 'green peppers', 'extra cheese') 注：使用*可以导入模块中的全部函数，如from pizza import *，但不建议这样做。 （3）使用as可以为函数指定别名 from 模块名 import 函数名 as 别名 # making_pizza.py from pizza import make_pizza as mp mp(16, 'pepperoni') mp(12,'mushrooms', 'green peppers', 'extra cheese') 第7章 类 7.1 创建和使用类 7.1.1 创建类 下面创建一个名为Dog的类： class Dog(): &quot;&quot;&quot;一次模拟小狗的简单尝试&quot;&quot;&quot; def __init__(self, name, age): &quot;&quot;&quot;初始化属性name和age&quot;&quot;&quot; self.name=name self.age=age def sit(self): &quot;&quot;&quot;模拟小狗被命令时坐下&quot;&quot;&quot; print(self.name.title() + &quot; is now sitting.&quot;) def roll_over(self): &quot;&quot;&quot;模拟小狗被命令时打滚&quot;&quot;&quot; print(self.name.title() + &quot; rolled over!&quot;) 注意两点： self前缀：类似于java中的this关键字。以self为前缀的变量可以供类中的所有方法使用，也可以通过类的任何实例来访问这些变量，它们被称为类的属性。编写方法时，应当传入self参数，类中的方法通过self.属性名来访问和修改属性。 __init__ 方法：相当于java中的构造方法，用来对属性进行初始化。后面创建实例时会用到。 7.1.2 创建实例 类由属性和方法构成。类编写好后，大部分时间都将花在使用根据类创建的实例上。下面的语句将由Dog类创建两个实例my_dog和your_dog： my_dog = Dog('willie', 6) your_dog = Dog('lucy', 3) 创建实例时，传入的参数是__init__方法中的参数列表（除self外）。 7.1.3 调用方法 类由属性和方法构成。因此实例也主要涉及对属性和方法的操作。调用方法的方式为：实例名.方法名(参数)。下面的语句将调用Dog类中的sit()和roll()方法。 my_dog.sit() your_dog.roll() 运行结果: Willie is now sitting. Lucy rolled over! 7.1.4 访问和修改属性 访问属性 想知道类的属性的值，可以用实例名.属性来访问属性的值。 print(&quot;My dog's name is &quot; + my_dog.name.title() + &quot;.&quot;) print(&quot;Your dog is &quot; + str(your_dog.age) + &quot; years old.&quot;) 运行结果： My dog's name is Willie. Your dog is 3 years old. 给属性指定默认值 我们新建一个名为Car的类，并为其中的odometer_reading属性指定默认值： class Car(): &quot;&quot;&quot;一次模拟汽车的简单尝试&quot;&quot;&quot; def __init__(self, make, model, year): &quot;&quot;&quot;初始化描述汽车的属性&quot;&quot;&quot; self.make = make self.model = model self.year = year # 为属性odometer_reading指定默认值（这样便无需传入包含初始值的形参） self.odometer_reading = 0 def get_descriptive_name(self): &quot;&quot;&quot;返回整洁的描述性信息&quot;&quot;&quot; long_name = str(self.year) + &quot; &quot; + self.make + &quot; &quot; + self.model return long_name.title() def read_odometer(self): &quot;&quot;&quot;打印一条指出汽车里程的信息&quot;&quot;&quot; print(&quot;This car has &quot; + str(self.odometer_reading) + &quot; mile(s) on it.&quot;) 它有四个属性，三个方法（含__init__()方法）。其中odometer_reading属性默认值为0。 修改属性 我们将修改odometer_reading属性，这可以直接在实例中修改，也可以创建一个方法专门用来修改。 （1）直接修改 my_new_car = Car('audi', 'a4', 2016) # 创建实例my_new_car my_new_car.odometer_reading = 23 # 直接修改属性 my_new_car.read_odometer() # 打印指出汽车里程的信息 （2）创建方法用来修改属性 我们在类中创建一个方法update_odometer()： def update_odometer(self, mileage): &quot;&quot;&quot; 将里程表读数设置为指定的值 禁止将里程表读数往回调 &quot;&quot;&quot; if mileage &gt;= self.odometer_reading: self.odometer_reading = mileage else: print(&quot;You can't roll back an odometer!&quot;) 可以通过这个方法来修改属性的值： my_new_car.update_odometer(200) my_new_car.read_odometer() 7.2 继承 7.2.1 继承 一个类继承另一个类时，它会获得另一个类的所有属性和方法。原有的类被称为父类，新的类被称为子类。 继承的语法：class 子类名(父类名):。继承的类调用父类中的方法时，用super()来指代父类。例如，对于上面的Car类，我们想写一个ElectricCar类来继承它，同时为它添加特有的属性battery_size和特有的方法describe_battery()： class ElectricCar(Car): &quot;&quot;&quot;电动汽车的独特之处&quot;&quot;&quot; def __init__(self, make, model, year): &quot;&quot;&quot; 电动汽车的独特之处 初始化父类的属性，再初始化电动汽车特有的属性 &quot;&quot;&quot; super().__init__(make, model, year) self.battery_size = 70 def describe_battery(self): &quot;&quot;&quot;打印一条描述电瓶容量的消息&quot;&quot;&quot; print(&quot;This car has a &quot; + str(self.battery_size) + &quot;-kWh battery.&quot;) 7.2.2 方法重写 继承的一大目的就是重写父类中的某些方法。例如，假设父类中有方法fill_gas_tank()： # 在Car类中 def fill_gas_tank(self): &quot;&quot;&quot;为油箱加油&quot;&quot;&quot; print(&quot;The gas tank has been filled up!&quot;) 而电动汽车不需要加油，因此可以在ElectricCar类中重写这个方法： # 在ElectricCar类中 def fill_gas_tank(self): &quot;&quot;&quot;电动汽车没有邮箱&quot;&quot;&quot; print(&quot;This car doesn't need a gas tank!&quot;) 7.2.3 将实例用作属性 有时候类的细节很多，可以将类的一部分提取出来，作为一个独立的类，然后将在原有的大类中写一个新的小类的实例，作为大类的一个属性。本质上还是新定义一个属性，只不过这个属性的数据类型是原有的类。 例如，我们可以给ElectricCar类中添加一个Battery类的实例： class Car(): ... class Battery(): &quot;&quot;&quot;一次模拟电动汽车电瓶的简单尝试&quot;&quot;&quot; def __init__(self, battery_size=70): &quot;&quot;&quot;初始化电瓶的属性&quot;&quot;&quot; self.battery_size = battery_size def describe_battery(self): &quot;&quot;&quot;打印一条描述电瓶容量的信息&quot;&quot;&quot; print(&quot;This car has a &quot; + str(self.battery_size) + &quot;-kWh battery.&quot;) class ElectricCar(Car): &quot;&quot;&quot;电动汽车的独特之处&quot;&quot;&quot; def __init__(self, make, model, year): &quot;&quot;&quot; 电动汽车的独特之处 初始化父类的属性，再初始化电动汽车特有的属性 &quot;&quot;&quot; super().__init__(make, model, year) self.battery = Battery() 编写如下代码： my_tesla = ElectricCar('tesla', 'model s', 2016) print(my_tesla.get_descriptive_name()) my_tesla.battery.describe_battery() 运行结果为： 2016 Tesla Model S This car has a 70-kWh battery. 7.3 将类保存到模块中 7.3.1 创建包含多个类的模块 建立一个名为car.py的模块，其中保存多个类： # car.py &quot;&quot;&quot;一组用于表示燃油汽车和电动汽车的类&quot;&quot;&quot; # 模块级文档字符串，简述模块内容 class Car(): &quot;&quot;&quot;一次模拟汽车的简单尝试&quot;&quot;&quot; def __init__(self, make, model, year): &quot;&quot;&quot;初始化描述汽车的属性&quot;&quot;&quot; self.make = make self.model = model self.year = year self.odometer_reading = 0 def get_descriptive_name(self): &quot;&quot;&quot;返回整洁的描述性名称&quot;&quot;&quot; long_name = str(self.year) + &quot; &quot; + self.make + &quot; &quot; + self.model return long_name.title() def read_odometer(self): &quot;&quot;&quot;打印一条消息，指出汽车的里程&quot;&quot;&quot; print(&quot;This car has &quot; + str(self.odometer_reading) + &quot; mile(s) on it.&quot;) def update_odometer(self, mileage): &quot;&quot;&quot; 将里程表读数设置为指定的值 拒绝将里程表往回拨 &quot;&quot;&quot; if mileage &gt;= self.odometer_reading: self.odometer_reading = mileage else: print(&quot;You can't roll back an odometer!&quot;) def increment_odometer(self, miles): &quot;&quot;&quot;将里程表读数增加指定的量&quot;&quot;&quot; self.odometer_reading += miles class Battery(): &quot;&quot;&quot;一次模拟电动汽车电瓶的简单尝试&quot;&quot;&quot; def __init__(self, battery_size=70): &quot;&quot;&quot;初始化电瓶的属性&quot;&quot;&quot; self.battery_size = battery_size def describe_battery(self): &quot;&quot;&quot;打印一条描述电瓶容量的消息&quot;&quot;&quot; print(&quot;This car has a &quot; + str(self.battery_size) + &quot;-kWh battery.&quot;) def get_range(self): &quot;&quot;&quot;打印一条描述电瓶续航里程的消息&quot;&quot;&quot; if self.battery_size == 70: range = 240 elif self.battery_size == 85: range = 270 message = &quot;This car can go approximately &quot; + str(range) message += &quot; miles on a full range.&quot; print(message) class ElectricCar(Car): &quot;&quot;&quot;模拟电动汽车的独特之处&quot;&quot;&quot; def __init__(self, make, model, year): &quot;&quot;&quot; 初始化父类的属性，再初始化电动汽车特有的属性 &quot;&quot;&quot; super().__init__(make, model, year) self.battery = Battery() 7.3.2 从模块中导入类 有两种导入方式： （1）从模块中导入特定的类 from 模块名 import 类名1, 类名2, ... 实例化时仅需说明实例属于哪个类即可，例如 from car import Car, ElectricCar my_beetle = Car('volkswagen', 'beetle', 2016) print(my_beetle.get_descriptive_name()) my_tesla = ElectricCar('tesla', 'roadster', 2016) print(my_tesla.get_descriptive_name()) 注：使用*可以导入模块中的全部类，如from car import *，但不建议这样做。 （2）导入整个模块 import 模块名 实例化时需要用模块名.类名(属性值列表)的方式，例如 import car my_beetle = car.Car('volkswagen', 'beetle', 2016) print(my_beetle.get_descriptive_name()) my_tesla = car.ElectricCar('tesla', 'roadster', 2016) print(my_tesla.get_descriptive_name()) 最后，也可以在一个模块中导入另一个模块。导入方式即为上面提到的两种方式。 7.3.3 Python标准库 Python标准库是一组模块，安装的Python都包含它，只需要在程序的开头包含一条简单的import语句即可使用标准库中的函数和类。 第8章 文件和异常 8.1 读取文件 这一小节中用到两个文件，一个文件是pi_digits.txt，一个文件是pi_million_digits.txt。它们均保存在与本小节编程文件相同的目录下。可点击下面两个链接下载这两个文件。 pi_digits.txt pi_million_digits.txt 8.1.1 读取全部文件内容 下面的代码会打开并读取pi_digits.txt文件，并将其内容显示到屏幕上。 # file_reader.py with open('pi_digits.txt') as file_object: # 打开文件 contents = file_object.read() # 读取文件 print(contents.rstrip()) # 打印文件内容 运行结果： 3.1415926535 8979323846 2643383279 分析程序代码： open()函数：参数为要打开的文件的相对路径或绝对路径，返回一个表示文件的对象。使用as为这个对象指定别名file_object。 with关键字：它可以在不再需要访问文件后将其关闭。关闭时机由Python自动确定。 也可以不用with关键字，使用open()和close()函数配合来打开和关闭文件，但这样如果程序出现bug可能会导致close()函数得不到调用，从而造成数据丢失，因此不建议这样做。 read()函数：文件对象的一个方法，读取这个文件的内容，并将内容作为字符串返回。 空行处理：read()函数到达文件末尾时自动返回一个空字符串，打印时作为空行打印，这样输出的结果就比原文件多了一个空行。因此使用rstrip()方法删除字符串末尾的空白符。 当使用其它目录下的文件时，注意在windows系统中文件路径使用反斜线(\\)，在Linux和OS X中使用斜线(/)。 8.1.2 逐行读取文件内容 可对文件对象使用for循环来遍历文件的每一行： # file_reader.py filename = 'pi_digits.txt' with open(filename) as file_object: for line in file_object: print(line.rstrip()) 运行结果： 3.1415926535 8979323846 2643383279 这里要注意，逐行读取时依然有空行处理，处理的原理和方式与上面相同。 8.1.3 创建包含文件各行内容的列表 使用with关键字时，open()返回的文件对象只能在with代码块内使用，因此需要有适当的变量来存储文件内容。可使用函数readlines()将文件各行的内容存储在一个列表中： filename = 'pi_million_digits.txt' with open(filename) as file_object: lines = file_object.readlines() pi_string = '' for line in lines: pi_string += line.strip() print(pi_string[:52] + &quot;...&quot;) print(len(pi_string)) 运行结果： 3.14159265358979323846264338327950288419716939937510... 100002 8.2 写入文件 下面的程序将创建名为programming.txt的文件，并在其中写入一句话I love programming.： filename = 'programming.txt' with open(filename, 'w') as file_object: file_object.write(&quot;I love programming.&quot;) 我们来看这段代码中的两个函数： open()函数：在open()函数中，第一个参数表示要打开的文件，如果文件不存在，则新建该文件。 第二个参数表示文件的打开模式，'r'表示以读取模式打开，'r'表示以写入模式打开，'a'表示以附加模式打开。 值得注意的是，以写入模式打开文件后，文件对象中的内容会被清空，因此后面写入的内容会完全覆盖原文件的内容。如果想要保留原来的内容，承接在原内容之后写入内容，则应当使用附加模式打开。 write()函数：文件对象.write(str)会在指定的文件对象中写入字符串str。需要注意两点：① str必须为字符串，如果是数值，请用str()转换数据类型；② write()函数写入字符串后不会换行，想换行请手动添加'\\n'。 8.3 异常 8.3.1 使用try-except-else代码块处理异常 一个常见的错误是，除数为零。这时程序会抛出ZeroDivisionError，并终止运行。如果我们能在代码中提前告诉Python发生这种异常时应该怎么办，就有备无患了： try: print(5/0) except ZeroDivisionError: print(&quot;You can't divide by zero!&quot;) 运行结果： You can't divide by zero! 这时try-except代码块，使用它处理异常的好处：首先，错误提示很友好，不是traceback；其次，如果后面还有代码，程序将继续运行。即，我们可以使用异常避免崩溃。 避免崩溃而出现traceback有两个好处：首先，不懂得技术的用户看到traceback会感到迷惑，而看到友好的错误提示信息；其次，懂得技术的程序员看到traceback中包含了许多与源代码相关的信息，这可以被用来展开攻击，隐藏traceback在避免攻击中显得尤为重要。 print(&quot;Give me two numbers, and I'll divide them.&quot;) print(&quot;Enter 'q' to quit.&quot;) while True: first_number = input(&quot;\\nFirst number: &quot;) if first_number == 'q': break second_number = input(&quot;second number: &quot;) if second_number == 'q': break try: answer = int(first_number) / int(second_number) except ZeroDivisionError: print(&quot;You can't divide by zero!&quot;) else: print(answer) try-except-else大致的原理是，运行try中的代码块，如果出现了except后面提到的异常，执行except代码块中的内容，如果没有抛出异常，执行else代码块中的内容。这段完成后继续执行后面的程序。 如果try中的代码块抛出异常，但不是except后面跟的异常，就会出现traceback并崩溃。 8.3.2 处理FileNotFoundError异常 上面提到了ZeroDivisionError，还有一种异常是FileNotFoundError，它发生在尝试打开一个文件而该文件不存在时。例如，假设当前目录中不存在alice.txt文件，那么执行下面的代码： filename = 'alice.txt' with open(filename) as f_obj: contents = f_obj.read() 会抛出一个含FileNotFoundError异常的trackback。为避免这一点，我们可以将with代码块放入try-except-else语句中。我们下面试图写一个程序，它能计算一个文本中含有多少个单词，为此先介绍split()函数： split()函数可以将指定的字符串按空白符分隔成一个个单词，将这些单词保存到一个列表中并返回。例如， title = &quot;Alice's adventures in wonderland&quot; print(title.split()) 运行结果： [&quot;Alice's&quot;, 'adventures', 'in', 'wonderland'] 我们要计算这几本书的单词数（点击链接可下载）： alice.txt (Alice's Adventures in Wonderland) moby_dick.txt (Moby Dick) little_women.txt (Little Women) 还有一本并没有下载的书siddhartha.txt。 代码如下： def count_words(filename): &quot;&quot;&quot;计算一个文件大致包含多少个单词&quot;&quot;&quot; try: with open(filename) as f_obj: contents = f_obj.read() except FileNotFoundError: print(&quot;Sorry, the file &quot; + filename + &quot; does not exist.&quot;) else: # 计算文件大致包含多少个单词 words = contents.split() num_words = len(words) print(&quot;The file &quot; + filename + &quot; has about &quot; + str(num_words) + &quot; words.&quot;) filenames = ['alice.txt', 'siddhartha.txt', 'moby_dick.txt', 'little_women.txt'] for filename in filenames: count_words(filename) 运行结果： The file alice.txt has about 26436 words. Sorry, the file siddhartha.txt does not exist. The file moby_dick.txt has about 214422 words. The file little_women.txt has about 187000 words. 下面介绍pass语句。我们将except代码块修改为 ... except FileNotFoundError: pass ... 这时遇到FileNotFoundError异常时程序便会“一声不吭”，继续执行，运行结果变为： The file alice.txt has about 26436 words. The file moby_dick.txt has about 214422 words. The file little_women.txt has about 187000 words. 8.4 存储数据 我们使用标准库中的json模块来实现数据的存储。用到其中的两个方法，dump()和load()，前者将内容存储到文件中，后者加载文件内容。 例如，我们想存一串数字列表到文件numbers.json中，便于另外的进程调用，可以用dump()方法实现： import json numbers = [2, 3, 5, 7, 11, 13] filename = 'numbers.json' with open(filename, 'w') as f_obj: json.dump(numbers, f_obj) 该段代码新建了一个名为numbers.json的文件，并将[2, 3, 5, 7, 11, 13]存入其中。 现在我们想调用储存的数字列表，可以用load()方法实现： import json filename = 'numbers.json' with open(filename) as f_obj: numbers = json.load(f_obj) print(numbers) 运行结果： [2, 3, 5, 7, 11, 13] 第9章 测试代码 9.1 测试函数 假设我们有模块name_function.py： def get_formatted_name(first, last, middle=''): &quot;&quot;&quot;Generate a neatly formatted full name.&quot;&quot;&quot; if middle: full_name = first + ' ' + middle + ' ' + last else: full_name = first + ' ' + last return full_name.title() 用以下代码测试该模块中给出的函数的正确性： import unittest from name_function import get_formatted_name class NamesTestCase(unittest.TestCase): &quot;&quot;&quot;测试name_function.py&quot;&quot;&quot; def test_first_last_name(self): &quot;&quot;&quot;能够正确地处理像Janis Joplin这样的姓名吗？&quot;&quot;&quot; formatted_name = get_formatted_name('janis', 'joplin') self.assertEqual(formatted_name, 'Janis Joplin') def test_first_middle_last_name(self): &quot;&quot;&quot;能够正确地处理像Wolfgang Amadeus Mozart这样的姓名吗？&quot;&quot;&quot; formatted_name = get_formatted_name('wolfgang', 'mozart', 'amadeus') self.assertEqual(formatted_name, 'Wolfgang Amadeus Mozart') 导入unittest模块，它能提供代码测试工具。 创建一个类NamesTestCase，继承unittest.TestCase类。 所有以test_打头的方法都将自动运行。上例中每个test_方法都能用来测试函数get_formatted_name()的一个方面。 unittest类最有用的功能：断言方法。这里用到的是assertEqual()。它能比较传入的两个字符串是否相同。 9.2 测试类 有6个常用的断言方法： 方法 用途 assertEqual(a, b) 核实 a == b assertNotEqual(a, b) 核实 a != b assertTrue(x) 核实x为True assertFalse(x) 核实x为False assertIn(item, list) 核实item在list中 assertNotIn(item, list) 核实item不在list中 测试类与测试函数基本一致，用到上述断言方法测试类的功能。 unittest.TestCase类还提供了一个setUp()方法，可以用它来提高效率。假设模块survey.py中有类AnonymousSurvey： class AnonymousSurvey(): &quot;&quot;&quot;收集匿名调查问卷的答案&quot;&quot;&quot; def __init__(self, question): &quot;&quot;&quot;存储一个问题，并为存储答案做准备&quot;&quot;&quot; self.question = question self.responses = [] def show_question(self): &quot;&quot;&quot;显示调查问卷&quot;&quot;&quot; print(self.question) def store_response(self, new_response): &quot;&quot;&quot;存储单份调查答卷&quot;&quot;&quot; self.responses.append(new_response) def show_results(self): &quot;&quot;&quot;显示收集到的所有答卷&quot;&quot;&quot; print(&quot;Survey results:&quot;) for response in self.responses: print('- ' + response) 我们可以用setUp()方法先创建一个问题和一份回答，供后面的测试方法使用。 # test_survey.py import unittest from survey import AnonymousSurvey class TestAnonymousSurvey(unittest.TestCase): &quot;&quot;&quot;针对AnonymousSurvey类的测试&quot;&quot;&quot; def setUp(self): &quot;&quot;&quot; 创建一个调查对象和一组答案，供使用的测试方法使用 &quot;&quot;&quot; question = &quot;What language did you first learn to speak?&quot; self.my_survey = AnonymousSurvey(question) self.responses = ['English', 'Spanish', 'Mandarin'] def test_store_single_response(self): &quot;&quot;&quot;测试单个答案会被妥善地存储&quot;&quot;&quot; self.my_survey.store_response(self.responses[0]) self.assertIn('English', self.my_survey.responses) def test_store_three_responses(self): &quot;&quot;&quot;测试三个答案会被妥善地存储&quot;&quot;&quot; for response in self.responses: self.my_survey.store_response(response) for response in self.responses: self.assertIn(response, self.my_survey.responses) ","link":"https://kimokcheon.github.io/post/python/"},{"title":"数据结构","content":"第1章 绪论 1.1 数据 数据(Data)：能输入到计算机中并被计算机程序处理的符号的总称。 数据元素(Data Element)：数据的基本单位。 数据项(Data Item)：一个数据元素可由若干个数据项组成，数据项是数据的不可分割的最小单位。 例如，学生的学籍信息包含学号、姓名、性别、出生日期、入学成绩，它们作为一个整体是数据元素，其中的每一项内容为数据项。 1.2 数据结构 数据结构：数据结构是指相互之间存在一定联系的数据元素的集合。 数据逻辑结构：数据元素之间的相互关系称为逻辑结构，通常分为四种：集合（数据间关系仅为同属一个集合）、线性结构（数据元素存在一对一关系）、树型结构（数据元素存在一对多关系）、图状结构（数据元素存在多对多关系）。 数据物理结构：数据的物理结构（即存储方式）是其逻辑结构在计算机中的表示和实现，数据结构的存储包括数据元素的存储和元素之间关系的表示。数据元素的关系在计算机中有两种不同的表示方法，顺序表示和非顺序表示。 顺序表示：用数据元素在存储器中的相对位置表示逻辑关系。在C语言中，用一维数组表示顺序存储结构。 非顺序表示：用指示数据元素存储地址的指针表示逻辑关系。在C语言中，用指针表示链式存储结构。 由此得出两种不同的存储结构：顺序存储结构和链式存储结构。在顺序存储结构中，数据元素存放的地址是连续的或者相差恒定常量；在链式存储结构中，数据元素存放的地址不确定，因此每个元素需要附加信息指明下个元素的位置。 1.3 数据类型 数据类型：数据类型指的是一个值的集合和定义在该值集上的一组操作的总称。以高级程序语言为例，数据类型被分为原子类型和结构类型。例如，C语言中提供了整型，其取值范围为-32768~32767（32位系统），可在其上进行加、减、乘、除、取模运算。 抽象数据类型(ADT)：抽象数据类型是指一个数学模型以及定义在该模型上的一组操作。 （1）ADT需要通过固有数据类型来实现。 （2）ADT的特征：数据抽象和数据封装。数据抽象是说用ADT处理的数据元素更强调其本质特征、功能及其对外提供的接口，数据封装是说将实体的外部特性和内部实现细节分离，对外隐藏内部细节。 （3）ADT的定义： 形式化定义：三元组ADT=(D, R, P)，其中D是数据对象，R是D上的关系集，P是对D的基本操作集。 一般定义形式： ADT &lt;抽象数据类型名&gt; { 数据对象：&lt;数据对象的定义&gt; 数据关系：&lt;数据关系的定义&gt; 基本操作：&lt;基本操作的定义&gt; } ADT &lt;抽象数据类型名&gt; 其中，数据对象和数据关系的定义用伪码描述，基本操作的定义是： &lt;基本操作名&gt;(&lt;参数表&gt;) 初始条件：&lt;初始条件描述&gt; 操作结果：&lt;操作结果描述&gt; 1.4 算法 1.4.1 算法的特征、算法与程序、算法的评价标准 （1）算法是对特定问题求解步骤的一种描述，有五个特征：有穷性、确定性、可行性、输入、输出。 注：①一个算法不收敛，并不一定违反“有穷性”的要求。 ②“确定性”并不意味着对于相同的输入一定有相同的输出（随机数），仅意味着算法的执行路径的确定性。 （2）算法与程序是两个不同的概念。程序是算法使用某种程序设计语言的具体实现。算法必须可终止，这就意味着不是所有的计算机程序都是算法。 （3）算法的评价标准：正确性、可读性、健壮性（算法应具有容错处理，即对非法输入作出恰当的反应）、高效率与低存储量。 1.4.2 算法的时空复杂度 （1）时间复杂度T(n)： 大O记号：称T(n)=O(f(n))T(n)=O(f(n))T(n)=O(f(n))，如果满足 ∃n0,M≥0,当n≥n0时,∣T(n)∣≤M∣f(n)∣\\exists n_0,M\\geq 0,当n\\geq n_0时,\\mid T(n)\\mid\\leq M \\mid f(n) \\mid ∃n0​,M≥0,当n≥n0​时,∣T(n)∣≤M∣f(n)∣ f(n)f(n)f(n)给出了T(n)T(n)T(n)的渐进上界。 另有T(n)=Ω(g(n))T(n)=\\Omega(g(n))T(n)=Ω(g(n))，g(n)g(n)g(n)给出了T(n)T(n)T(n)的渐进下界。 时间复杂度的阶之间的关系： O(1)&lt;O(log⁡n)&lt;O(n)&lt;O(nlog⁡n)&lt;O(n2)&lt;O(n3)&lt;O(2n)&lt;O(n!)&lt;O(nn)O(1)&lt;O(\\log n)&lt;O(n)&lt;O(n\\log n)&lt;\\\\ O(n^2)&lt;O(n^3)&lt;O(2^n)&lt;O(n!)&lt;O(n^n) O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n2)&lt;O(n3)&lt;O(2n)&lt;O(n!)&lt;O(nn) 时间复杂度的分析： 例1 分析Fibonacci数列递归实现方式的时间复杂度。 解：F(5)=F(4)+F(3)，又有F(4)=F(3)+F(2)，F(3)=F(2)+F(1)，由此递推下去，可绘成一棵高度为n-1的满二叉树，因此它的结点数为2n−1−12^{n-1}-12n−1−1，时间复杂度为O(2n)O(2^n)O(2n)，为指数阶。■ 一般地，我们考虑的是最坏情况时间复杂度。 （2）空间复杂度S(n)： 空间复杂度是指算法编写成程序后，在计算机中运行时所需存储空间大小的读量。这里的存储空间包括三个方面：程序本身所占存储空间、输入数据所占用的存储空间以及辅助空间。一般地，算法的空间复杂度指的是辅助空间（另两个可忽略）。 空间复杂度的分析： 例2 分析下面三个不同的程序所用的空间复杂度，它们均用来将一维数组a[n]中的元素倒置存放。 I. ReverseArray(int a[], int n){ int i, j, *b; b=(int *)malloc(sizeof(int)*n); for(i=0,j=n-1; i &lt; n; i++,j--) b[j]=a[i]; for(i=j=0; i &lt; n; i++,j++) a[i]=b[i]; free(b); } 解：辅助空间是b[n], i, j，共n+2个，故S(n)=n+2=O(n)S(n)=n+2=O(n)S(n)=n+2=O(n)。 II. ReverseArray(int a[],int n){ int i, j, t; for(i = 0,j = n-1; i &lt; j; i++, j--){ t=a[i]; a[i]=a[j]; a[j]=t; } } 解：辅助空间是3个临时变量i, j, t，故S(n)=3=O(1)S(n)=3=O(1)S(n)=3=O(1)。 III. ReverseArray(int a[],int n){ int i, t; for(i = 0; i &lt; n/2; i++){ t=a[i]; a[i]=a[n-i-1]; a[n-i-1]=t; } } 解：辅助空间是2个临时变量i, t，故S(n)=2=O(1)S(n)=2=O(1)S(n)=2=O(1)。■ 第2章 线性表 2.1 线性结构定义 线性结构：表示数据元素之间的有序关系，包含线性表、栈、队列、串、广义表。 2.1.1 线性表基本概念 线性表：由n个数据元素组成的有限序列，所有结点具有相同的数据类型。 线性表中数据元素的个数称为线性表的长度，长度为0的表称为空表。 首结点、尾结点、前驱、直接前驱、后继、直接后继。（见名知义） 记录：含有多个数据项的数据元素，每个记录有一个唯一标识每个结点的数据项组，称为关键字。 线性表中的结点可以是单值元素（只有一个数据项），也可以是记录型元素（这时每个数据项称为结点的一个域）。 若线性表中的结点按值由小到大（或由大到小排列），则称线性表是有序的。 2.1.2 线性表的ADT定义 应有的操作： 基本操作：初始化、销毁、插入元素、删除元素、元素定位、求表长、取元素、遍历； 其它操作（利用基本操作可实现）：将表置空、修改元素、线性表判空、求前驱、求后继、合并两个有序列表。 数据对象： D={ai∣ai∈ElemSet,i=1,2,...,n,n≥0}D=\\left\\{a_i\\mid a_i\\in ElemSet, i=1,2,...,n, n\\geq 0\\right\\} D={ai​∣ai​∈ElemSet,i=1,2,...,n,n≥0} 数据关系： R={&lt;ai−1,ai&gt;∣ai−1,ai∈D,i=2,3,...,n}R=\\left\\{ &lt;a_{i-1},a_i&gt;\\mid a_{i-1},a_i\\in D,i=2,3,...,n\\right\\} R={&lt;ai−1​,ai​&gt;∣ai−1​,ai​∈D,i=2,3,...,n} 2.2 线性表的顺序表示和实现 2.2.1 线性表的顺序表示 线性表的顺序表示：用一组地址连续的存储单元依次存储线性表的数据元素。有序关系通过地址的相邻来实现，即Loc(ai+1)=Loc(ai)+XLoc(a_i+1)=Loc(a_i)+XLoc(ai​+1)=Loc(ai​)+X，其中X为每个元素占用的存储单元大小。 2.2.2 线性表的顺序实现 （1）用动态分配的一维数组实现线性表SqList： /***************************** 线性表的定义 *****************************/ #define LIST_INIT_SIZE 100 //线性表初始大小 #define LISTINCREMENT 10 //线性表增量大小 typedef int ElemType; //元素的数据类型 typedef int Status; //处理状态 typedef struct{ ElemType *elem; //线性表存储空间的基地址 int length; //线性表当前长度 int listsize; //线性表当前分配到的存储容量 //以sizeof(ElemType)为单位 } SqList; 注：这里用typedef int ElemType定义ElemType仅是示例，当然可以用int以外的数据类型定义ElemType，如 typedef struct { int y,m,d; } ElemType; 这里的ElemType就是一个表示日期的数据类型。这要视实际需要而定。以后为方便起见常用int定义这样的数据类型。 （2）实现线性表的基本操作： 下面将逐个实现这五个基本操作：初始化、插入、删除、定位、合并 //线性表的初始化 Status InitList_Sq(SqList *L); //在第i个元素前插入元素e Status ListInsert_Sq(SqList *L, int i, ElemType e); //删除第i个元素，并传回删除的值 Status ListDelete_Sq(SqList *L, int i, ElemType *e); //定位元素 int LocateElem_Sq(SqList *L, ElemType e, Status (*compare)(ElemType, ElemType)); //将两有序表La,Lb合并为新的有序表Lc void MergeList_Sq(SqList *La, SqList *Lb, SqList *Lc); 线性表的初始化 InitList_Sq： /***************************** 初始化线性表 *****************************/ Status InitList_Sq(SqList *L){ L-&gt;elem=(ElemType *)malloc(LIST_INIT_SIZE * sizeof(ElemType)); if(!L-&gt;elem) exit(OVERFLOW); L-&gt;length = 0; L-&gt;listsize = LIST_INIT_SIZE; return OK; } //InitList_Sq 注： ① 核心语句3条：L-&gt;elem=...，L-&gt;length=...，L-&gt;listsize=...，也就是SqList结构体里的所有元素。它们分别申请了一块能容纳LIST_INIT_SIZE个元素的内存空间，初始化为空表，表的长度为LIST_INIT_SIZE。 ② void *malloc(unsigned int size)函数：用于在内存的动态存储区中申请一块长度为size的空间，并返回一个指向这块空间起始地址的指针。 ③ if(!L-&gt;elem)所在语句用于处理内存分配失败（此时L-&gt;elem=NULL）的情形。C 库函数 void exit(int status) 立即终止函数调用进程，它在库&lt;stdlib.h&gt;中。 ④ 时间复杂度为O(1)。 插入元素 ListInsert_Sq： /***************************** 向线性表第i个元素之前插入元素e *****************************/ Status ListInsert_Sq(SqList *L, int i, ElemType e){ //操作执行条件检查 if(i&lt;1 || i&gt;L-&gt;length+1) return ERROR; //i值不合法 if(L-&gt;length&gt;=L-&gt;listsize){ //当前存储空间已满，增加容量 ElemType *newbase=(ElemType *)realloc(L-&gt;elem, (L-&gt;listsize+LISTINCREMENT)*sizeof(ElemType)); if(!newbase) return ERROR; L-&gt;elem=newbase; L-&gt;listsize += LISTINCREMENT; } //执行操作 ElemType *p; ElemType *q=&amp;(L-&gt;elem[i-1]); for(p=&amp;(L-&gt;elem[L-&gt;length-1]);p&gt;=q;--p) *(p+1)=*p; *q=e; L-&gt;length++; } //ListInsert_Sq 注： ① realloc函数：void *realloc(void *mem_address, unsigned int newsize)，重新分配一块大小为newsize的存储空间，存放内容与mem_address内原有的内容一致（当然如果newsize比mem_address指向的空间小的话会有数据丢失），并返回新存储空间的起始地址。它在库&lt;stdlib.h&gt;中。 ② q指向第i个元素，p指向最后一个位置的元素。p从后往前依次把每个元素后移一位，直到把第i个元素后移到第i+1位位置，然后用*q=e把第i位填入元素e，最后将L-&gt;length元素增1。 ③ 平均时间复杂度为O(n)。 删除元素 ListDelete_Sq： /***************************** 删除线性表的第i个元素 *****************************/ Status ListDelete_Sq(SqList *L, int i, ElemType *e){ ElemType *p, *q; if(i&lt;1 || i&gt;L-&gt;length+1) return ERROR; //i值不合法 p=&amp;(L-&gt;elem[i-1]); *e = *p; //被删除元素的值赋给e q=L-&gt;elem+L-&gt;length-1; for(++p; p &lt;= q; ++p) *(p-1) = *p; L-&gt;length--; return OK; } //ListDelete_Sq 注： ① C语言复习：a是一个指针，*(a+i)等价于a[i]（取内容），因此&amp;a[i]等价于a+i（取地址）。 ② 平均时间复杂度为O(n)。 查找元素 LocateElem_Sq： /***************************** 在线性表中查找第1个值与e满足compare()函数的元素的位置，返回元素位置 *****************************/ int LocateElem_Sq(SqList *L, ElemType e, Status (*compare)(ElemType,ElemType)){ int i; ElemType *p; i=1; //i的初值为第1个元素的位置 p=L-&gt;elem; //p的初值为第1个元素的存储位置 while (i&lt;=L-&gt;length &amp;&amp; (*compare)(*p,e)!=0){ p++; i++; } if(i&lt;=L-&gt;length) return i; else return 0; } //LocateElem_Sq 注： ① 参数列表中，Status (*compare)(ElemType,ElemType)表示该参数名为compare，它是一个指针，指向一个函数，该函数有两个类型为ElemType的参数，返回值为Status类型。 ② while循环判断条件中，(*compare)(p,e)!=0表示p与e不满足compare()函数。我们可以按如下方式定义compare()函数： /***************************** compare()函数的定义 *****************************/ #define LESS -1 #define GREATER 1 Status (*compare)(ElemType 1, ElemType b){ if(a&lt;b) return LESS; if(a&gt;b) return GREATER; return 0; } 在主程序中按如下方式调用LocateElem_Sq()： int i=LocateElem_Sq(L,100,compare); //在线性表L中第一个值为100（或者说第一个值与100满足函数compare()）的元素位置为i //如未查找到则i=0 ③ 时间复杂度为O(L-&gt;length)。 合并两有序表为一新有序表 MergeList_Sq： /***************************** 将两个有序表La,Lb合并为新的有序表Lc，顺序均为递增 *****************************/ void MergeList_Sq(SqList *La, SqList *Lb, SqList *Lc){ ElemType *pa, *pb, *pc, *pa_last, *pb_last; pa = La-&gt;elem; pb = Lb-&gt;elem; pa_last = La-&gt;elem+La-&gt;length-1; pb_Last = Lb-&gt;elem+Lb-&gt;length-1; Lc-&gt;listsize = Lc-&gt;length = La-&gt;length + Lb-&gt;length; pc = Lc-&gt;Elem = (ElemType *)malloc(Lc-&gt;listsize*sizeof(ElemType)); if(!Lc-&gt;elem) exit(OVERFLOW); //分配存储失败 while(pa &lt;= pa_last &amp;&amp; pb &lt;= pb_last){ //归并列表，按递增顺序向Lc中插入元素 if(*pa &lt;= *pb) *pc++ = *pa++; else *pc++ = *pb++; } //处理La与Lb不等长的情况 while(pa &lt;= pa_last) *pc++ = *pa++; while(pb &lt;= pb_last) *pc++ = *pb++; } 注：时间复杂度为O(La-&gt;length + Lb-&gt;length)。 2.3 线性表的链式表示和实现 线性表的链式存储是指用一组任意的存储单元存储线性表中的数据。由于存储单元地址的任意性，我们还需要指针域来专门存放结点的直接后继的地址。 链表：通过每个结点的指针域将线性表的n个结点按其逻辑次序连接在一起的线性表。 链表结点的结构：数据域 + 指针域。 链表的分类： 线性链表/单链表 基于C指针实现的单链表 基于C数组实现的单链表/静态链表 双向链表 循环链表 双向循环链表 2.3.1 基于C指针实现的单链表 这是最常见的单链表。 结点的类型定义 typedef struct LNode{ ElemType data; //数据域，保存结点的值 struct LNode *next; //指针域，指示后继结点 }LNode, *LinkedList; 结点的赋值 LNode *p; p=(LNode *) malloc(sizeof(LNode)) p-&gt;data=20; p-&gt;next=NULL; 下面将实现线性表的基本操作：初始化、插入、删除、取第i个元素、合并 //生成n个元素的链表 LinkedList CreateList_L(int n); //在第i个元素之前插入元素e Status ListInsert_L(LinkedList L, int i, ElemType e); //删除第i个元素 Status ListDelete_L(LinkedList L, int i, ElemType e); //取第i个元素 Status GetElem_L(LinkedList L, int i, ElemType *e); //将两有序表合并成一新有序表 LinkedList MergeList_L(LinkedList La, LinkedList Lb); 1、创建单链表 LinkedList CreateList_L(int n){ LinkedList L, p; int i; //建立一个带头结点的空链表 L=(LinkedList)malloc(sizeof(LNode)); L-&gt;next = NULL; //从后往前插入元素 for(i=n;i&gt;0;i--){ p=(LinkedList)malloc(sizeof(LNode)); p-&gt;data=random(200); p-&gt;next=L-&gt;next; //将新来的结点插入到表头 L-&gt;next=p; } return L; } // CreateList_L 注： ① 插入元素的时候从最后一个开始，往前插入； ② 时间复杂度O(n)，n为链表长度。 2、单链表的元素插入 Status ListInsert_L(LinkedList L, int i, ElemType e){ //在第i个元素前插入元素e LinkedList p, s; p=L; int j=0; //找到第i-1个元素 while( p &amp;&amp; j &lt; i-1){ p=p-&gt;next; ++j; } //i给的值超出链表的范围时，报错 if(!p || j &gt; i-1) return ERROR; //新建结点s，插入到p后 s = (LinkedList)malloc(sizeof(LNode)); s-&gt;data = e; s-&gt;next = p-&gt;next; p-&gt;next = s; return OK; } //ListInsert_L 注：时间复杂度O(n)，n为链表长度。 3、单链表的元素删除 Status ListDelete_L(LinkedList L, int i, ElemType *e){ //删除第i个元素，并由e返回其值 LinkedList p, q; p=L; int j=0; //找到第i-1个元素 while(p-&gt;next &amp;&amp; j &lt; i-1){ p=p-&gt;next; ++j; } //i给的值超出链表的范围时，报错 if(!(p-&gt;next)||j&gt;i-1) return ERROR; //删除并释放结点 q=p-&gt;next; p-&gt;next=q-&gt;next; *e=q-&gt;data; free(q); return OK; } //ListDelete_L 注：时间复杂度O(n)，n为链表长度。 4、取第i个元素 Status GetElem_L(LinkedList L, int i, ElemType *e){ //当第i个元素存在时，其值赋给e并返回OK，否则返回ERROR LinkedList p; p=L-&gt;next; int j=1; //将p移动到第i个元素上去 while(p &amp;&amp; j &lt; i){ p=p-&gt;next; ++j; } if(!p || j &gt; i) return ERROR; *e=p-&gt;data; return OK; } //GetElem_L 5、两个有序单链表的合并 LinkedList MergeList_L(LinkedList La, LinkedList Lb){ LinkedList pa, pb, Lc, pc; pa = La-&gt;next; pb = Lb-&gt;next; Lc=pc=La; //用La的头节点作为Lc的头结点 // 合并链表 while(pa &amp;&amp; pb){ if(pa-&gt;data &lt;= pb-&gt;data){ pc-&gt;next=pa; pc=pa; pa=pa-&gt;next; }else{ pc-&gt;next=pb; pc=pb; pb=pb-&gt;next; } } pc-&gt;next = pa ? pa : pb; //插入pa或pb的剩余段 free(Lb); //释放Lb的头结点 return Lc; } // MergeList_L 注：时间复杂度为O(m+n)，其中m,n分别为La和Lb的长度。 上面的链表表示有如下缺点：① 链表的表长是隐含的； ② 输入数据合法性检查被推迟； ③ 对链表最后一个元素的操作需遍历整个链表； ④ 结点的当前位置很重要但没有体现。 因此我们可以对链表进行改进。① 增加表示表长、表尾、当前位置的变量； ② 将操作中的“位序i”改为“当前位置”。 改进的单链表： //结点类型 typedef struct LNode{ ElemType data; struct LNode *next; }Link, Position; //链表类型 typedef struct{ Link *head, *tail; //头尾结点 Link *current; //当前访问的结点 int curpos; //当前结点的位置 int len; //链表长度 } 2.3.2 静态链表 静态链表即为基于C数组实现的单链表。这种链表不使用指针，例如Java语言中没有指针，就可以使用数组来实现单链表。 静态链表可用下图来示意： 0号位置的结点的数据域为空闲表头，它的指针域指向下一个空闲结点，下一个空闲结点的指针域指向再下一个空闲结点，以此类推，最后一个空闲结点的指针域指回0处的空闲表头。这样形成了一个备用空闲链表。 1号位置的数据域为数据表头，是链表的头节点，它指向链表的首结点。该链表的尾结点指向0处的空闲表头，表示指向NULL。 可以看到，在同一块空间（如上图所示）中可以存储多个链表。 链表定义的代码实现 #define MAXSIZE 100 typedef struct SLinked{ ElemType data; int cur; }SLinkedList[MAXSIZE]; SlinkedList s; 下面在静态链表中实现链表的基本操作：初始化、创建、插入、删除、查找 初始化静态链表 //新建一个数组，把各分量链成一个空闲链表 void InitList(SLinkedList space){ int i; for(i=0;i &lt; MAXSIZE-1; i++){ space[i].cur = i+1; space[MAXSIZE-1].cur = 0; } } 创建静态链表 定义函数AllocNode()，它从空闲链表中分配一个结点： int AllocNode(SLinkedList space){ int i=space[0].cur; //空闲表头指向空闲位置 if(i==0) return 0; //没有空闲结点 space[0].cur = space[i].cur; //将空闲表头指针域指向下一个空闲位置 return i; } 创建静态链表： //创建一个含有n个结点的静态链表，返回表头位置 int CreateList(SLinkedList space, int n){ int head,k,s,l; k=AllocNode(space); //从空闲链表中取得一个空结点 head = k; for(i=1;i&lt;=n;i++){ s=AllocNode(space); scanf(&quot;%d&quot;,&amp;space[s].data); space[k].cur=s; k=s; } space[k].cur=0; //尾结点指向NULL return head; } 插入结点 //在head所指链表的第i个结点前插入值为x的结点 int InsertList(SLinkedList space, int head, int i, ElemType x){ int j,k,m; if (i &lt; 1) return 0; //合法性检查：所给i的范围正确 k=head; j=0; while(k!=0 &amp;&amp; j &lt; i-1){ //查找第i-1个结点 j++; k=space[k].cur; } if(k==0) return 0; //合法性检查：k不指向空闲表头(NULL) m=AllocNode(space); //分配一个新的空闲结点 if(m!=0){ space[m].data=x; space[m].cur=space[k].cur; space[k].cur=m; return 1; }else return 0; } 删除结点 定义函数FreeNode()，它回收下标为i的结点，回收到备用空闲链表的首部： void FreeNode(SLinkedList space, int i){ space[i].cur=space[0].cur; space[0].cur=i; } 删除结点： //在head所指的链表中，删除第i个结点 int Delete(SLinkedList space, int head, int i, ElemType *e){ int j,k,m; if(i &lt; 1) return 0; k=head; j=0; while(k!=0&amp;&amp;j &lt; i-1){ j++; k=space[k].cur; } if(k==0) return 0; m=space[k].cur; space[k].cur=space[m].cur; *e=space[m].data; FreeNode(space, m); return 1; } 查找值为x的结点 //查找第一个值为x的结点的位置，若找到返回它的位置，否则返回0 int Locate(SLinkedList space, int head, ElemType x){ int k; k=space[k].cur; while(k!=0 &amp;&amp; space[k].data!=x) k=space[k].cur; return k; } 2.3.3 双向链表、循环链表、双向循环链表 双向链表 构成链表的每个结点中设立两个指针域，一个指向其直接前驱的指针域prior，一个指向其直接后继next。 typedef struct node{ ElemType data; struct node *prior, *next; }DoublyLinkedList; 循环链表 在单链表的基础上，将尾结点的后继指向头结点。 双向循环链表 前两者的组合。 第3章 栈和队列 1. 栈 1.1 栈的基本概念 栈：先进后出（或后进先出）的线性表。示意图： 图中top称为栈顶，base（或bottom）称为栈底。 栈的一个特性：n个元素入栈，一共有多少种不同的出栈方式？ 考虑以元素1为界，之前有i个元素，之后有n-i-1个元素，因此得到递推式 hn=∑i=0n−1hihn−i−1h_n=\\sum_{i=0}^{n-1}h_{i}h_{n-i-1} hn​=i=0∑n−1​hi​hn−i−1​ 这是Catalan数递推表达式，通式为 hn=1n+1(2nn)h_n=\\frac{1}{n+1}{2n \\choose n} hn​=n+11​(n2n​) 栈的具体实现：顺序栈比较常用 顺序栈 动态顺序栈 静态顺序栈 链式栈 栈的基本操作：初始化空栈、返回栈的长度、进栈、出栈、获取栈顶元素、遍历栈等。 1.2 顺序栈和链式栈 1.2.1 动态顺序栈 动态顺序栈：采用动态一维数组来存储栈。 #define INITSIZE 100 #define INCREMENTSIZE 10 typedef int ElemType; typedef struct{ int top; ElemType *base; int stacksize; }SqStack; 栈的基本操作 主要有以下几个函数： //1. 构造一个空栈s Status InitStack(SqStack *s); //2. 取栈的长度 int GetLen(SqStack *s); //3. 查看栈顶元素 Status GetTop(SqStack *s, ElemType *e); //4. 元素入栈 Status Push(SqStack *s, ElemType e); //5. 元素出栈 Status Pop(SqStack *s, ElemType *e); //6. 判断栈是否为空 int IsStackEmpty(SqStack *s); //7. 遍历栈，从栈顶到栈底对每个元素调用visit()函数 Status StackTraverse(SqStack *s,visit()); 函数相关内容已放至文件中(下面的C程序均为GB2312编码)： SqStack.c 应用 数制转换：函数Conversion()将十进制正整数n转换成d进制数。 NumberSystem.c 括号匹配：函数MatchingBrackets()判断输入的括号串是否匹配。 BracketMatch.c 1.2.2 静态顺序栈 采用静态一维数组来存储栈，栈顶指针top指向栈顶，top所指位置存储最后一个元素（base处不存元素）。 #define MAX_STACK_SIZE 100 typedef int ElemType; typedef struct{ ElemType stack_array[MAX_STACK_SIZE]; int top; }SqStack; 1.2.3 链式栈 和链表几乎一致，栈顶元素为头结点的后继。 typedef struct Node{ ElemType data; struct Node *next; }LinkedStack; 文件LinkedStack.c实现这几个函数： //1. 构造一个空栈s Status InitStack(SqStack *s); //2. 取栈的长度 int GetLen(SqStack *s); //3. 查看栈顶元素 Status GetTop(SqStack *s, ElemType *e); //4. 元素入栈 Status Push(SqStack *s, ElemType e); //5. 元素出栈 Status Pop(SqStack *s, ElemType *e); //6. 判断栈是否为空 int IsStackEmpty(SqStack *s); 应用：行编辑程序问题 在用户输入一行的过程中，允许用户输入出差错，并在发现有误的同时可以及时更正。 用#代替退格符Backspace，@代表退行符，删除一行。例如，用户输入下面两行： whli##ilr#e(s#*s) outcha@putchar(*s=#++); 实际有效的是 while(*s) putchar(*s++); 代码：LineEditor.c 1.3 栈的应用举例 算术表达式求职/中缀表达式求值 --&gt;后缀表达式求值 迷宫寻路 递归的实现 老师已将代码上传至SEP网上。 2 队列 2.1 队列的基本概念 和栈类似，也是操作受限的线性表。队列是先进先出，允许进行删除的一端称为队头，允许进行插入的一端称为队尾。 队列的表示 也分为链式表示和顺序表示。 队列的基本操作 初始化、获取长度、判断是否为空、查看队头元素、入队、出队。 2.2 链队列 链队列的定义 链队列是用链表表示队列，设有头结点、各元素结点、队头指针和队尾指针。 typedef struct Node{ ElemType data; struct Node *next; }QNode; typedef struct { QNode *front; QNoed *rear; }LinkedQueue; 链队列的基本操作 //1. 链队列的初始化，构造一个空队列 Status InitQueue(LinkedQueue *lq); //2. 取队列的长度 int GetLen(LinkedQueue *lq); //3. 判断队列是否为空 int IsQueueEmpty(LinkedQueue *lq); //4. 查看队头元素 Status GetFront(LinkedQueue *lq, ElemType *e); //5. 元素入队（尾） Status Enqueue(LinkedQueue *lq, ElemType e); //6. （队头）元素出队 Status Dequeue(LinkedQueue *lq, ElemType *e); 代码：LinkedQueue.c 2.3 顺序队列 顺序队列：利用一组连续的存储单元存储队头到队尾的各个元素。 2.3.1 静态顺序队列 定义 #define MAXQUEUESIZE 100 typedef struct queue{ ElemType Queue_array[MAXQUEUESIZE]; int front; //队头指针 int rear; //队尾指针 int queuesize; //队列空间的大小 } SqQueue; 基本操作 初始化、判空、判满(rear==MAXQUEUESIZE)、入队、出队。 入队：将新元素插入rear所指的位置，然后rear加1； 出队：删去front所指的元素，然后front加1，并返回所删除的元素值。 静态顺序队列的假溢出 在入队和出队操作中，头、尾指针只增不减，因此被删除元素的空间不能得到利用，从而出现“假溢出”。 解决方式：将为队列分配的空间首尾相连，组成循环队列。 2.3.2 循环队列 定义 循环队列：将为队列分配的向量空间看成一个首尾相接的圆环。 #define MAXQUEUESIZE 100 typedef struct queue{ ElemType *base; //动态分配的存储空间 int front; //队头指针，指向第一个元素的位置 iont rear; //队尾指针，指向最后一个元素后面的位置 } CircularQueue; 基本操作 //1. 初始化 Status InitQueue(CircularQueue *cq); //2. 获取队列长度 int GetLen(CircularQueue *cq); //3. 判空 int IsQueueEmpty(CircularQueue *cq); //4. 查看队头元素 Status GetFront(CircularQueue *cq,ElemType *e); //5. 入队 Status Enqueue(CircularQueue *cq,ElemType e); //6. 出队 Status Dequeue(CircularQueue *cq,ElemType *e); 在循环队列中进行入队、出队操作时，队头、队尾指针仍要加1，但当到达所分配空间的末尾时，加1操作的结果是指向0位置。 可以用取模运算来实现： rear = (rear+1) % MAXQUEUESIZE; //出队 front = (front+1) % MAXQUEUESIZE; //入队 但无法用front == rear判断队空和队满。解决方案：① 增加计数器，记录队列长度； ② 增加一个标志位，区分队列“空”还是“满”； ③ 少用一个元素空间，约定尾指针的下一个位置是头指针时，队列即满： (rear + 1) % MAXQUEUESIZE == front; 循环队列基本操作代码：CircularQueue.c 第6章 树 6.1 术语 递归定义：根、子树。结点：直接前驱（1个）、直接后继（≥0个）。 表示法：圆括号表示法（广义表表示法）、树形表示法、文氏图表示法、目录结构表示法。 攀亲戚：孩子、双亲、兄弟、堂兄弟（双亲在同一层的结点）；祖先(ancestor)、子孙(descendant)。 度量：度、宽度、路径-从根到结点的路径；结点的层次/深度、结点的高度、树的深度、树的高度（树的深度=树的高度）。 植物学：叶子结点。有序树、无序树（区别：子树位置能不能互换）。m叉树、满m叉树、完全m叉树、森林。 6.2 基本操作 创造 初始化一棵树(InitTree(*T))、按定义构造一棵树(CreateTree(*T, def))、给结点赋值、把一颗树作为另一棵树p结点的第i棵子树。 探索 求根结点、求当前结点元素值、求当前结点的双亲结点、求当前结点的最左孩子、求当前结点的右兄弟、判空、求深度、遍历。 毁灭 清空树、销毁树、删除p结点的第i棵子树。 6.3 二叉树 二叉树是有序树。 6.3.1 性质 一般性质 若根结点所在层数为1，则第i层最多有2i−12^{i-1}2i−1个结点。 深度为k(k≥1)的二叉树至少有k个结点，至多有2k−12^k-12k−1个结点。 设度为i(i=0,1,2)的结点有nin_ini​个，则n0=n2+1n_0=n_2+1n0​=n2​+1。【翻译：叶子结点恰好比度为2的非叶结点多一个。】、 n个结点的二叉链表必定存在n+1个空链域。 满二叉树 深度为k，恰有2k−12^k-12k−1个结点。 按从上到下、从左到右的顺序，从0开始为它编号，则对于编号为iii的结点，它的双亲编号为⌊i2⌋\\lfloor\\frac{i}{2}\\rfloor⌊2i​⌋，左孩为2i2i2i，右孩为2i+12i+12i+1。 完全二叉树 设有n个结点，则深度为k=⌊log⁡2n⌋+1=⌈log⁡2(n+1)⌉k=\\lfloor \\log_2n\\rfloor +1=\\lceil \\log_2(n+1)\\rceilk=⌊log2​n⌋+1=⌈log2​(n+1)⌉。 6.3.2 存储 顺序存储结构 链式存储结构 二叉链表 三叉链表 线索链表 顺序存储结构 按照性质里面给的编号规则，用下面的结构存储： typedef TElemType SqBiTree[MAX_TREE_SIZE]; 有些编号不存在，对应的位置就不储存数据。所以有浪费空间的缺点。 二叉链表 typedef struct BiTNode{ TElemType data; // 结点内容 struct BiTNode *lchild, *rchild; // 左右孩子指针 } BiTree; 这下不浪费空间了。但是不好回溯，很难找妈妈。 双亲链表 typedef struct BPTNode{ TElemType data; // 结点内容 int *parent; // 双亲位置 char LRTag; // 该结点为左孩子or右孩子 } BPTNode; typedef struct BPTTree{ BPTNode nodes[MAX_TREE_SIZE]; int num_node; int root; } 这下能找到妈妈了。但是找不着孩子。 三叉链表 typedef struct BiTNode{ TElemType data; // 结点内容 struct BiTNode *lchild, *rchild; // 左右孩子指针 struct BiTNode *parent; // 双亲指针 } BiTree; 6.3.3 遍历 先左后右的遍历 先序遍历(DLR) 中序遍历(LDR) 后序遍历(LRD) 先右后左的遍历 先上后下的遍历（层次序遍历） 遍历可以用递归的方式，也可以用非递归的方式。 非递归遍历算法： 层次序遍历二叉树 采用队列，按照编号从小到的的形式遍历。 例子：表达式树 用树来存储一个四则运算表达式。可以很方便地用树的三种遍历方式将表达式转换为前缀、中缀和后缀表达式。 6.3.4 线索二叉树 由来：二叉树的遍历其实就是将非线性的二叉树的线性化。线性化之后，每个数据元素都有自己的直接前驱和直接后继。 定义：线索二叉树就是包含线索的二叉树。其中“线索”指向线性序列种数据元素的前驱和后继。【因此要约定好用哪种顺序来遍历】 实现：二叉树一般性质第4条：n个结点的二叉树存在n+1个空链域。可以用者n+1个链域来指示前驱和后继。并增设ltag和rtag，表明指针指示的是孩子还是前驱还是后继线索。0表示指示的是孩子，1表示指示的是线索。 代码：可以用以下结构存储线索二叉树： typedef enum{Link, Thread} PointerThr; typedef struct BiThrNode{ TElemType data; struct BiThrNode *lchild, *rchild; PointerThr ltag, rtag; } BiThrTree; 操作：建立线索二叉树、遍历线索二叉树、寻求给定结点的前驱和后继。（先序、中序、后序） 6.3.5 Huffman树 术语：结点的路径长度、树的路径长度、结点的带权路径长度、树的带权路径长度。 注意：树的路径长度是所有结点的路径长度之和，而树的带权路径长度是所有叶子结点的带权路径长度之和。 定义：叶子结点相同、带权路径长度最小的二叉树。因此它的特征就是权重越大的叶子结点离根越近。 构造：贪心算法，给定n个权值，两两合并最小的两个权值。 应用：最优判定树：决策过程最短（或平均判定次数最少）；多叉Huffman树：k叉对应每次合并k个最小的权值；Huffman编码：变长编码且为二进制前缀编码，数据压缩。 6.4 树 6.4.1 存储 双亲表示法 孩子表示法 孩子-兄弟表示法 孩子-兄弟表示法：一般树——二叉树之间的互相转换 6.4.2 性质 树的结点数等于所有结点的度数+1。（每个结点都有双亲，但根结点没有） 度为m的树，其第i层上至多有mi−1m^{i-1}mi−1个结点。 高度为h的m叉树至多有mh−1m−1\\frac{m^h-1}{m-1}m−1mh−1​个结点。 具有n个结点的m叉树的最小高度为⌈log⁡m[n(m−1)+1]⌉\\lceil \\log_m[n(m-1)+1]\\rceil⌈logm​[n(m−1)+1]⌉ 具有n个结点的不同形态的树的数目和具有n-1个结点的不同形态的树的数目相同，即tn=bn−1t_n=b_{n-1}tn​=bn−1​。 不同形态的二叉树的数目为卡塔兰数，即bn=Cn=1n+1(2nn)b_n=C_n=\\frac{1}{n+1}\\binom{2n}{n}bn​=Cn​=n+11​(n2n​)。 6.4.3 遍历 深度优先遍历 先根次序遍历 后根次序遍历 广度优先遍历/层次遍历 先根次序遍历 先访问根结点，然后先根遍历各子树。 性质：树的先根遍历与对应二叉树的先序遍历结果一致。因此树的先根遍历可以借助对应二叉树的先序遍历算法实现。 后根次序遍历 先对根节点的各子树进行后根遍历，然后访问根结点。 性质：树的后根遍历与对应二叉树的中序遍历结果一致。因此树的先根遍历可以借助对应二叉树的先序遍历算法实现。 6.4.4 并查集 定义：一种集合，每个元素从属且仅从属于一个集合，换句话说不同集合中的元素不相交（有点类似于离散数学中的partition）。用于处理不交集中元素的合并和查询问题。 操作：查询x所在集合，合并两个集合，判断两个元素是不是在同一个集合中。 存储：树表示。用一棵树表示一个子集合，树的每一个结点代表集合的一个元素。 改进：可以对并查集算法做两种改进：(1) 加权合并：合并的时候把小集合（结点数少的树）合并到大集合上；(2) 压缩路径：若待查询元素i不在第二层，把从根到i的所有结点都与根连接起来，实现路径压缩，缩短元素到达根结点的距离。 应用： 判断和构造等价类 判断和构造图的连通分量 求解最小生成树(Kruskal算法) 等价类 等价类是一个集合，其上的元素都满足等价关系。 等价类划分算法：利用等价偶对 n个元素的幂集 可以用一棵二叉树表示幂集的生成过程。先序遍历该状态树即可求得幂集元素。 四皇后问题/八皇后问题 6.5 森林 6.5.1 森林转换成一棵二叉树 步骤： 把每棵树转换为二叉树。 把后一棵树的根结点连接到前一棵树的根结点，作为其右子树。 6.5.2 遍历 森林的构成： 第一棵树的根结点 第一棵树的子树森林 其它树构成的森林 森林的遍历：下面提到的对树的先序/中序遍历，都是指对这棵树对应的二叉树作先序/中序遍历。 先序遍历： 访问第一棵树的根结点 先序遍历第一棵树的子树森林 先序遍历其余树构成的森林 中序遍历： 中序遍历第一棵树根结点的子树森林 访问第一棵树的根结点 中序遍历其余树构成的森林 Part I 数组 I.1 定义和表示 定义：数组是相同类型数据元素的集合。 存储：采用顺序存储结构实现，有静态数组和动态数组。 静态一维数组： ElemType A[MAX]; 动态一维数组： ElemType *A=(ElemType *)malloc(MAX * sizeof(ElemType)); if(!A) return ERROR; 动态多维数组： typedef struct{ ElemType *base; // 数组内的全部数据 int dim; // 数组的维数 int *bounds; // 数组各维的大小b_i int *constants; // 数组映象函数常量地址c_i } Array; 一维数组也被称为向量。二维数组可以用来存储矩阵。二维数组不是线性结构。 映象：由于内存是一维的，而多维数组是多维的，因此有存储顺序的映象方式。 二维数组有两种映象方式： 以行序为主序（C语言）、以列序为主序。 n维数组的映象函数：（类行序主序映象） LOC: location LOC(j1,j2,...,jn)=LOC(0,0,...,0)+∑i=1ncijiLOC(j_1,j_2,...,j_n)=LOC(0,0,...,0)+\\sum_{i=1}^nc_ij_i LOC(j1​,j2​,...,jn​)=LOC(0,0,...,0)+i=1∑n​ci​ji​ where bib_ibi​ is the length of the ith dimension, L is the length of a single element, and cic_ici​ is defined recursively as cn=L,ci−1=bi×ci,1&lt;i≤nc_n=L,\\quad c_{i-1}=b_i\\times c_i,\\quad 1&lt;i\\leq n cn​=L,ci−1​=bi​×ci​,1&lt;i≤n I.2 基本操作 初始化、取值、赋值 I.3 处理矩阵 I.3.1 特殊矩阵的压缩存储 特殊矩阵：对称矩阵、三对角矩阵（规律性强）；稀疏矩阵（零元素多）。 不存储可以不存储的元素，如对称元素、零元素。 对称矩阵 元素关于主对角线对称。只存储上/下三角矩阵，关键是找到内存位置kkk与元素下标(i,j)(i,j)(i,j)之间的关系。例如，行序优先存储下三角矩阵： k={i(i+1)2+j, i≥jj(j+1)2+i, i&lt;jk=\\left\\{ \\begin{aligned} \\frac{i(i+1)}{2}+j,\\ i\\geq j\\\\ \\frac{j(j+1)}{2}+i,\\ i&lt;j \\end{aligned} \\right. k=⎩⎪⎪⎨⎪⎪⎧​2i(i+1)​+j, i≥j2j(j+1)​+i, i&lt;j​ 三对角矩阵 主对角线和相邻的上下两条对角线之外的元素全为0。 稀疏矩阵 就是有很多0的矩阵。由三元组(i,j,aij)(i,j,a_{ij})(i,j,aij​)确定非零元素。下面重点分析。 I.3.2 稀疏矩阵的压缩存储 三元组顺序表：矩阵转置 行逻辑联接的顺序表：矩阵乘法 十字链表：矩阵加法 三元组表 // 定义三元组（矩阵的非零元） typedef struct { int i, j; ElemType e; } Triple; // 定义稀疏矩阵 typedef struct { Triple data[MAXSIZE + 1]; // 以顺序表存储全部三元组，行序主序 int mu, nu, tu; // 矩阵的行数、列数和非零元个数 } TSMatrix; 矩阵转置： 行、列数交换；每个三元组的行、列号交换；重排序。 快速转置算法：预先建立辅助数组num和cpot，num存转置前矩阵每列有多少非零元，cpot存每列第一个非零元在内存中的起始地址。 行逻辑联接的顺序表 在上述三元组表基础上，增加一个数据成员rpos，指示各行第一个非零元的位置。 // 定义三元组（矩阵的非零元） typedef struct { int i, j; ElemType e; } Triple; // 定义稀疏矩阵 typedef struct { Triple data[MAXSIZE + 1]; // 以顺序表存储全部三元组，行序主序 int rpos[MAXMN + 1]; // 各行第一个非零元在data[]中的位置下标 int mu, nu, tu; // 矩阵的行数、列数和非零元个数 } TSMatrix; 矩阵乘法 十字链表 typedef struct OLNode{ int i,j; ElemType e; struct OLNode *right, *down; } OLNode, *Olink; typedef struct{ Olink *rhead, *chead; int mu,nu,tu; } CrossList; 矩阵加法 Part II 广义表 II.1 类型定义 表头、表尾、长度、深度。 II.2 存储 II.2.1 表头表尾分析法 typedef enum{ATOM, LIST} ElemTag; typedef struct GLNode{ ElemTag tag; union{ AtomType atom; struct{ GLNode *hp, *tp; } ptr; } } Glist; II.2.2 子表分析法 typedef enum{ATOM, LIST} ElemTag; typedef struct GLNode{ ElemTag tag; union{ AtomType atom; struct GLNode *hp; } struct GLNode *tp; } Glist; 图 这一章内容较多，借助本笔记梳理一下。 1. 基本概念 顶点、边； 子图、生成子图：设有图G=(V,E)G=(V,E)G=(V,E)和G′=(V′,E′)G&#x27;=(V&#x27;,E&#x27;)G′=(V′,E′)，若V′⊆VV&#x27;\\subseteq VV′⊆V且E′⊆EE&#x27;\\subseteq EE′⊆E则为子图，若V′=VV&#x27;=VV′=V且E′⊆EE&#x27;\\subseteq EE′⊆E则为生成子图。 简单图（无自环，无重边）、多重图、完全图； 有向图、无向图；弧头、弧尾； 稀疏图、稠密图；权重、带权图/网； 路径、有向路径、路径长度、简单路径、回路、简单回路； 连通性： ① 对于无向图：连通图、连通分量（极大连通子图）、极小连通子图（连通图的生成树）。 ② 对于有向图：强连通图（任意两顶点间都有来和往的有向路径）、强连通分量、有向图的生成森林。（若干棵有向树，含有全部顶点）。 重(双)连通图、关节点/割点； 度、入度、出度、握手定理。 回边。 2. 图的存储结构 2.1 数组（邻接矩阵）表示法 用一维数组vexs[n]存储顶点信息，用二维数组A[n][n]存储顶点之间关系信息。 图的种类：UDG无向无权图、DG无向带权图、UDN有向无权图、DN有向带权图。 带权图不邻接的一对顶点，对应邻接矩阵中表示为0或∞都不影响，只是为了说明不是正常的权值。 #define MaxVertexNum 30 typedef enum{UDG, DG, UDN, DN} GraphKind; typedef struct ArcCell{ VRType adj; InfoType *info; } ArcCell, AdjMatrix[MaxVertexNum][MaxVertexNum]; typedef struct{ int vernum, arcnum; // 顶点数，边数 GraphKind kind; // 图的种类 VertexType vexs[MaxVertexNum]; // 顶点信息 AdjMatrix arcs; // 邻接矩阵 } MGraph; 或者用更简洁的表示方法： #define Max 30 typedef enum{UDG, DG, UDN, DN} GraphKind; typedef struct{ int vernum, arcnum; // 顶点数 GraphKind kind; // 图的种类 char vexs[Max]; // 存放顶点信息 int A[Max][Max]; // 存放边的信息 } MGraph; 2.2 邻接表法 无向图 对于有向图，可以构建正邻接链表（出度直观）和逆邻接链表（入度直观）。若无特别说明，邻接链表一般指正邻接链表。 #define MAX 30 typedef char ElemType; typedef struct node{ int vindex; struct node *next; } NodeLink; // 表结点 typedef struct { int vexnum, edgenum, kind; struct { ElemType vertex; NodeLink *first; } v[MAX]; // 表头结点数组 } AGraph; 2.3 十字链表法 用于有向图的表示中，如下图所示： #define MAX 30 typedef char ElemType; typedef struct ArcBox{ int tailvex, headvex; // 弧尾结点和弧头结点的序号 struct ArcBox *hlink, *tlink; } ArcNode; // 弧结点 typedef struct VexNode{ ElemType data; ArcBox *firstin, *firstout; } VexNode; // 顶点结点 typedef struct{ int vexnum, arcnum; VexNode xlist[MAX]; } OLGraph; 2.4 邻接多重表 用于无向图的表示中，如下图所示： #define MAX 30 typedef enum {unvisited, visited} VisitIf; // 标记是否被遍历 typedef struct EBox{ VisitIf mark; // 访问标记 int ivex, jvex; struct EBox *ilink, *jlink; InfoType info; // 与边相关的信息，如权值 } EBox; // 边结点 typedef struct VexBox{ VertexType data; EBox *firstedge; } VerBox; // 顶点结点 typedef struct { int vexnum, edgenum; VerBox adjmulist[MAX]; } AMGraph; 3. 图的遍历 从图的某一顶点出发，访问图中的其余顶点，每个顶点仅被访问一次。 数据结构：（正）邻接链表。 算法：深度优先搜索DFS和广度优先搜索BFS。（递归） 如何判断某个顶点是否被访问？解决办法是为每个顶点设立一个访问标志visited[w]。 3.1 深度优先搜索(DFS) 伪代码描述： 访问 顶点V; for(V的邻接点W1, W2, W3) 若 邻接点Wi 未被访问 从它出发进行深度优先遍历; 输出顺序：前序(pre-order)，后序(post-order)，逆前序(reverse pre-order)，逆后序(reverse post-order)。 正序可以用队列来实现，逆序可以用栈来实现。前序是在递归调用之前先将当前顶点压入队列/栈，后序是在递归调用之后再将当前顶点压入队列/栈。 回边：如果图上的某条边不在DFS生成树上，那么这条边叫做回边。 3.2 广度优先搜索(BFS) 描述： 从图中某个顶点V出发，访问V，然后依次访问V的所有未被访问过的邻接点，之后按这些顶点被访问的先后次序依次访问它们的邻接点，直至图中所有和V有路径相通的顶点都被访问到。 使用辅助队列Q来保存已访问过的顶点。 3.3 图遍历的应用 (1) 求两顶点之间的一条简单路径：从顶点A出发，进行DFS，直到搜索到B。 (2) 求两顶点之间的一条最短路径：从顶点A出发，进行BFS，直到搜索到B。 4. 图的拓扑排序 拓扑排序：由某个集合上的一个偏序适当添加关系，得到该集合上的一个全序的操作。注意原有的偏序关系要保留。 集合上有偏序关系，可以表示成有向无环图(DAG, Directed Acycling Graph)。 4.1 AOV网的拓扑排序 AOV网：有向图中，用顶点表示活动，用有向边表示活动之间的优先关系。 算法： 选择一个入度为0（无前驱）的顶点并输出。 删除该顶点以及从该顶点出发的所有有向边。 重复前两步，直到图中全部顶点已输出（图中无环），或图中不存在无前驱的顶点（图中必有环）。 数据结构：（正）邻接链表。 记录数据：设立栈来暂存入度为0的点；记录各顶点的入度；记录已输出顶点的数目。 5. 图的连通性 5.1 无向图的连通性 (1) 无向非连通图的连通分量（极大连通子图） (2) 无向非连通图的生成森林（极小连通子图） 从多个顶点出发进行遍历，每个顶点的遍历会产生一棵它对应连通分量的生成树。所有这些生成树构成了原来的图的生成森林。 (3) 无向连通图的生成树（一个极小连通子图），包含图中全部n个顶点和能构成一棵树的n-1条边。 按DFS和BFS算法分别能得到无向连通图的一棵生成树，前者被称为深度优先生成树，后者被称为广度优先生成树。 5.2 有向图的连通性 有向图的强连通分量：包含顶点V的强连通分量的顶点集合是，从V可到达的顶点集合与到达V的顶点集合的交集。 求有向图的强连通分量：Kosaraju算法，Tarjan算法。 Kosaraju算法： 对G进行深度优先遍历，生成G的深度优先生成森林T。 对森林T的顶点进行逆后序排序。 改变G中每一条弧的方向，构成一个新的有向图G'。 按2.中标出的顶点编号，从编号最大的顶点开始，对G'进行深度优先搜索，得到一棵深度优先生成树。 若尚未遍历G'的所有顶点，则从未访问的顶点中选择一个编号最大的顶点，由它开始再进行深度优先搜索，并得到另一棵深度优先生成树。重复步骤4，直到G'中的所有顶点都被访问。 这样得到的每一棵生成树中的顶点就是G的一个强连通分量的所有顶点。 下面是一个实例： 数据结构：十字链表。 5.3 重连通图和关节点 重连通图：若从一个连通图中删去任何一个顶点及其相关联的边，它仍为一个连通图，则它为重连通图。 关节点：删去该点及其相关联的边后，连通图被分为两个及以上的连通分量，则称该顶点为关节点。 关节点的判定： 对于连通图的深度优先生成树： (1) 若生成树的根结点有两个或两个以上的分支，则根结点必为关节点； (2) 对于生成树上任意一个内部结点V（非叶子结点），若其某棵子树的根或该棵子树中的其它结点没有和V祖先相通的回边，则结点V必为关节点。 【打个问号，没看懂】 5.4 最小生成树 最小生成树是带权连通图G上的生成树，它满足各边权重之和达到最小。（不唯一） (1) Prim算法 逐步添加结点，要求每次新添加结点时，新添加的w和已经在生成树上的顶点v之间存在一条边，该边的权值在所有连通顶点w和v之间的边中取值最小。 实现： 集合U：已在MST(Minimum Spanning Tree)上的顶点的集合。 closedge结构：adjvex成员——边所依附于U中的顶点；lowcost成员——边的权值。 选择初始顶点加入U；每次向U中新加入一个顶点，就更新一次closedge，其中新加入的顶点的lowcost设为0，而其它V-U中的顶点重新赋值为最小的权值所对应的边（这只需要检查原来的最小权值边和新加入的顶点对应的边哪个权值更小即可）。 (2) Kruscal算法 逐步添加边，要求每次新添加边时，新添加的边不会使得图中产生回路，且权值在这一限制下取到最小。（贪心原则） ","link":"https://kimokcheon.github.io/post/shu-ju-jie-gou/"},{"title":"C++ Primer Plus","content":" 因为平时经常遇到C++，以后的课程应该也免不了要用，学一下C++。 参考用书：C++ Primer Plus(Sixth Edition)，作者：Stephen Prata I have learned the programming language C already, thus I'll only take down new grammars and features in C++ in my notes. Also, all the Chinese versions I've found are scanned version, but I find an English version which is not scanned. Therefore I'll just use the English version. A chance to practice my English, not bad! Chpt 1. Getting Started with C++ C++ is a superset of C. C++ joins 3 separate programming categories: the procedural language, the object-oriented language and generic programming. C Programming Philosophy In general, computer languages deal with two cocepts--data and algorithms. Like most mainstream languages when C was created, C is a procedural language. That means is emphasizes the algorithm side of programming. C includes features to facilitate structured programming approach, making it relatively easy to read and modify a program. Top-down design was another feature of C. The idea is to break a large program into smaller, more manageable tasks. C uses programming unit called functions to implemente this idea. The C++ Shift: Object-Oriented Programming Unlike procedural programming, which emphasizes algorithms, OOP emphasizes the data. The idea is to design data forms that correspond to the essential features of a problem. In C++, a class is a specification describing such a new data form, and an object is a particular data structure constructed according to that plan. The OOP approach to program design is to first design classes, then proceed to design a program using objects of those classes. This process of going from a lower level of organization(such as classes) to a higher level(such as program design) is called bottom-up programming. There are other features of OOP such as information hiding, polymorphism, inheritance and etc. C++ and Generic Programming The term generic refres to code that is type independent. Generic programming involves extending the language so that you can write a function for a generic type once and use it for a variety of actual types. Chpt 2. Setting Out to C++ Namespaces If you use iostream instead of iostream.h, you should use the following namespace directive to make the definitions in iostream available to your program: using namespace std; This is called a using directive. Namespace support is a C++ feature that combines pre-existing code from several vendors and to help organize programs. One potential problem is that you might use two prepackaged products that both have a function called wanda(). The namespace facility lets a vendor pakcage its wares in a unit called a namespace so that you can use the name of a namespace to indecate which vendor's product you want. So Microflop Industries could place its definitions in a namespace called Microflop. Then Microflop::wanda() could denote Microflop's version of wanda(). Similarly, Piscine::wanda() could denote Piscine Corporation's version of wanda(). Thus, you can omit the using directive and, instead, code in the following style: std::cout &lt;&lt; &quot;Come up and C++ me some time.&quot;; std::cout &lt;&lt; std::endl; The following line means you can use names defined in the std namespace without using the std:: prefix: using namespace std; C++ Output with cout cout &lt;&lt; &quot;Come up and C++ me some time.&quot; The &lt;&lt; notation indicates that the statement is sending the string to cout; the symbols point the way the information flows. cout is a predefined object that knows how to display a variety of things, intcluding strings, numbers and individual characters. Thus, you can say that it inserts a string into the output stream. Using cin cin &gt;&gt; carrots; Just as C++ considers output to be a stream of characters flowing out of the program, it considers input to be a stream of characters flowing into the program. Chpt 3. Dealing with Data Naming Rules One rule is worth noticing: Names beginning with two underscore(_) characters or with an underscore character followed by an uppercase letter are reserved for use by the implementation--that is, the compiler and the resources it uses. Names beginning with a single underscore character are reserved for use as global identifiers by the implementation. Using a name such as __time_stop or _Donut doesn't produce a compiler error; instead, it leads to undefined behavior. In other words, there's no telling what the result will be. The sizeof Operator and the climits Header File You can apply the sizeof operator to a type name or to a variable name. When you use the sizeof operator with a type name, such as int, you enclose the name in parentheses. But when you use the operator with the name of the variable, such as n_short, parentheses are optional. The climits header file defines symbolic constants to represent type limits. Integer Literals An integer literal, or constant, is one you write out explicitly, such as 212 or 1776. C++, like C, lets you write integers in three different number bases: base 10, base 8, and base 16. C++ uses the first digit or two to identify the base of a number constant: 1-9: decimal(base 10) 0: octal(base 8) 0x or 0X: hexadecimal(base 16) If you want to display a value in headecimal or octal form, you can use cout manipulators dec, hex, and oct to display integers in decimal, hexadecimal, and octal formats, respectively. wchar_t, char16_t and char32_t The wchar_t type is an integer type with sufficient space to represent the largest extended character set used on the system. This type has the same size and sign properties as one of the other integer types, which is called the underlying type. The underlying type depends on the implementation. Because the sign and size of wchar_t can vary from one implementation to another, C++11 introduces the types char16_t, which is unsigned and 16 bits, and char32_t, which is unsigned and 32 bits. C++11 uses the u prefix for char16_t character and string constants, like u'C' and u&quot;be good&quot;. Similarly, it uses the U prefix for char32_t constants, like U'R' and U&quot;dirty rat&quot;. A member function: cout.put() The cout.put() function is the first example of an important C++ OOP concept, the member function. A member function belongs to a class and describes a method for manipulating class data. The cout is an object of class ostream. The class has a member function named put(). We can use the function with a particular object of the class, such as cout object. To use a class member function with an object of that class, simply use a period to combine the object name(cout) with the function name(put()). We'll learn &quot;Objects and Classes&quot; in Chapter 10. Now the only classes we have encountered are istream and ostream classes. The const qualifier C++ uses const to handle symbolic constants. For example, const int Months = 12 initialized a constant named Months with value of 12. Writing Floating-Point Numbers C++ has two ways of writing floating-point numbers. The first is the custom way, like 3.14159. The second method is called E notation, which is like 3.14E-6(= 0.00000314). The -6 is called an exponent, and the 3.14 is termed the mantissa.(You can use both E or e in E notation) Floating-Point Constants By default, floating-point constants such as 8.24 and 2.4E8 are type double. If we want a constant to be type float, we can use an f or F suffix. For type long double, we can use an l or L suffix. Conversion When you try to combine mixed types, C++ converts all the concerned types to the same type. C++ empowers us to force type conversions explicitly vis the type cast mechanism. You can use (typename) value or typename (value) to complete type cast. The former is traditional C form of type cast, whereas the second form is pure C++. The idea behind the new form is to make a type cast look ike a function call. This makes type casts for the built-in types look like the type conversions you can design for user-defined classes. C++ also introduces 4 type case operators that are more restrictive in bow they can be used. Ot the four, the static_cast&lt;&gt; operator, can be used for converting values from one numeric type to another. Usage: static_cast&lt;typename&gt; value. The idea behind is to be more restrictive than the traditional type cast. auto Declarations in C++11 C++11 introduces a facility that allows the compiler to deduce a type from the type of an initialization value. For this purpose it redefines the meaning of auto, a keyword dating back to C, but one hardly ever used. auto n = 100; // n is int Chpt 4. Compound Types Arrays You can use a comma-separated list of values (the initialization list) enclosed in braces to initialize an array, like int yamcosts[3] = {20, 30, 5};. However, you can only use the initialization form when defining the array. You cannot use it later(int hands[4]; hands[4] = {5, 6, 7, 9};) and you cannot assign one array wholesale to another(int cards[4] = {1, 2, 3, 4}; hands = cards;). You can let the compiler counter number of elements in an array while initializing: short things[] = {1, 5, 3, 8}; int num_elements = sizeof things / sizeof (short); C-style Strings C++ has two ways of dealing with strings. The first is C-style string, like char name[4] = {'S', 'a', 'm', '\\0'};; the second is using C++ string class. For C-style strings, you can just initialize it without denoting the number of characters: char fish[] = &quot;Bubbles&quot;; // let the compiler count A tricky point about cin is that cin uses whitespace(spaces, tabs, and newlines) to delineate a string. This means that cin only reads one word when it gets input from a character array. The program instr1.cpp shows this. To read input strings a line at a time instead of a word, you should use istream(cin is its object) class member functions getline() and get(). The difference is, after reading a line, getline() discards the newline character, whereas get() leaves it in the input queue. get(name, ArSize) reads input characters from keyboard and stops when input reaches its end or input is longer than ArSize. Note that the character '\\n' will be left in the inpiut queue. A single get() reads one character a time. We can use it to absort the '\\n' character left by the above function: cin.get(name, ArSize); // read first line cin.get(); // read newline cin.get(dessert, ArSize); // read second line Another way to use get() is to concatenate, or join, two class member functions, as follows: cin.get(name, ArSize).get(); // concatenate member functions This is possible because cin.get(name, ArSize) returns the cin object. Use string Class Just use string str1; to declare a string. We can also use cin and cout to assign or print the value of a string. The string class makes it simpler for some operations to be done. For example, you can assign a string object directly to another. Also you can combine strings using the operator +. An advantage of using string class is that you don't have to worry about oversizing. string objects will automatically resize its size to fit in your input or your operation. We can use member functions size() of string class to get the length of a string, which is equivalent to the strlen() function from the &lt;cstring&gt; header file(the older &lt;string.h&gt;). We can use getline(cin, stringname) to get a string from the keyboard. Note that cin is an argument of the function, which indicates that this getline() function is not the member function method from istream class. It takes cin as an argument that tells it where to find the input. Also, there isn't an argument for the size of the string because the string object automatically resizes to fit the objects, as we've discussed above. Structure and Union You've defined a strcture inflatable: struct inflatable{ char name[20]; float volume; double price; }; Then you can create variables of type inflatable: inflatable hat; Notice that you don't have to write struct before structure name inflatable, which is required in C. You can use string class members within structure definition. Just move the using directive before structure definition. The usage and function of union in C++ is the same as is in C. Enumerations Enumeration is defined as follows: enum spectrum {red, orange, yellow, green, blue, violet, indigo, ultraviolet}; It establishes red, orange, yellow, and so on, as symbolic constants for the integer values 0-7. These constants are called enumerators. Notice that only assignment operator is defined for enumerations. In particular, arithmetic operations are not defined. However, enumerators can be automatically converted to int type, but int types are not converted automatically to the enumeration type: int color = blue; // valid, spectrum type promoted to int spectrum band; band = 3; // invalid, int not converted to spectrum color = 3 + red; // valid, red converted to int Allocating Memory with new In C, you can allocate memory with the library function malloc(). You can still so so in C++, but C++ provides a better way: the new operator. int *pn = new int; The new int part tells the program you want some new storage suitable for holding an int. The new operator uses the type to figure out how many bytes are needed. Then it finds the memory and returns teh address.he Freeing memory with delete You can free memory with delete: int *ps = new int; ... delete ps; Use new to Create Dynamic Arrays int *psome = new int[10]; Use delete to Free Dynamic Arrays delete [] psome; Pointer and Array Array name denotes the address of the starting element of the array. We have that pointername[i] == *(pointername + i). Thus, in many cases we can use pointer names and array names in the same way. However, there are two major differences between pointer names and array names. The first one is that array name is a constant, so you cannot change it. But pointername is changeable: pointername = pointername + 1; // valid arrayname = arrayname + 1; // not allowed A second difference is that applying the sizeof operator to an array name yields the size of the array, even if the pointer points to an array. But applying the sizeof operator to array names produce the size of the array. For example: double wages[3] = {10000.0, 20000.0, 30000.0}; double *pw = wages; cout &lt;&lt; sizeof(wages) &lt;&lt; &quot; = size of wages array\\n&quot;; cout &lt;&lt; sizeof(pw) &lt;&lt; &quot; = size of pw pointer\\n&quot;; Running result: 24 = size of wages array 4 = size of pw pointer Pointer and String char animal[20] = &quot;bear&quot;; // animal holds bear char *ps = animal; cout &lt;&lt; animal &lt;&lt; &quot; at &quot; &lt;&lt; (int *) animal &lt;&lt; endl; cout &lt;&lt; ps &lt;&lt; &quot; at &quot; &lt;&lt; (int *) ps &lt;&lt; endl; Output: bear at 0x61fdf0 bear at 0x61fdf0 Normally, if you give cout a pointer, it prints an address. But if the pointer is type char *, cout displays the pointer-to string. If you want to see the address of the string, you have to type cast the pointer to another pointer type, such as int *, as the example above shows. The vector Template Class The vector template class is similiar to the string class in that it is a dynamic array. Basically, it's an alternative to using new to create a dynamic array. We'll pay attention to 5 aspects of the vector class: To use a vector class, you need to include the vector header file. The vector identifier is part of the std namespace, so you can use a using directive, a using declaration, or std::vector. Templates use a different syntax to indicate the type of data stored. The vector class uses a different syntax to indicate the number of elements. using namespace std; vector&lt;int&gt; vi; // create a zero-size array of int int n; cin &gt;&gt; n; vector&lt;double&gt; vd(n); // create an array of n doubles The array Template Class (C++11) Compared to vector, the built-in array type is a bit more efficient, but it comes at a cost of leesened convenience and safety. To solve this problem, C++11 adds the array template class. To create an array object, you need to include the array header file. Also it is in namespace std. #include &lt;array&gt; ... using namespace std; array&lt;int, 5&gt; ai; // create array object of 5 ints array&lt;double, 4&gt; ad = {1.2, 2.1, 3.43, 4.3}; Chpt 5. Loops and Relational Expressions cout.setf() function Note that in express.cpp, we use cout.setf(ios_base::boolalpha);. This function call sets a flag that instructs cout to display the words true and false instead of 1 and 0. For loop C++ allows you to declare a variable in the initialization area of a for loop, which is not permitted in C: for (int i = 0; i &lt; 5; i++) ... Building a Time-Delay loop In the ctime header file(or the time.h in traditional C), a function called clock() returns the system time elapsed since a program started execution. Note that clock() does not return the time in seconds, however, and the type of its return value might be long, unsigned long or others based on your system. ctime header file provides solutions to these problems. First, It defines a symbolic constant, CLOCKS_PER_SEC, that equals the number of system time units per second. So dividing the system time by this value yields seconds. Or you can multiply seconds by CLOCKS_PER_SEC to get time in the system units. Second, ctime establishes clock_t as an alias for the clock() return type. This means you can declare a variable as type clock_t, and the compiler cnverts it to long or unsigned int or whatever is the proper type for your system. Special Note on cin When reading type char values, just as when reading other basic types, cin skips over spaces and new line characters. You can refer to Listing 5.16 textin1.cpp to see this. The End-of-File(EOF) condition When cin detects the EOF, it sets two bits(the eofbit and the failbit) to 1. You can use a member function named eof() to see whether the eofbit has been set; the call cin.eof() returns the bool value true or false based on whether EOF has been detected or not. Similarly, the fail() member function returns true if either the eofbit or the failbit has been set to 1 and false otherwise. Note that the eof() and fail() methods report the result of the most recent attempt to read; that is, they report on the past rather than look ahead. So a cin.eof() or cin.fail() test should always follow an attempt to read. You can refer to Listing 5.18 textin3.cpp for this. bool value of cin The istream class provides a function that can convert an istream object such as cin to a bool value. This conversion function is called when cin occurs in a location where a bool is expected, such as in the test condition of a while loop. Chpt 6. Branching Statements and Logical Operators The cctype Library of Character Functions The cctype header file(ctype.h in the older style) holds several functions that simplify such tasks as determining whether a character is an uppercase letter or a digit or punctuation. For example, the isalpha(ch) function returns a nonzero if ch is a letter and zero value otherwise. Similarly, the ispunct(ch) function returns a true value only if ch is a punctuation character, such as a comma or a period. Reading Mismatch Type into a Variable Suppose you have the beneath lines in a program: int n; cin &gt;&gt; n; If you enter, say, a word instead a number? Four things occur in such a mismatch: The value of n is left unchanged. The mismatched input is left in the input queue. An error flag is set in the cin object. The call to the cin method, if converted to type bool, returns false. The fact that the method returns false means that you can use non-numeric input to terminate a number-reading loop. The fact that non-numeric input sats an error flag means that you have to reset the flag before the program can read more input. You can use the clear() method to reset the error flag, just use cin.clear(). Simple File I/O File output is silimar to console output using cout. In file output: You must include the fstream header file. The fstream header file defines an ofstream class for handling output. You need to declare one or more ofstream variables, or objects, which you can name as you please, as long as you respect the usual naming conventions. You must account for the std namespace; for example, you can use the using directive or the std:: prefix for elements such as ofstream. You need to associate a specific ofstream object with a specific file; one way to do so is to use the open() method. When you're finished with a file, you should use the close() method to close the file. You can use an ofstream object with the &lt;&lt; operator to output a variety of data types. Note that although the iostream header file provides a predefined ostream object called cout, you have to declare your own ofstream object, choosing a name for it and associating it with a file. Here's how you declare such objects: ofstream outFile; // outFile an ofstream object ofstream fout; // fout an ofstream object You may refer to Listing 6.15 outfile.cpp for usage of ofstream class. Note that when you open an existing file for output, by default it is truncated to a length of zero bytes, so the contents are lost. ifstream class is similarly designed. Note that is_open() method returns true if the file was successfully opened. You can use is_open() method to check whether a file was opened successfully: ifstream inFile; inFile.open(&quot;bowling.txt&quot;); if (!inFile.is_open()) exit(EXIT_FAILURE); The exit() function is prototyped in the cstdlib header file, which also defines EXIT_FAILURE as an argument value used to communicate with the operating system. The exit() function terminates the program. ","link":"https://kimokcheon.github.io/post/c-primer-plus/"},{"title":"RNN, Attention, Transformer, BERT","content":" RNN, Attention, Transformer, BERT简介 RNN(Recurrence Neural Network) 背景 有时候我们需要根据历史信息来判断未来的趋势。例如，给一句话，挖掉最后一个单词，让机器预测这个单词最大概率是什么。那机器不能只依据这个序列的最后一个单词（指挖掉的单词前面的那个单词）来判断最后一个单词填什么，而应该根据整个序列由前到后地推断。 “Sequence modeling” 实现 为了记住历史信息，引入了RNN。 假设激活函数是tanh，RNN的计算公式（为了写起来简单就不加粗了，但是都是向量、矩阵）： ht=tanh⁡(Wxxt+Whht−1)y^t=Wohth_t = \\tanh(W_xx_t+W_hh_{t-1})\\\\ \\hat{y}_t = W_oh_t ht​=tanh(Wx​xt​+Wh​ht−1​)y^​t​=Wo​ht​ 在hth_tht​的计算中引入了历史信息ht−1h_{t-1}ht−1​。 Attention RNN的不足 没有长期记忆。t时刻的执行与t-1时刻关系最紧密，与更早时刻关联比较弱，与t+1之后的执行没有关联。但是，考虑这一句话：“Bark is very cute and he is a dog”，“he”与“Bark”“dog”的关系最紧密，与它前面的单词“and”关系反而不大。 难以并行化。后一步执行必须等待当前步执行完毕，才能计算。 存在梯度消失和梯度爆炸。尤其到t很大的时候，从hth_tht​反向传播到h0h_0h0​，会出现多个相同数连乘的情况，很容易趋于0或趋于无穷。 例子：数据库查询 数据库按照键值对的方式组织，也就是一个键(key)对应一个值(value)。查询时，用户给出请求(query)，query到数据库中，与所有的key逐个比对。若发现某个key与query最接近，就把这个key对应的value返回，这就完成了一次查找。 Attention基本原理与这个接近，可以把一个单词看作一个query，一句话就是一个数据库。这句话中，与query关系越紧密的单词，它的权重就越高。 Self-Attention就是拿一句话中的每个单词与这一句话的全部单词进行比对，同样，关系越相近的单词权重就越高。例如，给出一句话“He tossed this tennis ball to serve”，下图就是其Self-Attention的示意： 为什么叫Attention？因为关系越相近的单词，我们的“关注度”（即赋予它的权重）越高。 实现 (1) 输入一句话，对每个单词，都给出其embedding向量ViV_iVi​。这句话就变成了一个向量组[V1,V2,...,Vn][V_1, V_2, ..., V_n][V1​,V2​,...,Vn​]。 所有单词都在同一个embedding space中，每个单词都是这个embedding space中的一个向量。embedding space按照单词语义远近组织，语义相近的单词在embedding space中也相近。 (2) 单词在语句中有顺序（顺序很重要！），因此再对每个单词给出其位置embedding向量PiP_iPi​，记为[P1,P2,...,Pn][P_1, P_2, ..., P_n][P1​,P2​,...,Pn​]。 (3) 将ViV_iVi​和PiP_iPi​相加，为了便于表述，再记为ViV_iVi​。这就是包含了单词词义和顺序信息的最终输入向量组。 (4) 引入MkM_kMk​矩阵，它表示key信息。做矩阵乘法[V1,V2,...,Vn]Mk[V_1, V_2, ..., V_n]M_k[V1​,V2​,...,Vn​]Mk​，这样每个向量就都附上了key。 (5) 引入MqM_qMq​矩阵，它表示query信息。做矩阵乘法[V1,V2,...,Vn]Mq=Q[V_1, V_2, ..., V_n]M_q=Q[V1​,V2​,...,Vn​]Mq​=Q。 (6) 计算Attention权重。计算矩阵乘法QKT=WQK^T=WQKT=W即可，只要query与key足够接近，乘积矩阵中对应元素的值就越大，也就是权重越高。 (7) 经过一个softmax层，对W矩阵做归一化操作。 (8) 引入MvM_vMv​矩阵，它表示value信息。做矩阵乘法[V1,V2,...,Vn]Mv=[V1′,V2′,...,Vn′][V_1, V_2, ..., V_n]M_v = [V&#x27;_1, V&#x27;_2, ..., V&#x27;_n][V1​,V2​,...,Vn​]Mv​=[V1′​,V2′​,...,Vn′​]。 (9) 计算Attention值：Attention=∑i=1nVi′WAttention = \\sum_{i=1}^nV&#x27;_iWAttention=∑i=1n​Vi′​W。容易发现，Attention和输入向量V有相同的维度。 Attention如何克服RNN的不足？ 任意两个单词都能找到联系，这就有了长期记忆。 存在大量矩阵计算，很容易实现并行化。 反向传播(BP)阶段，由于不是按照时间序一步一步计算的，因此不存在连乘状况，自然没有梯度消失和梯度爆炸。 Multi-Head Attention 只使用一组Mk,Mq,MvM_k, M_q, M_vMk​,Mq​,Mv​矩阵，效率比较低，且发现的联系也比较少。因此引入多组参数矩阵，称每组为一个“head”，将所有head计算出的Attention值拼接起来，形成最终的Attention值，这就是Multi-Head Attention。 Transformer Transformer是使用self-attention机制加速机器翻译的一个模型，于2017年提出。 Transformer结构如下： 其中，encoder和decoder的结构如下： |———————————————————| |———————————————————| | | | | | | | | | | | Feed Forward | | Feed Forward | | ↑ | | ↑ | | | | | | | | Attention | | Self Attention | | ↑ | | | | | | | | | Self Attention | | | | | | | | | |———————————————————| |———————————————————| encoder decoder encoder中使用了Self Attention机制，更准确地说是Multi-Head Self Attention，前面已经介绍过。Self Attention计算结果再经过一个前馈神经网络，然后传递给下一个encoder。 decoder与encoder的结构类似，不同的是，在经过第一次Self Attention的计算之后，还要与之前的encoder输出结果做一次Attention，然后再送入前馈神经网络。 具体技术细节和训练过程可以参考这篇文章：https://zhuanlan.zhihu.com/p/166608727。 BERT BERT是基于Transformer的自然语言理解(NLP)模型。简单理解就是，BERT会基于输入文本，生成与上下文相关的embedding，既有单词的embedding，又有句子的embedding。 如何训练BERT BERT是一种预训练模型，它的预训练目标就是生成一个好用的NLP模型，因此只用到了Transformer中的encoder。BERT的训练方式主要有两种： (1) MLM(Masked Language Modeling)。简单地说，BERT会接收一个文本序列，但是序列中有15%的单词被[MASK] token所代替。它的训练目标就是预测出[MASK]之下的单词。 (2) NSP(Next Sentence Prediction)。简单地说，BERT会接收到许多“句子对”，BERT需要判断出每组“句子对”中第二句话是否是第一句话之后应该说的话。这些句子对中有50%有承接关系，另外50%两句话没有关系。 在NSP中，输入文本的第一句话前面会加上一个[CLS]token，每句话的最后会加上一个[SEP]token用以标记。最后[CLS]的输出会被转换成一个2×1的向量，然后送入一个分类层，来确定第二句话是否是第一句话的后继。 如何运用BERT BERT可以用于多种NLP任务，只需要在核心模型之后加上一个layer即可。例如： (1) 分类任务（例如某个影评是积极的还是消极的）。这种任务和NSP比较像，只需要在[CLS] token的输出后面加上一个分类层即可。 (2) 问答任务。这类任务会针对一个文本做出提问，机器需要根据问题，将正确答案在文本中标记出来。使用BERT来完成这类任务时，可以另外训练两个向量，用于标记文本中正确答案的开始位置和结束位置。 (3) 命名实体识别(NER)任务。这类任务会将一个文本序列输入机器，机器需要标记出文本中的不同命名实体（比如XXX是人物/地点/组织……）。使用BERT来完成这类任务时，只需要把每个token的输出向量放进一个分类层即可。 有个YuTube视频大致演示了如何在python中调用BERT，完成一些简单的任务 参考资料： 老师课件 MIT 6.S191: Recurrent Neural Networks and Transformers - YouTube All you need to know about ‘Attention’ and ‘Transformers’ — In-depth Understanding — Part 1 - Towards Data Science 十分钟理解Transformer - 知乎 BERT Explained: State of the art language model for NLP - Towards Data Science ","link":"https://kimokcheon.github.io/post/rnn-attention-transformer-bert/"},{"title":"Verilog","content":" 参考教材：《Verilog数字系统设计教程（第二版）》（夏宇闻 编著） Verilog自学真困难。 Verilog语言练习网站：HDLBits 第一章 模块 1.1 概述 Verilog的基本设计单元是模块。一个模块由两部分构成，一部分描述接口，一部分描述逻辑功能。 例1 设计一个2输入(a,b)、2输出(c,d)的模块block，输出c为输入相与，输出d为输入相或。 module block(a,b,c,d) input a,b; output c,d; assign c = a | b; assign d = a &amp; b; endmodule 1.2 模块端口的声明 模块的端口声明了模块的输入输出口，格式如下： module 模块名(口1,口2,口3,口4,...); 1.3 模块内容 模块的内容包括I/O说明、内部信号声明和功能定义。 I/O说明 输入口： input [信号位宽-1:0] 端口名1; input [信号位宽-1:0] 端口名2; ... 输出口： output [信号位宽-1:0] 端口名1; output [信号位宽-1:0] 端口名2; ... I/O说明也可以放在端口声明的语句里，格式如下： module module_name(input port1,input port2,... output port1,output port2,...); 内部信号声明 内部信号用reg或wire表示。每个逻辑门输入输出都需要指定wire或reg类型。wire表示直通，即只要输入有变化，输出马上无条件地反映；reg表示一定要有触发，输出才会反映输入。在模块内用到的和端口有关的wire和reg类型变量格式如下： reg [width-1:0] R变量1,R变量2,...; wire [width-1:0] W变量1,W变量2,...; 功能定义 模块中最重要的是逻辑功能定义部分。有3种方法： 1、用assign声明语句 assign a=b&amp;c;//a为b与c 2、用实例元件 and #2 u1(q,a,b); 说明：上面语句表示设计中用到一个跟与门(and)一样的，名为u1的与门，输入为a,b，输出为q，#2表示输出延迟为2个单位时间。要求每个实例元件的名字是唯一的。 3、用always语法块 always @ (posedge clk or posedge clr); begin if(clr) q&lt;=0; else if(en) q&lt;=d; end 说明：always块既可以描述组合逻辑，又可以描述时序逻辑。上面的例子生成了一个带有异步清除端的D触发器（目前还看不懂，提前感受下）。 1.4 模块的引用 类似于程序设计语言里面函数的调用。比如，引用4个可扩展4位比较器来构建16位比较器。 引用方式有两种： 1、严格按照模块定义的端口顺序连接，不必标明原模块的端口名。即 模块名(连接端口1信号名,连接端口2信号名,连接端口3信号名,...); 2、用“.”注明原模块是定义时规定的端口名。即 模块名(.端口1名(连接信号1名),.端口2名(连接信号2名),.端口3名(连接信号3名),...); 第二章 数据类型、常量和变量 2.1 常量 数字 1、整数： 有3种表达： (1) &lt;位宽&gt; &lt;进制&gt; &lt;数字&gt; 这是最全面的描述方式。如： 8'b10101100 //8：位宽 'b：二进制 即，8位二进制数10101100 8'ha2 //'h：十六进制 即，8位十六进制数a2（位宽是对二进制而言的） (2) &lt;进制&gt; &lt;数字&gt; 采用默认位宽，由机器决定，至少32位。 (3) &lt;数字&gt; 采用默认进制十进制。 2、x值和z值： x代表不定值，z代表高阻态。x可以用来代表十六进制中的4位二进制数的状态，也可以代表八进制中的3位二进制数的状态，二进制数中的1位。z类似。z也可写作&quot;?&quot;。（有啥用？） 4'b10x0 4'b101z 3、负数： 负号必须写在数字表达式的最前面。 -8'd5 //表示5的补码，用8位二进制表示 4、下划线： 用来分隔开数的表达，提高程序的可读性。 16'b1010_1011_1100_0011 parameter型（参数型） parameter 参数名1=表达式,参数名2=表达式,参数名3=表达式,...; 参数型常用来定义延迟时间和变量宽度。在模块或实例引用时，可通过参数传递改变在被引用模块中已经定义的参数（目前不懂）。 2.2 变量 wire表示直通，即只要输入有变化，输出马上无条件地反映；reg表示一定要有触发，输出才会反映输入。 wire型 wire型数据常用来表示用以assign关键字指定的组合逻辑信号。格式： wire [位宽-1:0] 数据名1,数据名2,数据名3,...; reg型 就是寄存器，是数据存储单元的抽象。通常，在设计中要用always模块使用行为描述语句来表达逻辑关系。常用reg来表示always模块内的指定信号，代表触发器。格式： reg [位宽-1:0] 数据名1,数据名2,数据名3,...; memory型 Verilog通过对reg型变量建立数组来对存储器建模，可以描述ROM等存储器。Verilog中没有多维数组，memory格式如下： reg [n-1:0] 存储器名[m-1:0]; 如： reg [7:0] mema[255:0];//存储器名为mema，有256个8位存储单元（寄存器），地址范围是0-255 第三章 运算符与表达式 3.1 与大部分程序设计语言含义相同的运算符 算术运算符：+，-，*，/，% 位运算符：~，&amp;，|，(异或)，~(同或) 逻辑运算符：&amp;&amp;，||，!(逻辑非) 关系运算符：&lt;，&gt;，&lt;=，&gt;= 移位运算符：&gt;&gt;，&lt;&lt; 3.2 等式运算符 ==，!=：逻辑等式运算符，结果由两个操作数的值决定，由于操作数中某些位可能是不定值x和高阻态z，因此结果可能为不定值x。只要其中一个操作数中含有x或z，结果即为x。 ===，!==：case等式运算符（因为它们常用于case表达式的判别），对不定值x和高阻态z也进行比较，两个操作数必须完全一致才为1，否则为0。 3.3 拼接运算符 {} 使用方法： {信号1的某几位,信号2的某几位,信号3的某几位,...} 如{a,b[3:0],w,3'b101}。 重复信号，如： {4{w}} //相当于{w,w,w,w} 嵌套表达，如： {b,{3{a,b}}} //相当于{b,a,b,a,b,a,b} 3.4 缩减运算符 功能：多个与、或、非运算的缩减。如： reg [3:0] B; reg C; C=&amp;B; 相当于 C=((B[0] &amp; B[1]) &amp; B[2]) &amp; B[3]; 3.5 赋值语句 &lt;=：非阻塞式赋值，并行执行。一般用于时序电路。 =：阻塞式赋值，后边的语句必须在这句执行完毕才能执行（顺序执行）。一般用于assign语句。 举例说明： 例2（非阻塞式赋值） always @ (posedge clk) begin b &lt;= a; c &lt;= b; end 事实上实现了下面的电路图： 例3（阻塞式赋值） always @ (posedge clk) begin b = a; c = b; end 事实上实现了下面的电路图： 第四章 控制流 块语句、条件语句、循环语句、生成语句 4.1 块语句 4.1.1 顺序块 特点：块内语句顺序执行；每条语句的延迟时间是相对于前一条语句的仿真时间而言的；直到最后一条语句执行完，程序流程控制才跳出该语句块。 格式： begin 语句1; 语句2; ... 语句n; end 可以自行添加两语句间的时间延迟（此处每条语句的延迟时间是相对于前一条语句的仿真时间而言的）： begin areg=breg; #10 creg=areg; //在两条赋值语句之间延迟10个时间单位 end 4.1.2 并行块 特点：块内语句同时执行；块内每条语句的延迟时间是相对于程序流程控制进入到块内的仿真时间的。 格式： fork 语句1; 语句2; ... 语句n; join 4.1.3 命名块的禁用 命名块：块可以有自己的名字，例如： begin: block1 //该语句块的名字为block1 语句1; 语句2; ... 语句n; end 命名块的一大好处是可以用disable关键字终止执行。这一点非常类似于C语言中用break语句来退出循环的执行。 务必注意：在阅读下面的例题之前，请先学习4.2条件语句和4.3循环语句。 例4 从寄存器flag的低有效位开始，查找第一个值为1的位。 reg [15:0] flag; integer i;//用于计数的整数 initial begin flag=16'b0010_0000_0000_0000; i=0; begin: block1 while(i&lt;16) begin if(flag[i]) begin $ display(&quot;Encountered a TRUE bit at element number %d&quot;,i); disable block1; //在标志寄存器flag中找到了值为1的位，禁用block1 end i=i+1; end end end 4.2 条件语句 过程块语句：initial和always语句引导begin end块。 条件语句必须在过程块语句中使用。 条件语句分为：if else语句，case语句 4.2.1 if else语句 与一般程序设计语言相同，3种形式： (1) if(条件表达式) 语句; (2) if(表达式) 语句1; else 语句2; (3) if(表达式1) 语句1; else if(表达式2) 语句2; else if(表达式3) 语句3; ... else if(表达式m) 语句m; else 语句n; 如果if语句中含有多条语句，应当用begin和end将它们包含起来。如： if(a&gt;b) begin out1&lt;=int1; out2&lt;=int2; end else begin out1&lt;=int2; out2&lt;=int1; end 表达式可以简写： if(expression) 等价于 if(expression==1) 4.2.2 case语句 一般形式： case(表达式) &lt;case分支项&gt; endcase case分支项的一般形式： 分支表达式: 语句; default: 语句; 举个例子： reg [15:0] rega; reg [9:0] result; case(rega) 16'd0: result=10'b0111111111; 16'd1: result=10'b1011111111; 16'd2: result=10'b1101111111; 16'd3: result=10'b1110111111; 16'd4: result=10'b1111011111; 16'd5: result=10'b1111101111; 16'd6: result=10'b1111110111; 16'd7: result=10'b1111111011; 16'd8: result=10'b1111111101; 16'd8: result=10'b1111111110; default: result=10'bx; endcase 注意： 执行完case分支项的语句后，会跳出该case语句结构（与C语言不同！）。 case语句所有表达式值的位宽必须相等，这样才能比较。 不当使用条件语句会导致锁存器的产生。例如 always @ (al or d) begin if (al) q=d end 这里if语句保证了只有当al=1时，q才取d的值，但是没有给出al=0的值，因此这时q会延续之前的取值，也就是说会形成一个锁存器。 可以使用末尾的else或者default分支来避免锁存器的产生。 4.3 循环语句 Verilog中提供了四种类型的循环语句：forever语句，repeat语句，while语句，for语句。forever以后再说。 4.3.1 repeat语句 格式： repeat(循环次数表达式) begin 语句1; 语句2; ... 语句n; end 其中，循环次数表达式用于指定循环次数，可以是一个整数、变量或者数值表达式。 例5 使用repeat循环、加法和移位语句实现乘法器。 parameter size=8, longsize=16; reg [size:1] opa,opb; reg [longsize:1] result; begin: mult //这里mult是该语句块的名称，通过begin加冒号来定义 reg [longsize:1] shift_opa, shift_opb; shift_opa = opa; shift_opb = opb; result=0; repeat(size) begin if(shift_opb[1]) result=result+shift_opa; shift_opa=shift_opa&lt;&lt;1; shift_opb=shift_opb&gt;&gt;1; end end 4.3.2 while语句 一般形式： while(表达式) begin 语句1; 语句2; ... 语句n; end 与C语言一致，不再赘述。 4.3.3 for语句 一般形式： for(循环变量赋初值;循环结束条件;循环变量增值) begin 语句1; 语句2; ... 语句n; end 与C语言一致，不再赘述。 4.4 生成语句 生成语句是用来生成一些代码的。它分为循环生成语句、条件生成语句和case生成语句。 循环生成语句可以用来减少一些相似代码的重复编写，简化代码。条件生成语句的目的是左右编译器的行为，类似于C语言中的条件选择宏定义，根据一些初始参数来决定载入哪部分代码来进行编译。case生成与条件生成作用相似。 生成语句的介绍请参见这篇CSDN博文：verilog generate 生成语句 第五章 结构说明语句 initial说明语句，always说明语句 initial语句只执行一次，用于初始化；always语句不断地重复活动，直到仿真过程结束。 5.1 initial说明语句 语法： initial begin 语句1; 语句2; ... end 例6 用initial 块对存储器变量赋初值。 initial begin areg=0; for(index=0;index &lt; size;index=index+1) memory[index] = 0; end 5.2 always说明语句 语法： always &lt;时序控制&gt; begin 语句1; 语句2; ... end ","link":"https://kimokcheon.github.io/post/verilog/"},{"title":"CYK","content":"/* 输入格式： 第一行输入n, 表示生成式的个数, 输入要满足CNF. 之后n行，每行代表一个生成式。用大写字母代表变量, 其中S表示起始变量,小写字母代表终结符，若有epsilon, 用0表示。(变量和终结符个数&lt;=26) 生成式如下 S-&gt;AB, S-&gt;AB|a, S-&gt;a|b, 中间没有多余字符。 之后输入一个字符串，长度m &lt;= 500. 复杂度： O(m^3*n) */ #include &lt;bits/stdc++.h&gt; using namespace std; #define mkp make_pair const int N = 505; int n, m; bool f[N][N][27]; int from[N][N][27]; vector&lt;int&gt; who[27]; // 存可以生成终结符i的变量 pair&lt;int, int&gt; production[27]; // 存生成式 string w; bool Sto0; inline void readALine() { string x; getline(cin, x); char S = x[0]; if (x[3] == '0') { // S-&gt;0 Sto0 = true; } else { // S-&gt;AB... production[S-'A'] = mkp(x[3]-'A', x[4]-'A'); for (int i = 0; i &lt; x.length(); i ++) if (x[i] &lt;= 'z' and x[i] &gt;= 'a') who[x[i]-'a'].push_back(S-'A'); } } inline void debug() { for (int i = 0; i &lt; m; i ++) for (int j = i; j &lt; m; j ++) { vector&lt;int&gt; a; for (int k = 0; k &lt; 26; k ++) if (f[i][j][k]) a.push_back(k); if (a.size()) { printf(&quot;%d-%d : &quot;, i+1, j+1); for (auto x: a) printf(&quot;%c &quot;, x+'A'); puts(&quot;&quot;); } } } inline void printAPath() { queue &lt;pair&lt; pair&lt;int, int&gt;, int&gt; &gt; q; q.push(mkp(mkp(0, m-1), 'S'-'A')); bool ok = 0; while(!q.empty()) { int l = q.front().first.first, r = q.front().first.second, p = q.front().second; q.pop(); printf(&quot;%c&quot;, p+'A'); if (l == r) { q.push(mkp(mkp(l, l), p)); } else ok = 0; if (r == m - 1) { printf(&quot; -&gt; &quot;); if (ok) break; ok = 1; } if (l == r) continue; int k = from[l][r][p]; if (f[l][k][production[p].first] and f[k+1][r][production[p].second]) { q.push(mkp(mkp(l, k), production[p].first)); q.push(mkp(mkp(k+1, r), production[p].second)); } } cout &lt;&lt; w &lt;&lt; endl; } signed main() { freopen(&quot;test.txt&quot;, &quot;r&quot;, stdin); cin &gt;&gt; n; getchar(); for (int i = 1; i &lt;= n; i ++) readALine(); cin &gt;&gt; w; m = w.length(); if (Sto0) { // 如果 S-&gt; epsilon if (m == 1 and w[0] == '0') puts(&quot;Yes&quot;); else puts(&quot;No&quot;); return 0; } for (int i = 0; i &lt; m; i ++) for (auto x : who[w[i]-'a']) f[i][i][x] = 1, from[i][i][x] = i; for (int l = 2; l &lt;= m; l ++) { for (int i = 0 ; i &lt; m; i ++) { int j = i + l - 1; if (j &gt;= m) break; for (int k = i; k &lt; j; k ++) { for (int p = 0; p &lt; 26; p ++) { int A = production[p].first, B = production[p].second; if (A == 0 and B == 0) continue; if (f[i][k][A] and f[k+1][j][B]) f[i][j][p] = 1, from[i][j][p] = k; } } } } debug(); if (f[0][m-1]['S'-'A']) puts(&quot;Yes&quot;), printAPath(); else puts(&quot;No&quot;); return 0; } 4 S-&gt;AB A-&gt;BC|a B-&gt;AC|b C-&gt;a|b abaab ","link":"https://kimokcheon.github.io/post/cyk/"},{"title":"Linux操作","content":"快捷键 Tab: 命令和文件名补全； Ctrl+C: 中断正在运行的程序； Ctrl+D: 结束键盘输入(End Of File，EOF) VIM 三个模式 一般指令模式(Command mode): VIM 的默认模式，可以用于移动游标查看内容； 编辑模式(Insert mode): 按下 &quot;i&quot; 等按键之后进入，可以对文本进行编辑； 指令列模式(Bottom-line mode): 按下 &quot;:&quot; 按键之后进入，用于保存退出等操作。 在指令列模式下，有以下命令用于离开或者保存文件。 命令 作用 :w 写入磁盘 :w! 当文件为只读时，强制写入磁盘。到底能不能写入，与用户对该文件的权限有关 :q 离开 :q! 强制离开不保存 :wq 写入磁盘后离开 :wq! 强制写入磁盘后离开 ¶ 文件与目录的基本操作 ¶ 1. ls 列出文件或者目录的信息，目录的信息就是其中包含的文件。 ## ls [-aAdfFhilnrRSt] file|dir -a : 列出全部的文件 -d : 仅列出目录本身 -l : 以长数据串行列出，包含文件的属性与权限等等数据 2. cd 更换当前目录。 cd [相对路径或绝对路径] ¶ 3. mkdir 创建目录。 ## mkdir [-mp] 目录名称 -m : 配置目录权限 -p : 递归创建目录 ¶ 4. rmdir 删除目录，目录必须为空。 rmdir [-p] 目录名称 -p : 递归删除目录 ¶ 5. touch 更新文件时间或者建立新文件。 ## touch [-acdmt] filename -a : 更新 atime -c : 更新 ctime，若该文件不存在则不建立新文件 -m : 更新 mtime -d : 后面可以接更新日期而不使用当前日期，也可以使用 --date=&quot;日期或时间&quot; -t : 后面可以接更新时间而不使用当前时间，格式为[YYYYMMDDhhmm] ¶ 6. cp 复制文件。 如果源文件有两个以上，则目的文件一定要是目录才行。 cp [-adfilprsu] source destination -a : 相当于 -dr --preserve=all 的意思，至于 dr 请参考下列说明 -d : 若来源文件为链接文件，则复制链接文件属性而非文件本身 -i : 若目标文件已经存在时，在覆盖前会先询问 -p : 连同文件的属性一起复制过去 -r : 递归持续复制 -u : destination 比 source 旧才更新 destination，或 destination 不存在的情况下才复制 --preserve=all : 除了 -p 的权限相关参数外，还加入 SELinux 的属性, links, xattr 等也复制了 ¶ 7. rm 删除文件。 ## rm [-fir] 文件或目录 -r : 递归删除 ¶ 8. mv 移动文件。 ## mv [-fiu] source destination ## mv [options] source1 source2 source3 .... directory -f : force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 ¶ 获取文件内容 ¶ 1. cat 取得文件内容。 ## cat [-AbEnTv] filename -n : 打印出行号，连同空白行也会有行号，-b 不会 ¶ 2. tac 是 cat 的反向操作，从最后一行开始打印。 ¶ 3. more 和 cat 不同的是它可以一页一页查看文件内容，比较适合大文件的查看。 ¶ 4. less 和 more 类似，但是多了一个向前翻页的功能。 ¶ 5. head 取得文件前几行。 ## head [-n number] filename -n : 后面接数字，代表显示几行的意思 ¶ 6. tail 是 head 的反向操作，只是取得是后几行。 ¶ 7. od 以字符或者十六进制的形式显示二进制文件。 ¶ 指令与文件搜索 ¶ 1. which 指令搜索。 ## which [-a] command -a : 将所有指令列出，而不是只列第一个 ¶ 2. whereis 文件搜索。速度比较快，因为它只搜索几个特定的目录。 ## whereis [-bmsu] dirname/filename ¶ 3. locate 文件搜索。可以用关键字或者正则表达式进行搜索。 locate 使用 /var/lib/mlocate/ 这个数据库来进行搜索，它存储在内存中，并且每天更新一次，所以无法用 locate 搜索新建的文件。可以使用 updatedb 来立即更新数据库。 ## locate [-ir] keyword -r: 正则表达式 ¶ 4. find 文件搜索。可以使用文件的属性和权限进行搜索。 ## find [basedir] [option] example: find . -name &quot;shadow*&quot; 压缩与打包 ¶ 压缩文件名 Linux 底下有很多压缩文件名，常见的如下: 扩展名 压缩程序 .Z compress .zip zip .gz gzip .bz2 bzip2 .xz xz .tar tar 程序打包的数据，没有经过压缩 .tar.gz tar 程序打包的文件，经过 gzip 的压缩 .tar.bz2 tar 程序打包的文件，经过 bzip2 的压缩 .tar.xz tar 程序打包的文件，经过 xz 的压缩 ¶ 压缩指令 ¶ 1. gzip gzip 是 Linux 使用最广的压缩指令，可以解开 compress、zip 与 gzip 所压缩的文件。 经过 gzip 压缩过，源文件就不存在了。 有 9 个不同的压缩等级可以使用。 可以使用 zcat、zmore、zless 来读取压缩文件的内容。 $ gzip [-cdtv#] filename -c : 将压缩的数据输出到屏幕上 -d : 解压缩 -t : 检验压缩文件是否出错 -v : 显示压缩比等信息 -## : ## 为数字的意思，代表压缩等级，数字越大压缩比越高，默认为 6 ¶ 2. bzip2 提供比 gzip 更高的压缩比。 查看命令: bzcat、bzmore、bzless、bzgrep。 $ bzip2 [-cdkzv#] filename -k : 保留源文件 ¶ 3. xz 提供比 bzip2 更佳的压缩比。 可以看到，gzip、bzip2、xz 的压缩比不断优化。不过要注意的是，压缩比越高，压缩的时间也越长。 查看命令: xzcat、xzmore、xzless、xzgrep。 $ xz [-dtlkc#] filename ¶ 打包 压缩指令只能对一个文件进行压缩，而打包能够将多个文件打包成一个大文件。tar 不仅可以用于打包，也可以使用 gip、bzip2、xz 将打包文件进行压缩。 $ tar [-z|-j|-J] [cv] [-f 新建的 tar 文件] filename... ==打包压缩 $ tar [-z|-j|-J] [tv] [-f 已有的 tar 文件] ==查看 $ tar [-z|-j|-J] [xv] [-f 已有的 tar 文件] [-C 目录] ==解压缩 -z : 使用 zip； -j : 使用 bzip2； -J : 使用 xz； -c : 新建打包文件； -t : 查看打包文件里面有哪些文件； -x : 解打包或解压缩的功能； -v : 在压缩/解压缩的过程中，显示正在处理的文件名； -f : filename: 要处理的文件； -C 目录 : 在特定目录解压缩。 使用方式 命令 打包压缩 tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称 查 看 tar -jtv -f filename.tar.bz2 解压缩 tar -jxv -f filename.tar.bz2 -C 要解压缩的目录 正则表达式 ¶ grep g/re/p(globally search a regular expression and print)，使用正则表示式进行全局查找并打印。 $ grep [-acinv] [--color=auto] 搜寻字符串 filename -c : 统计个数 -i : 忽略大小写 -n : 输出行号 -v : 反向选择，也就是显示出没有 搜寻字符串 内容的那一行 --color=auto : 找到的关键字加颜色显示 示例: 把含有 the 字符串的行提取出来(注意默认会有 --color=auto 选项，因此以下内容在 Linux 中有颜色显示 the 字符串) $ grep -n 'the' regular_express.txt 8:I can't finish the test. 12:the symbol '*' is represented as start. 15:You are the best is mean you are the no. 1. 16:The world Happy is the same with &quot;glad&quot;. 18:google is the best tools for search keyword 因为 { 和 } 在 shell 是有特殊意义的，因此必须要使用转义字符进行转义。 $ grep -n 'go\\{2,5\\}g' regular_express.txt ¶ printf 用于格式化输出。 它不属于管道命令，在给 printf 传数据时需要使用 $( ) 形式。 $ printf '%10s %5i %5i %5i %8.2f \\n' $(cat printf.txt) DmTsai 80 60 92 77.33 VBird 75 55 80 70.00 Ken 60 90 70 73.33 ¶ awk 是由 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 创造，awk 这个名字就是这三个创始人名字的首字母。 awk 每次处理一行，处理的最小单位是字段，每个字段的命名方式为: $n，n 为字段号，从 1 开始，$0 表示一整行。 示例: 取出登录用户的用户名和 IP $ last -n 5 dmtsai pts/0 192.168.1.100 Tue Jul 14 17:32 still logged in dmtsai pts/0 192.168.1.100 Thu Jul 9 23:36 - 02:58 (03:22) dmtsai pts/0 192.168.1.100 Thu Jul 9 17:23 - 23:36 (06:12) dmtsai pts/0 192.168.1.100 Thu Jul 9 08:02 - 08:17 (00:14) dmtsai tty1 Fri May 29 11:55 - 12:11 (00:15) $ last -n 5 | awk '{print $1 &quot;\\t&quot; $3}' 可以根据字段的某些条件进行匹配，例如匹配字段小于某个值的那一行数据。 $ awk '条件类型 1 {动作 1} 条件类型 2 {动作 2} ...' filename 示例: /etc/passwd 文件第三个字段为 UID，对 UID 小于 10 的数据进行处理。 $ cat /etc/passwd | awk 'BEGIN {FS=&quot;:&quot;} $3 &lt; 10 {print $1 &quot;\\t &quot; $3}' root 0 bin 1 daemon 2 awk 变量: 变量名称 代表意义 NF 每一行拥有的字段总数 NR 目前所处理的是第几行数据 FS 目前的分隔字符，默认是空格键 示例: 显示正在处理的行号以及每一行有多少字段 $ last -n 5 | awk '{print $1 &quot;\\t lines: &quot; NR &quot;\\t columns: &quot; NF}' dmtsai lines: 1 columns: 10 dmtsai lines: 2 columns: 10 dmtsai lines: 3 columns: 10 dmtsai lines: 4 columns: 10 dmtsai lines: 5 columns: 9 ","link":"https://kimokcheon.github.io/post/linux-cao-zuo/"},{"title":"面向对象知识点","content":"1. C++ Classes Introduction 1.1 class vs. struct 1.2 Data members and Function Members Declaration and Definition 1.3 RAII and Smart Pointers Resource Acquisition is Initialization Resource Acquisition Is Initialization Smart Pointers:unique_ptr,shared_ptr,weak_ptr 2. Class Hierarchy Child/Derived Class; Parent/Base Class; Extend. 多态初探 2.1 Access Specifiers pulic, protected, private 2.2 Inheritance Access Specifiers pulic, protected, private 2.3 Namespace 3. Class Constructor and Destructor 3.1 Intro 3.2 Default Constructor 3.3 Class Initialization 3.3.1 Initializer List 3.3.2 In-Class Member Initializer 3.3.3 Initialization Order follows the order of declarations and not the order in the initialization list 3.3.4 Uniform Initialization 3.4 Constructors and Inheritance Class constructors are never inherited; called order. 3.5 Delegate Constructor 3.6 explicit Keyword 3.7 Copy Constructor 3.8 Move Constructor 3.8.1 Move Semantics 3.8.2 std: :move 3.8.3 lvalues and rvalues references 3.8.4 move operations(c++11) 3.8.5 std: :vector&lt;T,Allocator&gt;: :emplace_back 4.Templates 4.1 Template functions 4.2 Announcements 4.3 Concept Lifting 4.4 Generic Programming and Lifting 5.Functions and Algorithm 5.1 Lambda functions 5.2 STL Algorithm 6. Class Keywords 6.1 this 6.2 static Initialization 6.3 const 6.4 mutable 6.5 using Type Declaration Inheritance 6.6 friend Friend class Friend member function 6.7 delete 7. Polymorphism Polymorphism vs. Overloading. Function binding. Static binding Dynamic binding 7.1 virtual methods Usage. When virual methods works. 7.2 Virtual Table Never use malloc in C++. 7.3 override keyword for safety 7.4 final keyword for safety 7.5 Common Errors All classes with at least one virtual method should declare a virtual destructor Do not call virtual methods in constructor and destructor Do not use default parameters in virtual methods 7.6 Pure Virtual Method 7.7 Abstract Class and Interface 8. Inheritance Casting and Run-time Type Identification 8.1 Hierarchy Casting Upcasting Downcasting Sidecasting 8.2 RTTI type_info class typeid keyword dynamic_cast keyword 9. Operator Overloading 9.1 Overview 9.2 operator[] 9.3 operator&lt; 9.4 operator&lt;=&gt; 9.5 operator() 9.6 operator T() 9.7 Return type overloading resolution 9.8 operator ++/-- 9.9 operator type= 9.10 operator &lt;&lt; 9.11 Others Principle of Least Astonishment(POLA) Operators preserve precedence and short-circuit properties Binary operators should be implemented as friend method 10. Error Handing 10.1 C++ Exceptions 10.2 Defining Custom Exceptions 10.3 noexcept Keyword 10.4 Memory Allocation Issues 10.5 Alternative Error Handling Approaches ","link":"https://kimokcheon.github.io/post/mian-xiang-dui-xiang-zhi-shi-dian/"},{"title":"AI Research Tool","content":"AI-research-tools 推荐一些我喜欢的科研工具（有些限定于 AI 领域） 标记【待尝试】的是我还未使用过但感觉比较有用的工具，会尽快尝试并根据体验决定是否保留 请通过 issues 等方式向我推荐您觉得好用的但不在此清单上的 AI 领域科研工具，感谢 目录 AI-research-tools 趋势关注 RSS 阅读器 论文查找 搜索引擎 arXiv 相关 代码实现查找 论文阅读 查阅下载 文献管理 文献翻译 笔记工具 编码实验 Pytorch 相关 功能配置封装 项目参考 项目管理 风格指南 项目模板 神经网络分析器 可视化 实验记录 数据集查找 数据集下载 特征工程 超参搜索 Debug 工具 论文写作 LaTeX 模板 LaTeX 编辑器 语言表达 搭配查找 句式推荐 写作检查 公式编辑 截屏悬浮 表格转 LaTeX 绘制示意图 绘图工具 绘图参考 PPT 插件 图片转换 图片休整 论文投递 会议期刊查找筛选 匿名链接 arXiv 提交 代码开源 其他 专利检索 专注工作 白噪声 / 音乐 趋势关注 RSS 阅读器 irreader 阅读器：这是我现在在使用的 RSS 阅读器。一个非常大的优点是，对于一些没有提供 RSS 订阅源的网站，irreader 可以自定义 RSS 订阅源。另外，订阅的 RSS 更新时，有弹窗提醒。还有一个我暂时用不到的功能是，irreader 同时支持订阅播客和播放有声媒体。 论文查找 搜索引擎 Google scholar：搜索论文的首选，可以在这里查看论文统计和引用参考文献，还能通过关注作者或者论文获得新论文更新提醒，以及利用自动化推荐来提供一个基本库。 Semantic scholar：可以结合外部材料整合进行论文的语义分析。功能包括：展示引用和参考文献、度量论文影响力、展示论文图表、自动生成关键词（根据标题）、分析作者、在互联网寻找额外资源（例如，相关 youtube 视频），以及推荐论文。 dblp: computer science bibliography：专为 CS 设计的论文查询网站，收录比较顶级并可以被检索到的论文。可以根据会议、期刊等分类查询作者的论文，想搜一个计算机会议的所有文章时好用。 中国知网海外服务：支持全 PDF 格式下载。具体可见 海外版知网升级了！（全PDF下载），从此告别CAJ阅读器！。 arXiv 相关 arXiv: 论文预印本收录网站。 arXiv-sanity：在功能上相比于 arXiv 有很大的改进，包括在浏览中显示摘要、评论和非常基本的社交、推荐、库功能。搜索也更好用。 Semantic Sanity: A Personalized Adaptive Feed：创建自己的个性化 arXiv 选读 Feed。创建每个 Feed 时，会让您先选择几篇论文，然后根据这几篇论文开始推荐，对于推荐结果可以点赞或者不喜欢来帮助调整推荐结果。 卖萌屋Arxiv服务: 只包含 arxiv 当日更新的论文。优点在于把作者机构也展示出来。仍在改进。 Paper Digest – AI for tracking and summarizing papers: 提供邮件订阅前一天出的论文的列表，附有每篇论文的一句话总结。对我更重要的是这个网站也会在每个顶会论文全部公布时进行整理。 代码实现查找 Papers With Code：自动把论文连接到实现代码的 GitHub 资源库和数据集，并根据 GitHub 的收藏量排序。展示各任务上的 SOTA 以供比较。 labmlai/annotated_deep_learning_paper_implementations：很多算法的 PyTorch 实现，带有在线版的注释。缺点是展示的部分不是从头实现，一部分代码放在他们自己的包里了。 论文阅读 查阅下载 SCI-Hub 科研论文全文下载可用网址 文献管理 Mendeley：支持 web、PC、Mac 和移动手机等多个平台，可以直接注释和高亮显示 PDF，有限额的免费云存储。另外有每周邮件推荐论文。 文献翻译 CopyTranslator：最大的优点在于有置顶、点按复制、监听剪贴板等功能，阅读文献配合使用时可以无缝切换，非常方便。 Saladict 沙拉查词：浏览器翻译插件，有非常丰富的设置来配合用户的使用习惯。除了官方文档，也可以看 沙拉查词 + Alfred，打造最佳文献翻译体验！ 来了解。我还在探索如何在 Windows 系统上实现浏览器外翻译。 笔记工具 我个人习惯使用印象笔记。 编码实验 Pytorch 相关 功能配置封装 pytorch-lightning：将 PyTorch 开发中的各种通用配置（训练验证逻辑、超参搜索、分布式训练等）全部包装起来，以更高级的形式快速搭建模型。功能强大，有些复杂，正在摸索。机器之心写的简介 项目参考 the-incredible-pytorch：有关 PyTorch 的各种教程、项目、视频等资源。 computervision-recipes：微软出品，基于 PyTorch 的各种 CV 任务的教程。 项目管理 torchtracer：一个管理 PyTorch AI 实验项目的工具，主要用于保存各类训练数据（模型 checkpoints、超参数组合、日志、loss 变化曲线图像等）。 风格指南 pytorch-styleguide：一份 PyTorch 的非官方风格指南和最佳实践总结。 项目模板 Pytorch-Project-Template：一个可扩展的 PyTorch 项目模板，包括图像分割、目标分类、GANs 和强化学习等实例。 pytorch-template：另一份 PyTorch 项目模板。 神经网络分析器 torchinfo：打印 PyTorch 模型信息，包含模型每层的参数量、输出张量大小等。 flops-counter.pytorch：计算模型总共的 FLOPs（浮点运算数，理解为计算量，可以用来衡量算法/模型的复杂度）以及每层的占比。缺点是似乎不支持 RNN 相关层，另外打印下来的信息不是很方便看。 可视化 PyTorch 最新版本已经带有 tensorboard。官方 tutorial。 visdom：【待尝试】用于创建、组织和共享实时丰富数据可视化的灵活工具。 Convolution Visualizer：如果卷积层配置比较复杂，不方便计算输出大小时，可以利用这个可视化工具辅助。 实验记录 fitlog：【待尝试】架构无关的实验记录工具，可以看邱锡鹏老师在知乎写的介绍。 数据集查找 Google Dataset Search Data Search | Bifrost：视觉数据集搜索。 数据集下载 gdown：用于解决在 Google Drive 上下载大型数据集常发生的失败现象。 特征工程 Featuretools：【待尝试】自动化特征工程库。 超参搜索 optuna：自动超参数优化框架。 microsoft/nni：【待尝试】用于神经模型搜索和超参数调优的开源自动机器学习（AutoML）的工具包，支持绝大多数主流框架和运行环境。 Hyperopt：【待尝试】分布式异步超参数优化。看到知乎上有人推荐，不过根据文档来看，目前支持的优化算法只有两种，且不包括贝叶斯优化。 BoTorch：【待尝试】基于 PyTorch 的贝叶斯优化库。 automl/Auto-PyTorch：【待尝试】基于 PyTorch 的自动结构搜素和超参数搜索。 Debug 工具 PySnooper：【待尝试】致力让用户抛弃print函数来 debug（然而，至少目前我还是习惯用 logging 模块，和print差不了多少）。机器之心写的简介 论文写作 LaTeX 模板 包括论文、报告、海报等在内的各种 LaTeX 模板。 Templates from Overleaf LaTeX Templates LaTeX 编辑器 我个人习惯使用 VSCode 进行离线的 LaTeX 写作，配合 Github 私有库进行版本管理。 Overleaf：支持多人协作的在线 LaTeX 编辑器。但是对网络连接有一定要求。 语言表达 搭配查找 可以看一下这篇文章的推荐：有了这些网站，英文论文再也不难写了（15个英文论文写作辅助网站介绍和使用技巧） - 知乎 Linggle：搜索最常出现的英文词语搭配。不确定自己的表达方式是否正确时使用。 Corpus of Contemporary American English (COCA)：可以查词汇搭配的美式英语语料库，可以查看具体的用了这个词的句子。 British National Corpus (BYU-BNC)：英式英语的语料库，语料比美式的少一些 Thesaurus：将低端词汇转换为同义的高端词汇。 易搜搭ESODA：清华HCI Lab工作室出品的一款适合国人英语写作的词组搭配查询工具。可切换具体研究方向的论文语料库，展示相关的可替换用法，支持中英混搜。 Words and phrases: frequency, genres, collocates, concordances, synonyms, and WordNet：用不同颜色区分高中低频词，展现代表文章类型的词汇，并归类出相关可替换的词。虽然说是英文写作措辞辅助工具，感觉最大的用途是学习相关领域论文常用的词汇和搭配。 句式推荐 Academic Phrasebank：学术用语库，告诉你各个章节适合用哪些句式搭配。 写作检查 请注意在线检测工具的泄露风险，谨慎处理关键文字。 Grammarly：语法、句型、标点、选词检测修改，有浏览器插件。 Nounplus.net：免费的在线英文语法检测。 proofread：【待尝试】对科学文章草稿自动检查，寻找不符合英文科学写作标准的部分，并提出修改意见。作者写的介绍：分享一个自己做的英文科学写作检查器 - 知乎。 公式编辑 Mathpix：通过截取复杂数学方程式的截图将其转换为 LaTeX 代码。可以处理 PDF 的印刷体和照片中的手写公式等。 MyScript Webdemo：Math 模块可以将手写公式转为 LaTeX 代码；同时，Diagram 模块可以将手绘的框图转化为工整的框图。 Detexify LaTeX handwritten symbol recognition: 忘记某些字符用 LaTeX 怎么表示时，可以在这个网站上通过手写来查询。 截屏悬浮 写论文时经常会遇到需要参考多个文献或代码的情况，同时查看多个文件并频繁切换会非常麻烦。这里是别人推荐的两个能够将截图悬浮置顶的工具，并随时调整位置和大小，方便写作时参考。 Snipaste：【待尝试】有 Windows 和 Mac 版，暂时没有 Linux 版。 Snappy：【待尝试】有 Mac 和 iPhone &amp; iPad 版，暂时没有 Windows 版。 表格转 LaTeX Excel2LaTeX：用在 Excel 上的宏工具，能够将 Excel 表格转换为 LaTeX 代码，节省很多时间。能够满足大多数效果的转换，有些效果可能需要微调。 绘制示意图 绘图工具 PPT 通常是我的第一选择：入手快，种类多，自由度高，支持导出矢量图。 Inkscape with latex equation extensions：【待尝试】 http://Lucidchart.com：在线画矢量图，可以导出 png、pdf，也支持各种颜色，组合和图层等。 绘图参考 Paper-Picture-Writing-Code：基于 LaTex 的画图代码，包含折线图、柱状图、散点图、注意力可视化以及结构图。 academic-drawing：Matlab/Python 绘图，主要用于画时序数据。 awesome-latex-drawing：LaTeX 绘图，主要用于画贝叶斯网络、张量分解等。 PlotNeuralNet：Python 得到可用于 LaTeX 的图，主要画 CNN。 PPT 插件 IguanaTex：帮助插入 LaTeX 公式的 PPT 插件。将输入的 LaTeX 代码转换为高质量的 png 图片来插入。 图片转换 提供各种格式的图片的转换服务的网站很多。这里只是简单列举，你也可以通过搜索引擎来找到其他类似的网站。 Convert PNG/JPEG (Raster) to EPS/PDF (Vector) Format：将 jpg、png 格式的图片文件转换为 eps 文件。 EPS到PDF转换器：也可以将 eps 文件转换为别的格式的图片。 图片休整 Crop PDF files online - PDF Tools：裁剪 pdf 文件的白边。 在命令行中直接将 eps 转换为 pdf：epstopdf &lt;file.eps&gt;；自动裁剪 pdf 的白边：pdfcrop &lt;file.pdf&gt;。 论文投递 会议期刊查找筛选 ccf-deadlines：可以根据研究方向和 CCF 等级来筛选本年度已经确定截稿日期的会议。对国内的同学比较友好。 AI Conference Deadlines：可以根据研究方向筛选会议。但是好像需要科学上网才能看到全部信息。 Conference List：根据截稿时间排序，过期的会议不在首页出现。有一页可以看每个研究方向有哪些会议，但是没有办法根据研究方向筛选还没过期的会议。 Conference Partner (会伴)：计算机最新国际会议和期刊列表。可以注册以关注会议或期刊。比较全，但目前信息更新不及时。 Conference-Acceptance-Rate：主要会议近年录取率统计。 匿名链接 出于论文盲审考虑，有时候文件（如源码）链接需要是匿名的。有些人会选择在 Github 上创建一个匿名用户，但为每一个会议的每一篇论文都创建一个之后再用不到的用户过于繁琐。我查到有一些工具支持匿名分享文件如下。 Dropbox：应该是最常用的。 Open Science Framework Figshare arXiv 提交 Arxiv 论文提交流程——看这篇就够了：文章，用于了解将论文提交至 arXiv 上的流程。 arxiv-latex-cleaner：将论文的 LaTeX 代码清理为提交至 arXiv 上的要求。一个亮点是能够自动清理掉论文中所有被注释掉的内容。 overleaf -&gt; arxiv 丝滑提交过程：如果是使用 Overleaf（而不是在本地将 LaTeX 代码编译为论文），可以先参考本文下载合适的源码包，然后再考虑使用 arxiv-latex-cleaner。 代码开源 为已发表的论文提供清晰、可复现的代码能够有效推动领域发展。这里推荐一些对开源代码有帮助的工具。 ReproducibilityChecklist-v2.0：一份机器学习复现清单，列举了你应该提供哪些文件来增强你的论文的可复现性。 pigar：Python 项目 requirements 文件自动生成工具。 其他 专利检索 Google Patents：免费检索和下载中英文专利。具体可见 Google Patents，免费检索和下载中英文专利的最佳工具！。 专注工作 番茄·人生：Windows PC 端待办事项软件，番茄工作法时钟。 白噪声 / 音乐 Rainyscope rain simulator：下雨声。 lofi.cafe - lofi music 🎧：随机播放 Lo-Fi 音乐，习惯在工作时听音乐的同学可以尝试一下。需要科学上网。 ","link":"https://kimokcheon.github.io/post/ai-research-tool/"},{"title":"Operating System","content":"**List and briefly define the four main elements of a computer.**A processor, which controls the operation of the computer and performs its data processing functions ; a main memory, which stores both data and instructions; I/O modules, which move data between the computer and its external environment; and the system bus, which provides for communication among processors, main memory, and I/O modules. In general terms, what are the four distinct actions that a machine instruction can specify? (1) Processor-memory: Data may be transferred from processor to memory or from memory to processor. (2) Processor-I/O: Data may be transferred to or from a peripheral device by transferring between the processor and an I/O module. (3) Data processing: The processor may perform some arithmetic or logic operation on data. (4) Control: An instruction may specify that the sequence of execution be altered. What is an interrupt? An interrupt is a mechanism by which other modules (I/O, memory) may interrupt the normal sequencing of the processor How can multiple interrupts be serviced by setting priorities? Multiple interrupts may be serviced by assigning different priorities to interrupts arising from different sources. This enables a higher-priority interrupt to be serviced first when multiple requests arrive simultaneously; it also allows a higher-priority interrupt to pre-empt a lower-priority interrupt. For example, suppose a system has assigned a higher priority to a communication line and a lower priority to a magnetic disk. When two simultaneous requests arrive, the computer services the communication line. Similarly, if some disk operations are ongoing when a request for the communication line arrives, the state of the disk is put in a stack and the communication line operations are catered to. How can multiple interrupts be serviced by setting priorities? Multiple interrupts may be serviced by assigning different priorities to interrupts arising from different sources. This enables a higher-priority interrupt to be serviced first when multiple requests arrive simultaneously; it also allows a higher-priority interrupt to pre-empt a lower-priority interrupt. For example, suppose a system has assigned a higher priority to a communication line and a lower priority to a magnetic disk. When two simultaneous requests arrive, the computer services the communication line. Similarly, if some disk operations are ongoing when a request for the communication line arrives, the state of the disk is put in a stack and the communication line operations are catered to. What characteristics are observed while going up the memory hierarchy? (1) Increasing cost per bit (2) Decreasing capacity (3) Decreasing access time (4) Increasing frequency of access to the memory by the processor What is the difference between a multiprocessor and a multicore system? A multicore computer is a special case of a multiprocessor, in which all of the processors are on a single chip. What are three objectives of an OS design? (1) Convenience: OS makes computer more convenient to use (2) Efficiency: OS allows computer system resources to be used in an efficient manner (3) Ability to evolve: OS should be constructed in such a way as to permit effective development, testing, and introduction of new system functions without interfering with service. What is the kernel of an OS? The kernel is a portion of the operating system that includes the most heavily used portions of software. Generally, the kernel is maintained permanently in main memory. The kernel runs in a privileged mode and responds to calls from processes and interrupts from devices. What is multiprogramming? Multiprogramming is a mode of operation that provides for the interleaved execution of two or more computer programs by a single processor. What is a process? A process is a program in execution. A process is controlled and scheduled by the operating system. How is the execution context of a process used by the OS? The execution context, or process state, is the internal data by which the operating system is able to supervise and control the process. This internal information is separated from the process, because the operating system has information not permitted to the process. The context includes all of the information that the operating system needs to manage the process and that the processor needs to execute the process properly. The context includes the contents of the various processor registers, such as the program counter and data registers. It also includes information of use to the operating system, such as the priority of the process and whether the process is waiting for the completion of a particular I/O event. List and briefly explain five storage management responsibilities of a typical OS. Process isolation:The operating system must prevent independent processes from interfering with each other's memory, both data and instructions. Automatic allocation and management: Programs should be dynamically allocated across the memory hierarchy as required. Allocation should be transparent to the programmer. Thus, the programmer is relieved of concerns relating to memory limitations, and the operating system can achieve efficiency by assigning memory to jobs only as needed. Support of modular programming: Programmers should be able to define program modules, and to create, destroy, and alter the size of modules dynamically. Protection and access control: Sharing of memory, at any level of the memory hierarchy, creates the potential for one program to address the memory space of another. This is desirable when sharing is needed by particular applications. At other times, it threatens the integrity of programs and even of the operating system itself. The operating system must allow portions of memory to be accessible in various ways by various users. Long-term storage: Many application programs require means for storing information for extended periods of time, after the computer has been powered down. 2.7. What is time slicing? A technique adopted in time-sharing systems to distribute CPU time to multiple users. In this technique, a system clock generates interrupts at a particular rate. At each clock interrupt, the OS regains control and can assign the processor to another user. Thus, at regular time intervals, the current user is preempted and another user is loaded in. To preserve the old user program status for later resumption, the old user programs and data are written out to disk before the new user programs and data are read in. Subsequently, the old user program code and data are restored in main memory when that program is given a turn in a subsequent time-slice. 2.8. Describe the round-robin scheduling technique. Round robin is a scheduling algorithm in which processes are activated in a fixed cyclic order; that is, all processes are in a circular queue. A process that cannot proceed because it is waiting for some event (e.g. termination of a child process or an input/output operation) returns control to the scheduler. 2.9(old). Explain the difference between a monolithic kernel and a microkernel. A monolithic kernel is a large kernel containing virtually the complete operating system, including scheduling, file system, device drivers, and memory management. All the functional components of the kernel have access to all of its internal data structures and routines. Typically, a monolithic kernel is implemented as a single process, with all elements sharing the same address space. A microkernel is a small privileged operating system core that provides process scheduling, memory management, and communication services and relies on other processes to perform some of the functions traditionally associated with the operating system kernel. **2.10. What is multithreading?**Multithreading is a technique in which a process, executing an application, is divided into threads that can run concurrently. **2.11(old). List the key design issues for an SMP(对称多处理) operating system.**Simultaneous concurrent processes or threads; scheduling; synchronization; memory management; reliability and fault tolerance. 3.1. What is an instruction trace? An instruction trace for a program is the sequence of instructions that execute for that process. 3.2. Explain the concept of a process and mark its differences from a program. A process is an instance of a program being executed. A program is a passive entity whereas a process is an active entity. 3.7. List four characteristics of a suspended process. (1) The process is not immediately available for execution. (2) The process may or may not be waiting on an event. If it is, this blocked condition is independent of the suspend condition, and occurrence of the blocking event does not enable the process to be executed. (3) The process was placed in a suspended state by an agent; either itself, a parent process, or the operating system, for the purpose of preventing its execution. (4) The process may not be removed from this state until the agent explicitly orders the removal. 3.9. What are the elements of a process image? (1) User Program: Comprises the program to be executed (2) User Data: modifiable part of user space. Generally, includes a user stack area, program data, and programs that can be modified (3) Stack: Used to store parameters and calling addresses for procedures and system calls. Each process has one or more LIFO (Last In First Out) stacks associated with (4) Process Control Block: Contains many pieces of information associated with a specific process, like process identifier, process state information, and process control information 3.11. What are the steps performed by an OS to create a new process? (1) Assign a unique process identifier to the new process. (2) Allocate space for the process. (3) Initialize the process control block. (4) Set the appropriate linkages. (5) Create or expand other data structures. 3.13. Give three examples of an interrupt. Clock interrupt, I/O interrupt, memory fault. 4.2. List reasons why a mode switch between threads may be cheaper than a mode switch between processes. Less state information is involved. 4.3. What are the two separate and potentially independent characteristics embodied in the concept of process? Resource ownership and scheduling/execution. Shared memory. Reduced context switching. Faster synchronization mechanisms. 4.4. Give four general examples of the use of threads in a single-user multiprocessing system. Foreground/background work; asynchronous processing; speedup of execution by parallel processing of data; modular program structure. 4.5. How is a thread different from a process? Process: (1) Generally, more than one process cannot share same memory. Sharing memory among processes requires additional memory-management schemes (2) Process creation, process execution, and process switch are time consuming. (3) Processes are generally loosely coupled and so a lesser amount of resource sharing is possible. (4) Communication between processes is difficult and requires system calls. Thread: (1) Threads of the same process can share the same memory unless they are specially allotted separate memory locations. (2) Thread creation, thread execution, and thread switch are much faster in comparison. (3) As the threads of a process are tightly coupled; a greater amount of resource sharing is possible. (4) Communication between threads is much easier and more efficient. 4.6. What are the advantages of using multithreading instead of multiple processes?(1) the costs associated with context switching, communication, data sharing, and synchronisation are lower. (2) On single-processor machines, multithreading is particularly advantageous when the jobs are varied in terms of time and resource requirements and when some jobs require concurrent processing. (3) On multiprocessor systems, multithreading may be able to take advantage of the additional hardware (if OS supports it), thus resulting in better overall performance. 5.1. List four design issues for which the concept of concurrency is relevant. Communication among processes, sharing of and competing for resources, synchronization of the activities of multiple processes, and allocation of processor time to processes. 5.2. What are three contexts in which concurrency arises? Multiple applications, structured applications, operating-system structure. 5.3. What is a race condition? A race condition occurs when multiple processes or threads read and write data items so that the final outcome depends on the order of execution of instructions in the multiple processes. 5.4. List three degrees of awareness between processes and briefly define each. (1) Processes unaware of each other: These are independent processes that are not intended to work together. (2) Processes indirectly aware of each other: These are processes that are not necessarily aware of each other by their respective process IDs, but that share access to some object, such as an I/O buffer. (3) Processes directly aware of each other: These are processes that are able to communicate with each other by process ID and which are designed to work jointly on some activity. 5.5. What is the distinction between competing processes and cooperating processes? Competing processes need access to the same resource at the same time, such as a disk, file, or printer. Cooperating processes either share access to a common object, such as a memory buffer or are able to communicate with each other, and cooperate in the performance of some application or activity. 5.6. List the three control problems associated with competing processes, and briefly define each. (1) Mutual exclusion: competing processes can only access a resource that both wish to access one at a time; mutual exclusion mechanisms must enforce this one-at-a-time policy. (2) Deadlock: if competing processes need exclusive access to more than one resource then deadlock can occur if each processes gained control of one resource and is waiting for the other resource. (3) Starvation: one of a set of competing processes may be indefinitely denied access to a needed resource because other members of the set are monopolizing that resource. 5.7. What is starvation with respect to concurrency control by mutual exclusion? Starvation refers to a situation where a runnable process is infinitely overlooked by the scheduler for performance of a certain activity. In the context of concurrency control using mutual exclusion, this situation occurs when many processes are contending to enter in the critical section and a process is indefinitely denied access. Although this process is ready to execute in its critical section, it is never chosen and as an outcome never runs to completion. 5.8. What operations can be performed on a semaphore? (1) A semaphore may be initialized to a nonnegative value. (2) The wait operation decrements the semaphore value. If the value becomes negative, then the process executing the wait is blocked. (3) The signal operation increments the semaphore value. If the value is not positive, then a process blocked by a wait operation is unblocked. 5.9. What is the difference between binary and general semaphores? A binary semaphore may only take on the values 0 and 1. A general semaphore may take on any integer value. **5.10. What is the key difference between a mutex and a binary semaphore?**The key difference between the two is that the process that locks a mutex must be the one to unlock it; in a semaphore implementation, however, if the operation wait(s) is executed by one process, the operation signal(s) can be executed by any process 6.1. Give examples of reusable and consumable resources. Examples of reusable resources are processors, I/O channels, main and secondary memory, devices, and data structures such as files, databases, and semaphores. Examples of consumable resources are interrupts, signals, messages, and information in I/O buffers. 6.2. What are the three conditions that must be present for deadlock to be possible? (1) Mutual exclusion. Only one process may use a resource at a time. (2) Hold and wait. A process may hold allocated resources while awaiting assignment of others. (3) No preemption. No resource can be forcibly removed from a process holding it. 6.3. What are the four conditions that create deadlock? (1) Mutual exclusion. Only one process may use a resource at a time. (2) Hold and wait. A process may hold allocated resources while awaiting assignment of others. (3) No preemption. No resource can be forcibly removed from a process holding it. (4) Circular wait. A closed chain of processes exists, such that each process holds at least one resource needed by the next process in the chain. 6.4. How can the hold-and-wait condition be prevented? The hold-and-wait condition can be prevented by requiring that a process request all of its required resources at one time, and blocking the process until all requests can be granted simultaneously. 6.5. Why can’t you disallow mutual exclusion in order to prevent deadlocks? Mutual exclusion restricts the usage of a resource to one user at a time. If mutual exclusion is disallowed, then all non-sharable resources become sharable. While this may not hamper some activities (like a read-only file being accessed by a number of users), it poses serious problems for activities that require non-sharable resources (like writing to a file). Preventing mutual exclusion in these situations gives undesirable results. Also, there are some resources (like printers) that are inherently non-sharable, and it is impossible to disallow mutual exclusion. Thus, in general, mutual exclusion cannot be disallowed for practical purposes. 6.6. How can the circular wait condition be prevented? The circular-wait condition can be prevented by defining a linear ordering of resource types. If a process has been allocated resources of type R, then it may subsequently request only those resources of types following R in the ordering. 6.7. List some of the methods that may be adopted to recover from deadlocks.(1) Abort all deadlocked processes. Though this is a common solution adopted in operating systems, the overhead is very high in this case. (2) Back up each deadlocked process to some previously defined checkpoint and restart all processes. (3) Detect the deadlocked processes in a circular-wait condition. Successively abort deadlocked processes until the circular wait is eliminated and the deadlock no longer exists. (4) Successively preempt resources until the deadlock no longer exists 7.1. What requirements is memory management intended to satisfy? Relocation, protection, sharing, logical organization, physical organization. 7.2. What is relocation of a program? To relocate a program is to load and execute a given program to an arbitrary place in the memory; therefore, once a program is swapped out to the disk, it may be swapped back anywhere in the main memory. 7.3. What are the advantages of organizing programs and data into modules? (1) Modules can be written and compiled independently. All references from one module to another can be resolved by the system at run time. (2) Each module can be given different degrees of protection (like read only, read-write, execute only, read-write-execute, etc.). The overhead associated with this is quite nominal. (3) A module can be shared among different processes by incorporating appropriate mechanisms. **7.4. What are some reasons to allow two or more processes to all have access to a particular region of memory?**If a number of processes are executing the same program, it is advantageous to allow each process to access the same copy of the program rather than have its own separate copy. Also, processes that are cooperating on some task may need to share access to the same data structure. **7.6. What is the difference between internal and external fragmentation?**Internal fragmentation refers to the wasted space internal to a partition due to the fact that the block of data loaded is smaller than the partition. External fragmentation is a phenomenon associated with dynamic partitioning, and refers to the fact that a large number of small areas of main memory external to any partition accumulates. 7.8. What is the difference between a page and a frame? In a paging system, programs and data stored on disk or divided into equal, fixed-sized blocks called pages, and main memory is divided into blocks of the same size called frames. Exactly one page can fit in one frame. **7.9. What is the difference between a page and a segment?**An alternative way in which the user program can be subdivided is segmentation. In this case, the program and its associated data are divided into a number of segments. It is not required that all segments of all programs be of the same length, although there is a maximum segment length. 7.5. Another placement algorithm for dynamic partitioning is referred to as worst-fit. In this case, the largest free block of memory is used for bringing in a process. a. Discuss the pros and cons of this method compared to first-, next-, and best-fit. A criticism of the best-fit algorithm is that the space remaining after allocating a block of the required size is so small that in general it is of no real use. The worst fit algorithm maximizes the chance that the free space left after a placement will be large enough to satisfy another request, thus minimizing the frequency of compaction. The disadvantage of this approach is that the largest blocks are allocated first; therefore a request for a large area is more likely to fail. b. What is the average length of the search for worst-fit? Same as best fit. **7.12. Consider a memory-management system based on paging. The total size of the physical memory is 2 GB, laid out over pages of size 8 KB. The logical address space of each process has been limited to 256 MB. ** **a. Determine the total number of bits in the physical address. **We have total size of physical memory as 2GB. This means that 21×230=2312^1\\times2^{30}=2^{31}21×230=231. So physical address is equal to 31 bits **b. Determine the number of bits specifying page replacement and the number of bits for page frame number. **We get page size = 8kb = 232^323. 1 kb = 2102^{10}210. 23×210=2132^3\\times2^{10}=2^{13}23×210=213. So page replacement = 13 bits. Page frame number = physical address - replacement bits = 31 - 13 = 18 bits. **c. Determine the number of page frames. **The number of frames is given as 218=28×2102^{18}=2^{8}\\times2^{10}218=28×210 = 256K. So number of frames = 256K **d. Determine the logical address layout.**Logical add space is 256K. Page size= physical pages = 8kb. Logical address layout= 28bits. Page number = 15 bits. Displacement = 12 bits. 256k/8k = 32 pages in address space process. 8.1. How does the use of virtual memory improve system utilization? (1) More processes may be maintained in main memory: The use of virtual memory allows the loading of only portions of a process into the main memory. Therefore, more processes can enter the system, thus resulting in higher CPU utilisation. (2) A process may be larger than all of main memory: The use of virtual memory theoretically allows a process to be as large as the disk storage available, however, there will be system constraints (such as address space) that will limit the size 8.2. Explain thrashing. Thrashing is a phenomenon in virtual memory schemes, in which the processor spends most of its time swapping pieces rather than executing instructions. 8.3. Why is the principle of locality crucial to the use of virtual memory? Algorithms can be designed to exploit the principle of locality to avoid thrashing. In general, the principle of locality allows the algorithm to predict which resident pages are least likely to be referenced in the near future and are therefore good candidates for being swapped out. 8.4. Which considerations determine the size of a page? (1) Page size versus page table size (2) Page size versus TLB usage (3) Internal fragmentation of pages (4) Page size versus disk access **8.5. What is the purpose of a translation lookaside buffer?**The TLB is a cache that contains those page table entries that have been most recently used. Its purpose is to avoid, most of the time, having to go to disk to retrieve a page table entry. 8.7. What are the drawbacks of using either only a precleaning policy or only a demand cleaning policy? Cleaning refers to determining when a modified page should be written out to secondary memory. Two common cleaning policies are demand cleaning and pre-cleaning. There are problems with using either of the two policies exclusively. This is because, on the one hand, pre-cleaning involves a page being written out but remaining in the main memory until the page replacement algorithm dictates that it can be removed. Therefore, while precleaning allows the writing of pages in batches, it makes little sense to write out hundreds or thousands of pages only to find that the majority of them have been modified again before they are replaced. The transfer capacity of secondary memory is limited in this method; it is wasted in unnecessary cleaning operations. On the other hand, with demand cleaning, the writing of a dirty page is coupled to, and precedes, the reading in of a new page. This technique may minimise page writes, but it results in the fact that a process that suffers a page fault may have to wait for two-page transfers before it can be unblocked. This may decrease processor utilisation 8.8. What is the relationship between FIFO and clock page replacement algorithms? The clock policy is similar to FIFO, except that in the clock policy, any frame with a use bit of 1 is passed over by the algorithm. 8.9. How is a page fault trap dealt with? (1) The memory address requested is first checked, to make sure it was a valid memory request. (2) If the reference was invalid, the process is terminated. Otherwise, the page must be paged in. (3) A free frame is located, possibly from a free-frame list. (4) A disk operation is scheduled to bring in the necessary page from disk. ( This will usually block the process on an I/O wait, allowing some other process to use the CPU in the meantime. ) (5) When the I/O operation is complete, the process's page table is updated with the new frame number, and the invalid bit is changed to indicate that this is now a valid page reference. (6) The instruction that caused the page fault must now be restarted from the beginning, ( as soon as this process gets another turn on the CPU. ) **8.11. What is the difference between a resident set and a working set?**The resident set of a process is the current number of pages of that process in main memory. The working set of a process is the number of pages of that process that have been referenced recently. 9.1. How is processor scheduling done in the batch portion of an OS? Processor scheduling in a batch system, or in the batch portion of an OS, is done by a longterm scheduler. Newly submitted jobs are routed to disk and held in a batch queue from which the long-term scheduler creates processes and then places these in the ready queue so that they can be executed. 9.5. Identify the advantages and disadvantages of preemptive scheduling. Advantages: (1) It ensures fairness to all processes regardless of their priority in most cases. (2) It reduces the monopolisation of the CPU by a large process. (3) It increases the scheduling capacity of the system. (4) Depending on the CPU time the process needs, it also gives a quick response time for processes. Disadvantages: (1) Pre-emption is associated with extra overhead due to increased contextswitch, increased caching, increased bus-related costs etc. (2) Pre-emptive scheduling results in increased dispatcher activities and, subsequently, more time for dispatching. 9.6. Briefly define FCFS scheduling. As each process becomes ready, it joins the ready queue. When the currently-running process ceases to execute, the process that has been in the ready queue the longest is selected for running. 9.7. Briefly define round-robin scheduling. A clock interrupt is generated at periodic intervals. When the interrupt occurs, the currently running process is placed in the ready queue, and the next ready job is selected on a FCFS basis. 9.8. Briefly define shortest-process-next scheduling. This is a nonpreemptive policy in which the process with the shortest expected processing time is selected next. 9.9. Briefly define shortest-remaining-time scheduling. This is a preemptive version of SPN. In this case, the scheduler always chooses the process that has the shortest expected remaining processing time. When a new process joins the ready queue, it may in fact have a shorter remaining time than the currently running process. Accordingly, the scheduler may preempt whenever a new process becomes ready. 9.10. Briefly define highest-response-ratio-next scheduling. When the current process completes or is blocked, choose the ready process with the greatest value of R, where R = (w + s)/s, with w = time spent waiting for the processor and s = expected service time. **9.11. Briefly define feedback scheduling.**Scheduling is done on a preemptive (at time quantum) basis, and a dynamic priority mechanism is used. When a process first enters the system, it is placed in RQ0 (see Figure 9.4). After its first execution, when it returns to the Ready state, it is placed in RQ1. Each subsequent time that it is preempted, it is demoted to the next lowerpriority queue. A shorter process will complete quickly, without migrating very far down the hierarchy of ready queues. A longer process will gradually drift downward. Thus, newer, shorter processes are favored over older, longer processes. Within each queue, except the lowest-priority queue, a simple FCFS mechanism is used. Once in the lowest-priority queue, a process cannot go lower, but is returned to this queue repeatedly until it completes execution. **9.3. Consider that a uniprocessor system has n processes to be scheduled. If only nonpreemptive scheduling algorithms are allowed, can you determine the maximum number of possible schedules in terms of n?*Uniprocessor can have only one process at a time i.e it takes one process at a time and completes. Since in case of non premptive scheduling ,process can not be prempted until it completes its execution. Possibility of Scheduling the n process is as follows : 1st st Process can be executed in n ways , 2nd Process can be execute in (n-1) ways , 3rd Process can be executed in (n-2) ways ... (n-1)th Process can be executed in 2 ways , nth Process can be executed in 1 ways. Total number of possible ways=n(n-1)(n-2)(n-3).........2.1 =n! . So ,total number of possible way to schedule process in non premptive mode in uniprocessor=n! 10.1. List and briefly define five different categories of synchronization granularity. (1) Fine: Parallelism inherent in a single instruction stream. (2) Medium: Parallel processing or multitasking within a single application. (3) Coarse: Multiprocessing of concurrent processes in a multiprogramming environment. (4) Very Coarse: Distributed processing across network nodes to form a single computing environment. (5) Independent: Multiple unrelated processes. 10.2. What grain size of parallelism is appropriate for a multiprogrammed uniprocessor? Coarse grained or very coarse grained parallelisms are appropriate for a multiprogrammed uniprocessor. In this situation the synchronisation between processes is at a very gross level. Thus, it can easily be handled as a set of concurrent processes whose interaction among themselves is limited. The processes get CPU time in the uniprocessor system in accordance with any scheduling algorithm they might use. **10.3. For which kinds of applications is gang scheduling of threads most useful?**Gang scheduling is most useful for medium-grained to fine-grained parallel applications whose performance severely degrades when any part of the application is not running while other parts are ready to run. It is also beneficial for any parallel application, even one that is not performance sensitive. 11.3. What is the difference between block-oriented devices and stream-oriented devices? Give a few examples of each. Block-oriented devices stores information in blocks that are usually of fixed size, and transfers are made one block at a time. Generally, it is possible to reference data by its block number. Disks and tapes are examples of block-oriented devices. Stream-oriented devices transfer data in and out as a stream of bytes, with no block structure. Terminals, printers, communications ports, mouse and other pointing devices, and most other devices that are not secondary storage are stream oriented. **11.5. State some utilities of buffering.**Buffering is a technique that smoothes out peaks in I/O demand. However, no amount of buffering will allow an I/O device to keep pace with a process indefinitely when the average demand of the process is greater than the I/O device can service. Even with multiple buffers, all of the buffers will eventually fill up, and the process will have to wait after processing each chunk of data. However, in a multiprogram- ming environment, when there is a variety of I/O activity and a variety of process activity to service, buffering is one tool that can increase the efficiency of the OS and the performance of individual processes. **11.7. Calculate how much disk space (in sectors, tracks, and surfaces) will be required to store 300,000 120-byte logical records if the disk is fixed sector with 512 bytes/sector, with 96 sectors/track, 110 tracks per surface, and 8 usable surfaces. Ignore any file header record(s) and track indexes, and assume that records cannot span two sectors.**Each sector can hold 4 logical records. The required number of sectors is 300,000/4 = 75,000 sectors. This requires 75,000/96 = 782 tracks, which in turn requires 782/110 = 8 surfaces. **11.8. Consider the disk system described in Problem 11.7 , and assume the disk rotates at 360 rpm. A processor reads one sector from the disk using interrupt-driven I/O, with one interrupt per byte. If it takes to process each interrupt, what percentage of the time will the processor spend handling I/O? (disregard seek time)**There are 512 bytes/sector. Since each byte generates an interrupt, there are 512 interrupts. Total interrupt processing time = 2.5 × 512 = 1280 µs. The time to read one sector is: ((60 sec/min) / (360 rev/min)) / (96 sectors/track) = 0.001736 sec = 1736 µs Percentage of time processor spends handling I/O: (100) × (1280/1736) = 74% 12.1. What are the desirable properties of a file system? A field is the basic element of data containing a single value. A record is a collection of related fields that can be treated as a unit by some application program. 12.2. What is the difference between a file and a database? A file is a collection of similar records, and is treated as a single entity by users and applications and may be referenced by name. A database is a collection of related data. The essential aspects of a database are that the relationships that exist among elements of data are explicit and that the database is designed for use by a number of different applications. 12.3. What is a file management system? A file management system is that set of system software that provides services to users and applications in the use of files. 12.4. What criteria are important in choosing a file organization? Rapid access, ease of update, economy of storage, simple maintenance, reliability. **12.5. What are some advantages and disadvantages of sequential file organization?**Advantages: (1) Simplicity of organization. (2) Ease of access to adjacent records. (3) Simplicity of retrieval algorithms that may require additional data structure. (4) Fast retrieval of sequential data based on the primary key. (5) Creation of automatic backup copy. Disadvantages: (1) The average access time is equal to the time required to access half the file. (2) Even simple queries are time consuming. (3) Insertion of records mid-way is time consuming because it requires shifting all records after the inserted record in order to maintain the physical order of the system. (4) Record deletion results in a wastage of space and is therefore not a problem-free alternative to shifting records **12.2. One scheme to avoid the problem of preallocation versus waste or lack of contiguity is to allocate portions of increasing size as the file grows. For example, begin with a portion size of one block, and double the portion size for each allocation. Consider a file of n records with a blocking factor of F, and suppose a simple one-level index is used as a file allocation table. ** **a. Give an upper limit on the number of entries in the file allocation table as a function of F and n. **log⁡2NF\\log_2\\frac{N}{F}log2​FN​ **b. What is the maximum amount of the allocated file space that is unused at any time?**Less than half the allocated file space is unused at any time. 12.9. Fragmentation of a disk can be removed by the process of compaction. Compaction involves a relocation of the files. But disks do not have relocation registers or base registers. How, then, can files be relocated in a disk?(1) Disk fragmentation is a common problem that occurs when files on a disk become fragmented and spread out over multiple physical locations on the disk. This can cause a significant slowdown in the performance of the disk, as the read/write heads of the disk have to move around more frequently to access the different parts of the file. To address this problem, the process of compaction can be used to relocate the fragmented files to contiguous blocks on the disk, thereby improving disk performance. The process of compaction involves moving the data from its current location to a new location on the disk. However, as disks do not have relocation registers or base registers, the data cannot be relocated directly. Instead, the data is relocated using a technique known as file copying. (2) File copying involves reading the data from its current location and writing it to a new location on the disk. This new location is chosen to be contiguous with the rest of the file, so that the file becomes a single contiguous block on the disk. Once the file has been copied to its new location, the file allocation table (FAT) is updated to reflect the new location of the file. The FAT is a table that maps the logical addresses of files on the disk to their physical locations on the disk. The process of file copying can be time-consuming, especially if there are many fragmented files on the disk. Additionally, if there is not enough contiguous space on the disk to accommodate the relocated files, then the compaction process may not be successful. To address these issues, various optimization techniques can be used to improve the efficiency of the compaction process. (3) One such technique is the use of a partial compaction algorithm, which only compacts a portion of the disk at a time, rather than the entire disk. This can help to reduce the time required for the compaction process, as well as the amount of disk space required to temporarily store the relocated files. Another technique is the use of a priority-based compaction algorithm, which prioritizes the compaction of files that are frequently accessed or that are critical to the operation of the system. This can help to improve the overall performance of the system by ensuring that the most important files are located in contiguous blocks on the disk. Final answer : In conclusion, while disks do not have relocation registers or base registers, fragmented files can still be relocated on a disk through the process of file copying. Although the process of compaction can be time-consuming, various optimization techniques can be used to improve the efficiency of the process and ensure that the most important files are located in contiguous blocks on the disk. 12.11. Consider a hierarchical file system in which free disk space is kept in a free space list. **a. Suppose the pointer to free space is lost. Can the system reconstruct the free space list? **Yes. the method employed is very similar to that used by many LISP systems for garbage collection. First we would establish a data structure representing every block on a disk supporting a file system. A bit map would be appropriate here. Then, we would start at the root of the file system (the &quot;/&quot; directory), and mark every block used by every file we could find through a recursive descent through the file system. When finished, we would create a free list from the blocks remaining as unused. This is essentially what the UNIX utility fsck does. **b. Suggest a scheme to ensure that the pointer is never lost as a result of a single memory failure.**Keep a &quot;backup&quot; of the free-space list pointer at one or more places on the disk. Whenever this beginning of the list changes, the &quot;backup&quot; pointers are also updated. This will ensure you can always find a valid pointer value even if there is a memory or disk block failure. ","link":"https://kimokcheon.github.io/post/operating-system/"},{"title":"Three Frameworks","content":"各框架模型保存的格式汇总 https://blog.csdn.net/charlotte_android/article/details/93889130 Tensorflow CheckPoint (.ckpt) 在训练 TensorFlow 模型时，每迭代若干轮需要保存一次权值到磁盘，称为“checkpoint”。这种格式文件是由 tf.train.Saver() 对象调用 saver.save() 生成的，只包含若干 Variables 对象序列化后的数据，不包含图结构，所以只给 checkpoint 模型不提供代码是无法重新构建计算图的。 GraphDef (.pb) .pb 为二进制文件。这种格式文件包含 protobuf 对象序列化后的数据，包含了计算图，可以从中得到所有运算符（operators）的细节，也包含张量（tensors）和 Variables 定义，但不包含 Variable 的值。.pb 有两种类型： FrozenGraphDef 类：尽管.pb不能包含variable的只，但FrozenGraphDef将所有variable都变成了tf.constant，和graph一起frozen到一个文件，可用于作为预训练模型或推理 GraphDef 类：不包含variable的值，因此只能从中恢复计算图，但一些训练的权值和参数需要从ckpt文件中恢复。 Keras 保存整个模型（.h5），可用于继续训练 model.save(filepath)将Keras模型和权重保存在一个HDF5文件中，该文件将包含： 模型的结构，模型的权重，训练配置（损失函数，优化器，准确率等），优化器的状态 保存模型结构 model.to_json()将模型序列化保存为json文件，里面记录了网络的整体结构, 各个层的参数设置等信息. 将json字符串保存到文件. 除了json格式,还可以保存为yaml格式的字符串，形式与JSON一样 保存模型权重（.h5） 经过调参后网络的输出精度比较满意后,可以将训练好的网络权重参数保存下来，可通过下面的代码利用HDF5进行保存： model.save_weights(‘model_weights.h5’) Pytorch https://zhuanlan.zhihu.com/p/38056115 保存和加载整个模型( .pth或.pkl都可以，没区别，都是以二进制文件存储)。类同tensorflow中的.ckpt，不能进行平台迁移。 checkpoint = { &quot;model&quot;: model.state_dict(), # model是一个继承了torch.nn.Module的类的对象 &quot;optimizer&quot;: optimizer.state_dict(), # 例如 optimizer = torch.optim.Adam(model.parameters(), lr=lr) 'best_loss': lossMIN, 'epoch': epochID + 1 } # checkpoint 是一个字典 torch.save(checkpoint, os.path.join( path, &quot;epoch%d.pth&quot; % epoch))) # checkpoint = torch.load('XXX.pth') 仅保存和加载模型参数(推荐使用)，可进行平台见的迁移。 state_ditc 详见：https://zhuanlan.zhihu.com/p/38056115 PS：平台迁移的意思是，例如在pytorch和Tensorflow中分别构建了一个相同的网络，并且每一层的命名这些也都是一样的，那么在一个框架下训练的模型文件可以在另外一个框架中直接拿来用。checkpoint文件就没有这种功能。 torch.save(model.state_dict(), 'params.pkl') model.load_state_dict(torch.load('params.pkl')) 其他保存数据的格式：.t7文件，.pth文件，.pkl格式，.h5文件等。 从tensorflow模型到pytorch模型 https://blog.csdn.net/weixin_42699651/article/details/88932670 注意这种方法，只在两个框架中网络保存时，参数名一致时才能用 例如从 Tensorflow detection model zoo 下载权重。下载后，文件夹中有 checkpoint， model.ckpt.data-00000-of-00001， model.ckpt.index， model.ckpt.meta 几个文件 执行命令：python3 ckpt2h5.py ./model.ckpt 会生成: model.h5文件 # File ckpt2h5.py import tensorflow as tf import deepdish as dd import argparse import os import numpy as np def tr(v): # tensorflow weights to pytorch weights if v.ndim == 4: return np.ascontiguousarray(v.transpose(3,2,0,1)) elif v.ndim == 2: return np.ascontiguousarray(v.transpose()) return v def read_ckpt(ckpt): # https://github.com/tensorflow/tensorflow/issues/1823 reader = tf.train.NewCheckpointReader(ckpt) weights = {n: reader.get_tensor(n) for (n, _) in reader.get_variable_to_shape_map().items()} pyweights = {k: tr(v) for (k, v) in weights.items()} return pyweights if __name__ == '__main__': parser = argparse.ArgumentParser(description=&quot;Converts ckpt weights to deepdish hdf5&quot;) parser.add_argument(&quot;infile&quot;, type=str, help=&quot;Path to the ckpt.&quot;) parser.add_argument(&quot;outfile&quot;, type=str, nargs='?', default='', help=&quot;Output file (inferred if missing).&quot;) args = parser.parse_args() if args.outfile == '': args.outfile = os.path.splitext(args.infile)[0] + '.h5' outdir = os.path.dirname(args.outfile) if not os.path.exists(outdir): os.makedirs(outdir) weights = read_ckpt(args.infile) dd.io.save(args.outfile, weights) 以上代码将.ckpt文件转换成了一个.h5文件，文件中包含网络权重 # 在pytorch中将权重读出来 net = ... import torch import deepdish as dd net = resnet50(..) model_dict = net.state_dict() # 将字典内部元素从 numpy 转换为 tensor 类型 weights_dict = = dd.io.load('./model.h5') # 将.h5读入成 OrderedDict tensor_dict = {} for k,v in weights_dict.items(): tensor_dict[k] = torch.Tensor(v) print(k) # 可以看到网络每一层的名字是什么 model_dict.update(tensor_dict) net.load_state_dict(model_dict) ","link":"https://kimokcheon.github.io/post/three-frameworks/"},{"title":"Tensorflow","content":"1.安装 1.1 后端Tensorflow的安装 按照官网用pip安装： https://www.tensorflow.org/install/pip?hl=zh-cn Warning： Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA 原因： 当用GPU时，可忽略它。 这个警告简而言之就是CPU支持AVX（高级向量扩展指令集），但是安装的tensorflow并没有运用这个功能，不能实现CPU上的加速，参见： https://blog.csdn.net/hq86937375/article/details/79696023 解决方案： 从源码安装可解决这个问题，参见：https://github.com/lakshayg/tensorflow-build 验证是否安装成功: 查看 cuDNN version：cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 查看 CUDA version: cat /usr/local/cuda/version.txtimport tensorflow as tf import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' # 屏蔽掉 info 等级的log tf.test.is_gpu_available() print(&quot;Num GPUs Available: &quot;, len(tf.config.experimental.list_physical_devices('GPU'))) a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]) b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]) c = tf.matmul(a, b) print(c) 1.2 前端Kares的安装 为配合tensorflow， 使用python3: 进入python3的虚拟环境(venv为创建虚拟环境时自定义的文件夹名称): source ./venv/bin/activate pip install keras 2. 模型的格式 Tensorflow训练后的模型可以保存ckpt文件或pb文件。 ckpt导出网络结构与权值分离的四个文件，一般用于继续训练，但是需要原来的代码支持，所以不能在多平台、编程语言中迁移，在恢复模型之前需要再定义一遍网络结构 .pb文件则是GraphDef或FrozenGraphDef的序列化文件，训练好的模型可在多平台、多语言中迁移。.pb 有两种： FrozenGraphDef 类：包含所有的variable，但是所有的variable都已经变成了tf.constant和graph一起frozen到一个文件，可用于作为预训练模型或推理 GraphDef 类：不包含variable的值，因此只能从中恢复计算图，但一些训练的权值和参数需要从ckpt文件中恢复。 官方提供freeze_graph.py脚本可将ckpt文件转为pb文件 2.1 名词定义 https://tensorflow.juejin.im/extend/tool_developers/index.html https://zhuanlan.zhihu.com/p/31308381 Protocol Buffers (简称protobufs)： 是Google开源的一个与语言无关、平台无关的序列化协议。所谓序列化就是，在Tensorflow上写好也训练好一个神经网络之后，怎样把这个模型保存起来，以方便抑制到其他平台上（例如嵌入式系统）。protobufs支持二进制格式（.pb文件）、文本格式（.pbtxt文件，方便人阅读）两种格式。 文本文件结构跟 XML，Json等文件结构类似。所有的 TensorFlow 文件格式都是基于 Protocol Buffers的 Graph： 是一个抽象概念，一些 Operation 和 Tensor 的集合就叫做 Graph MetaGraph： 一个Meta Graph 由一个计算图和其相关的元数据构成。其包含了用于继续训练，实施评估和（在已训练好的的图上）做前向推断的信息 GraphDef： 简单理解就是 Graph 按 protobufs 协议序列化之后的对象，用.pb文件存储。这种格式文件包含了计算图，可以从中得到所有运算符的细节，也包含张量（tensors）和 Variables 定义，但不包含 Variable 的值，因此只能从中恢复计算图，训练需要的的权值仍需要从 checkpoint 中恢复 FrozenGraphDef： TensorFlow 一些例程中用到 frozen_inference_graph.pb 文件作为预训练模型，这和上面 GraphDef 不同，属于冻结（Frozen）后的 GraphDef 文件，简称 FrozenGraphDef 格式。GraphDef 虽然不能保存 Variable，但可以保存 Constant，通过 tf.constant 将 weight 直接存储在 NodeDef 中 NodeDef： NodeDef是GraphDef的组成部分。一个Graph由很多个Node构成，每个Node都定义了一个运算操作和输入连接 MetaGraphDef： 一个类的名称，是MetaGraph的具体实现。 2.2 Checkpoint (.ckpt文件) ---四件套 https://www.zhihu.com/question/61946760 API saver = tf.train.Saver() saver.save(session, checkpoint_path) # 保存checkpoint saver.restore(session, checkpoint_path) # 载入checkpoint CheckPoint (*.ckpt) import tensorflow as tf if __name__ == &quot;__main__&quot;: #定义两个变量 a = tf.Variable(tf.constant(1.0,shape=[1],name=&quot;a&quot;)) b = tf.Variable(tf.constant(2.0,shape=[1],name=&quot;b&quot;)) c = a + b init = tf.initialize_all_variables() sess = tf.Session() sess.run(init) #声明一个保存 saver = tf.train.Saver() saver.save(sess,&quot;./model.ckpt&quot;) 运行完上述代码，会产生四个文件： checkpoint: 保存了一个目录下所有断点模型文件列表，可以用来迅速查找最近一次的断点文件 model.ckpt.meta: 是MetaGraphDef序列化的二进制文件，保存了网络结构相关的数据，包括graph_def和saver_def等 model.ckpt.data-00000-of-00001: 保存所有变量的值：网络权值, 梯度, 超参数等 model.ckpt.index: 文件为数据文件提供索引 2.3 Protocol Buffer (.pb文件) https://zhuanlan.zhihu.com/p/60069860 从.pb文件中构建图 (GraphDef) import tensorflow as tf graph = tf.GraphDef() with open(model_file, &quot;rb&quot;) as f: graph_def.ParseFromString(f.read()) with graph.as_default(): tf.import_graph_def(graph_def) ","link":"https://kimokcheon.github.io/post/tensorflow/"},{"title":"Pytorch_Example","content":"Pytorch Cookbock Cookbook https://zhuanlan.zhihu.com/p/59205847 Python 使用和高性能技巧总结 https://zhuanlan.zhihu.com/p/48293468 Tensor Processing Example import torch x = torch.zeros((16,10,30,30), dtype=torch.float) print(x.shape) a = torch.stack((x,x,x),1) # stack是建立一个新的维度 print(a.shape) b = torch.cat((x,x,x), dim=1) # cat是在已有的维度上拼接 print(b.shape) k = x.expand(2,3,-1,-1,-1,-1) # 只能将大小为1维度的扩展到更大尺寸 # k = x.expand(2,3,-1,20,-1,-1) # 会报错 print(k.shape) c = x.repeat(2,3,1,2,1,1) # 可以repeat任意维度，新的维度默认加在前面 print(c.shape) d = torch.unsqueeze(x, 2) print(d.shape) e = torch.unsqueeze(x, 2).repeat(1,1,3,1,1) print(e.shape) 得到 torch.Size([16, 10, 30, 30]) torch.Size([16, 3, 10, 30, 30]) torch.Size([16, 30, 30, 30]) torch.Size([2, 3, 16, 10, 30, 30]) torch.Size([2, 3, 16, 20, 30, 30]) torch.Size([16, 10, 1, 30, 30]) torch.Size([16, 10, 3, 30, 30]) Custom DataLoader Example 见： https://pytorch.org/tutorials/beginner/data_loading_tutorial.html https://zhuanlan.zhihu.com/p/30934236 要点在于在 CustomDataset(Dataset)的__init__中不直接读入图片，而只读入csv文件，包含图片路径等；在__getitem__中才读入index所对应图片。这样可以节省内存。 Pytorch的数据读取主要包含三个类，这三者大致是一个依次封装的关系: 1被装进2, 2被装进3 Dataset: 提供了自定义数据集的方法，可在__getitem__中使用transform class torchvision.transforms.Compose(transforms) 见: https://pytorch.org/docs/stable/torchvision/transforms.html https://blog.csdn.net/Hansry/article/details/84071316 DataLoader: 在Dataset的基础上，加上了mini-batch, shuffle, multi-threading 的功能 DataLoaderIterfrom torch.utils.data import Dataset, DataLoader from torchvision import transforms, utils class CustomDataset(Dataset): def __init__(self, transform = None): XXX self.transform = transform def __len__(self): XXX def __getitem__(self, idx): sample = XXX if self.transform: sample = self.transform(sample) return sample my_dataset = CustomDataset(transform=transforms.Compose([Rescale(256), RandomCrop(224), ToTensor()])) dataloader = Dataloader(my_dataset, batch_size=4, shuffle=True, num_workers=4) for index, sample in enumerate(dataloader): # training... torchvision: torchvision package provides some common datasets and transforms 见： https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#afterword-torchvision collate_fn的使用: You can use your own collate_fn to process the list of samples to form a batch. The batch argument is a list with all your samples. E.g. if you would like to return variable-sized data. https://zhuanlan.zhihu.com/p/30385675 https://blog.csdn.net/weixin_42028364/article/details/81675021 collate_fn中可以定义怎样将 从__getitem__获取的长度为batch_size的数据 组成a batch of training data，输入训练网络。比如文字识别，label是一个单词，每个label不一样长，需要先把他们统一成相同长度。或者multi-scale training: selects new image size every tenth batch: def collate_fn(self, batch): # Selects new image size every tenth batch if self.multiscale and self.batch_count % 10 == 0: self.img_size = random.choice(range(self.min_size, self.max_size + 1, 32)) # Resize images to input shape imgs = torch.stack([resize(img, self.img_size) for img in imgs]) self.batch_count += 1 return paths, imgs, targets dataloader 输出的数据都是默认在 CPU 上，如果要用 GPU 训练，需要手动移到 GPU 上。用 dali 模块，可以将一些预处理也放在 GPU 上 Linear Regression Example 这个例子是把所有训练数据一次性读到内存中了的 见: https://gist.github.com/dvgodoy/1d818d86a6a0dc6e7c07610835b46fe4 Only load the batch training data instead of the whole data into GPU because graphics card’s RAM is precious. We need to send our model to the same device where the data is. If our data is made of GPU tensors, our model must “live” inside the GPU as well. During validation, it's better to use with torch.no_grad() and model.eval() together. import numpy as np import torch import torch.optim as optim import torch.nn as nn from torchviz import make_dot from torch.utils.data import Dataset, TensorDataset, DataLoader from torch.utils.data.dataset import random_split device = 'cuda' if torch.cuda.is_available() else 'cpu' ############## Genreate dataset, dataloader ################ np.random.seed(42) x = np.random.rand(100, 1) true_a, true_b = 1, 2 y = true_a + true_b*x + 0.1*np.random.randn(100, 1) x_tensor = torch.from_numpy(x).float() y_tensor = torch.from_numpy(y).float() class CustomDataset(Dataset): def __init__(self, x_tensor, y_tensor): self.x = x_tensor self.y = y_tensor def __getitem__(self, index): return (self.x[index], self.y[index]) def __len__(self): return len(self.x) dataset = TensorDataset(x_tensor, y_tensor) # dataset = CustomDataset(x_tensor, y_tensor) train_dataset, val_dataset = random_split(dataset, [80, 20]) train_loader = DataLoader(dataset=train_dataset, batch_size=16) # it is on CPU val_loader = DataLoader(dataset=val_dataset, batch_size=20) # it is on CPU ##################### Generate Model ######################## class ManualLinearRegression(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(1, 1) def forward(self, x): return self.linear(x) ################### Define train step ###################### def make_train_step(model, loss_fn, optimizer): def train_step(x, y): model.train() yhat = model(x) loss = loss_fn(y, yhat) loss.backward() optimizer.step() optimizer.zero_grad() return loss.item() return train_step ################### Train the model ###################### # Estimate a and b torch.manual_seed(42) model = ManualLinearRegression().to(device) # model = nn.Sequential(nn.Linear(1, 1)).to(device) loss_fn = nn.MSELoss(reduction='mean') # output the mean of several MSEloss optimizer = optim.SGD(model.parameters(), lr=1e-1) train_step = make_train_step(model, loss_fn, optimizer) # return of make_train_step is a function n_epochs = 100 training_losses = [] validation_losses = [] print(model.state_dict()) for epoch in range(n_epochs): batch_losses = [] for x_batch, y_batch in train_loader: x_batch = x_batch.to(device) # Transfer the batch data from CPU to device y_batch = y_batch.to(device) loss = train_step(x_batch, y_batch) batch_losses.append(loss) training_loss = np.mean(batch_losses) # report one training_loss per epoch training_losses.append(training_loss) with torch.no_grad(): val_losses = [] for x_val, y_val in val_loader: x_val = x_val.to(device) y_val = y_val.to(device) model.eval() yhat = model(x_val) val_loss = loss_fn(y_val, yhat).item() # change tensor to python type val_losses.append(val_loss) validation_loss = np.mean(val_losses) validation_losses.append(validation_loss) print(f&quot;[{epoch+1}] Training loss: {training_loss:.3f}\\t Validation loss: {validation_loss:.3f}&quot;) print(model.state_dict()) # get the current value for all parameters ","link":"https://kimokcheon.github.io/post/pytorch_example/"},{"title":"Pytorch_Advance","content":"Deterministic 的问题 其实没必要严格要求 deterministic，从实际角度出发，只要每次跑出来结果差距都不大就行了：https://pytorch.org/docs/stable/notes/randomness.html torch.backends.cudnn.deterministic=True 是能让卷积操作 deterministic，其他操作如 torch.nn.MaxPool3d 基本没办法确保deterministic： https://stackoverflow.com/a/66647424 初始化也不行：https://github.com/pytorch/pytorch/issues/19013 Dataloader 的 worker 数量不同也会使得采样结果 non-deterministic: https://pytorch.org/docs/stable/data.html#data-loading-randomness pytorch多gpu并行训练 https://zhuanlan.zhihu.com/p/105755472 https://zhuanlan.zhihu.com/p/86441879 https://zhuanlan.zhihu.com/p/95700549 https://zhuanlan.zhihu.com/p/68717029 High-level 介绍 DP 和 DDP Training Neural Nets on Larger Batches: Practical Tips for 1-GPU, Multi-GPU &amp; Distributed setups (里面关于DP的图有错误，DP中从loss计算梯度仍是并行的) DP: 实现是单进程多线程，只能用于单机多卡；并且用的 parameter server 构架，会导致GPU之间通信是瓶颈；好处是代码改动很少 并且其中一个 GPU 需要计算 loss 并整合梯度，会导致负载不均衡。具体，并行训练分以下四步 （其中下图左下角的两步画错了，应该是GPU-1计算并分发loss，而不是分发梯度）： 1：把每张卡的输出聚集到 GPU0 2：只在 GPU0 在算 loss 3：把 loss scatter 到其他 GPU 上 4：每个 GPU 算各自的梯度，再把梯度汇总到 GPU0 上 可以看到 loss 的计算始终在一个 GPU 上，所以会有负载不均衡，所以有类似 PyTorch Encoding 的包，使得 loss 的计算也能并行。也即每张卡算自己的 loss，然后再算自己的梯度，最后只需将梯度聚集就可以 但这种方法不适用于对比学习，因为对比学习 loss 计算本身就必须知道一个batch内所有样本的 output 这时普通的 DDP 也不适用，需要用 DDP2 来计算 NCE loss，见 https://pytorch-lightning.readthedocs.io/en/stable/advanced/multi_gpu.html#distributed-data-parallel-2 DDP：实现是多进程，可用于单机多卡或多机多卡，用的 ring-all-reduce 构架 加速主要来源于3点：多进程，ring-all-reduce，负载均衡；可以见到没有聚合output在一张卡上计算梯度的步骤了，而是根据每张卡上的loss直接反传 DDP 具体用法 三种方式 https://zhuanlan.zhihu.com/p/358974461 https://zhuanlan.zhihu.com/p/187610959 每个进程负责一个GPU，推荐 每个进程多GPU，但每个进程都是 DP，但 python 的 PIL 会造成 CPU bound 每个进程调用多个GPU，主要用于 model 太大 batchsize=1 都放不下的情况 import os import torch import torchvision import torch.distributed as dist import torch.utils.data.distributed from torchvision import transforms from torch.multiprocessing import Process os.environ['MASTER_ADDR'] = 'localhost' # New added os.environ['MASTER_PORT'] = '12355' # New added def main(rank): dist.init_process_group(&quot;ncll&quot;, rank=rank, world_size=3) # New added torch.cuda.set_device(rank) # New added trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))]) data_set = torchvision.datasets.MNIST(&quot;./&quot;, train=True, transform=trans, target_transform=None, download=True) train_sampler = torch.utils.data.distributed.DistributedSampler(data_set) # New added data_loader_train = torch.utils.data.DataLoader(dataset=data_set, batch_size=256, sampler=train_sampler) # use train_sampler to split the original batch size net = torchvision.models.resnet101(num_classes=10) net.conv1 = torch.nn.Conv1d(1, 64, (7, 7), (2, 2), (3, 3), bias=False) net = net.cuda() net = torch.nn.parallel.DistributedDataParallel(net, device_ids=[rank]) # New added criterion = torch.nn.CrossEntropyLoss() opt = torch.optim.Adam(net.parameters(), lr=0.001) for epoch in range(10): for i, data in enumerate(data_loader_train): images, labels = data images, labels = images.cuda(), labels.cuda() opt.zero_grad() outputs = net(images) loss = criterion(outputs, labels) loss.backward() opt.step() if i % 10 == 0: print(&quot;loss: {}&quot;.format(loss.item())) if rank == 0: # only the main process saves the model torch.save(net, &quot;my_net.pth&quot;) if __name__ == &quot;__main__&quot;: size = 3 processes = [] for rank in range(size): p = Process(target=main, args=(rank,)) p.start() processes.append(p) for p in processes: p.join() # or use spawn # mp.spawn(main, args=(size,), nprocs=size, join=True) torch.distributed.init_process_group() 默认 env:// 的初始方法，也可以使用 tcp 和 file 多机分布式启动方式： 用 torch.distributed.launch。假设一共有两台机器（节点1和节点2），每个节点上有8张卡，节点1的IP地址为192.168.1.1，占用的端口12355（端口可以更换），启动的方式如下： 其中 torch.distributed.launch 将会被 torchrun 代替：https://pytorch.org/docs/stable/elastic/run.html#launcher-api # 节点1 python -m torch.distributed.launch --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=&quot;192.168.1.1&quot; --master_port=12355 MNIST.py # 节点2 python -m torch.distributed.launch --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=&quot;192.168.1.1&quot; --master_port=12355 MNIST.py 按模块启动：python -m torch.distributed.launch main.py https://www.cnblogs.com/xueweihan/p/5118222.html 直接启动 python xxx.py 是把 xxx.py 文件所在的目录放到了sys.path属性中 按模块启动 python -m xxx.py 是把你输入命令的目录（也就是当前路径），放到了sys.path属性中 多GPU多进程模拟联邦学习，进程初始化报错 https://discuss.pytorch.org/t/understanding-minimum-example-for-torch-multiprocessing/101010 背景 由于要调用 CUDA，多进程用的是 spawn 而不是 fork 多进程之间是要共享一个 list of tensors，但不同进程用的是 list 里面不同的 slices 一个错误复现的代码如下： import torch, os import torch.distributed as dist import torch.multiprocessing as mp def run(rank, size): &quot;&quot;&quot; Distributed function to be implemented later. &quot;&quot;&quot; print(f'rank {rank} of {size}') def init_process(rank, size, data, fn, backend='gloo'): &quot;&quot;&quot; Initialize the distributed environment. &quot;&quot;&quot; os.environ['MASTER_ADDR'] = '127.0.0.1' os.environ['MASTER_PORT'] = '29500' dist.init_process_group(backend, rank=rank, world_size=size) fn(rank, size) def processes(data): size = len(data) processes = [] for rank in range(size): p = mp.Process(target=init_process, args=(rank, size, data, run)) p.start() processes.append(p) for p in processes: p.join() if __name__ == &quot;__main__&quot;: mp.set_start_method(&quot;spawn&quot;) size_vector = 133 part = int(size_vector/8) indices = torch.arange(size_vector) split_data = torch.split(indices, part) print(split_data) processes(split_data) 解决方案 以上代码在 Pytorch1.9 的Linux版本下会报错： ValueError: bad value(s) in fds_to_keep，在windows下则正常运行 解决方案有两种： 将 mp.Process() 那行改成：data_i = data[rank]; p = mp.Process(target=init_process, args=(rank, size, data_i, run)) 在 mp.Process() 那行之前加：data = [i.clone() for i in data]，相当于将 data 的每个元素重新在内存里面复制了一遍 原因分析 You cannot pass a tensor to the mp.Process that has data shared with other processes 报错的的原因应该是来源于 Pytorch 内部的内存管理机制，tensor 和 tensor 之间是自动共享内存的。试过 copy.deepcopy(data) 不起作用，必须要用 .clone() 为什么 windows 不报错而 linux 报错，可能和两个平台的多进程实现机制有关，windows没有fork，所以为新进程强行开了新的存储空间 Pytorch Internals Folders torch/：包含导入和使用的实际Python模块。Python代码，很容易上手调试。 torch/csrc/：它实现了在Python和C++之间进行转换的绑定代码，以及一些非常重要的PyTorch功能，如autograd引擎和JIT编译器。它还包含C++前台代码。 torch._C 模块在 torch/csrc/Module.cpp 中定义。这个模块被称为是一个扩展模块（一个用C实现的Python模块），它允许我们定义新的内建对象类型（例如：Tensor）并调用 C/C++ 函数。 aten/：“A Tensor Library”的缩写（由Zachary DeVito创造），是一个实现Tensors操作的C++库。存放一些内核代码存在的地方，尽量不要在那里花太多时间。 c10/：这是一个双关语。C代表Caffe，10既是二级制的2 (Caffe2)，也是十进制的10（英文Ten，同时也是Tensor的前半部分）。包含PyTorch的核心抽象，包括Tensor和Storage数据结构的实际实现。 Pytorch Features https://speakerdeck.com/perone/pytorch-under-the-hood?slide=21 Tensors Although PyTorch has an elegant python first design, all PyTorch heavy work is actually implemented in C++. The integration of C++ code is usually done using what is called an extension. zero-copy tensors # a copy is made np_array = np.ones((1,2)) torch_array = torch.tensor(np_array) # This make a copy torch_array.add_(1.0) # underline after an operation means an in-place operation print(np_array) # array([[1., 1.]]) # zero-copy np_array = np.ones((1,2)) torch_array = torch.from_numpy(np_array) # This make a copy torch_array.add_(1.0) # or torch_array += 1.0 (in place operation) print(np_array) # array([[2., 2.]]) # zero-copy np_array = np.ones((1,2)) torch_array = torch.from_numpy(np_array) # This make a copy torch_array = torch_array + 1.0 # not an in-place operatio on torch_array print(np_array) # array([[1., 1.]]) The tensor FloatTensor did a copy of the numpy array data pointer instead of the contents. The reference is kept safe by Python reference counting mechanism. The abstraction responsible for holding the data isn't actually the Tensor, but the Storage. We can have multiple tensors sharing the same storage, but with different interpretations, also called views, but without duplicating memory. t_a = torch.ones((2,2)) t_b = t_a.view(4) t_a_data = t_a.storage().data_ptr() t_b_data = t_b.storage().data_ptr() t_a_data == t_b_data # True JIT: just-in-time compiler https://zhuanlan.zhihu.com/p/52154049 https://zhpmatrix.github.io/2019/03/01/c++-with-pytorch/ 早期的PyTorch只有Python前端，但对于工业界的实际部署问题，Python语言太慢，可移植性和适用性根本无法和C++相比。当时的一个想法是，PyTorch训练模型，然后前向推断时将结构和参数灌入到C++代码中，这估计也是早些年的一些做法。但是调研之后，将PyTorch的C++后端拉出来并不容易，而且如果从C++原生代码来写起，工作量也很大。因此，希望有一个C++前端方便做推断部署。 千呼万唤始出来。PyTorch1.0发布了，这样业界部署的工作流程可以变成这样： 论文发布-&gt;PyTorch开源代码(或者自己实现)-&gt;训练模型-&gt;导出模型-&gt;载入模型(C++/Python/其他框架/其他硬件平台) PyTorch1.0后，可以通过两种方式，分别是Tracing和Script，将一个Python代码转化为TorchScript代码，继而导出相应的模型可以继续被优化，同时被C++所调用，最终实现对生产环境下的支持（考虑到多线程执行和性能原因，一般Python代码并不适合做部署） Tracing Tracing方式对于含有if和for-loop的场景失效，需要用script方式 Script https://zhpmatrix.github.io/2019/03/09/torch-jit-pytorch/ Dataloader 加速 仅从使用者的角度考虑,DataLoader做了下面的事情： 开启多个子进程worker 每个 worker 通过主进程获得自己需要采集的idx。idx的顺序由采样器（sampler）或 shuffle 得到。每个 worker 开始采集一个batch的数据。因此增大 num_workers 的数量，内存（不是显存）占用也会增加。因为每个 worker 都需要缓存一个 batch 的数据 第一个 worker 数据采集完成后，会卡在这里，等着主进程取走数据。主进程处理完这个 batch 之后，这个 worker 开始采集下一个 batch 主进程采集完最后一个 worker 的batch。此时需要回去采集第一个 worker 产生的第二个 batch。如果第一个 worker 此时没有采集完，主线程会卡在这里等（这也是为什么在数据加载比较耗时的情况下，每隔 num_workers 个 batch，主进程都会在这里卡一下） Dataloader 数据装载阻塞的问题: https://zhuanlan.zhihu.com/p/91521705 Pytorch Dataloader 的实现是多进程 一个 worker 独立的处理一个 batch，而不是多个 worker 同时处理一个 batch dataloader 不是 等所有worker数据取完才进行下一批次的数据读取，worker 之间并没有同步 输出的数据保持顺序性：主线程（进行front/back propagation）按照idx=0, 1, 2, 3...依次处理 worker 产生的 batch worker 会等待主进程处理完（主要即GPU time）上个 batch，才采样下一个 batch 用 GPU 来完成 dataloader 中的 transform: https://zhuanlan.zhihu.com/p/77633542 https://github.com/pytorch/pytorch/issues/31359 进一步加速： https://www.cnblogs.com/pprp/p/14199865.html Prefetch next batch / 新开的cuda stream拷贝tensor到gpu：https://zhuanlan.zhihu.com/p/97190313 生产者消费者模型：https://blog.csdn.net/winycg/article/details/92443146 APEX ","link":"https://kimokcheon.github.io/post/pytorch_advance/"},{"title":"Pytorch","content":"1. Pytorch的安装 可考虑是否在虚拟环境中安装， 安装步骤见 https://pytorch.org/ 1.1 CUDA，cuDNN 的区别？ 见 CUDA Installation CUDA is a general purpose parallel computing PLATFORM and programming model that leverages the parallel compute engine in NVIDIA GPUs in a more efficient way on a CPU cuDNN(CUDA Deep Neural Network library) is a LIBRARY 2. Pytorch 的使用 2.1 常用命令 2.1.1 torch.nn.Sequential() 和 torch.nn.ModuleList() 见 https://zhuanlan.zhihu.com/p/64990232 ModuleList 就是一个储存各种模块的 list，这些模块之间没有联系，没有实现 forward 功能。相比于普通的 Python list，ModuleList 可以把添加到其中的模块和参数自动注册到网络上。 Sequential 内的模块需要按照顺序排列，要保证相邻层的输入输出大小相匹配，内部 forward 功能已经实现，可以使代码更加整洁。 2.1.2 torch.nn 和 torch.nn.functional 的区别 torch.nn API: https://pytorch.org/docs/stable/nn.html torch.nn 是里面包含的是，torch.nn.functional 里面包含的是函数。 如果我们只保留nn.functional下的函数的话，在训练或者使用时，我们就要手动去维护weight, bias, stride这些中间量的值，这显然是给用户带来了不便。 而如果我们只保留nn下的类的话，其实就牺牲了一部分灵活性，因为做一些简单的计算都需要创造一个类，这也与PyTorch的风格不符。 见 https://www.zhihu.com/question/66782101/answer/246341271 2.1.3 torch.no_grad(), torch.set_grad_enabled(), torch.enable_grad() 和 model.eval() 见 https://www.cnblogs.com/guoyaohua/p/8724433.html model.eval(): changes the forward() behaviour of the module it is called upon. It disables certain layers exclusive for training stage. BN层一般放在conv层后面，激活函数之前；Dropout对于conv层和FC层都可以适用 在train模式下，dropout网络层会按照设定的参数p设置保留激活单元的概率（保留概率=p); batchnorm层会继续计算数据的mean和var等参数并更新 在val模式下，dropout层会让所有的激活单元都通过；而batchnorm层会停止计算和更新mean和var，用从所有训练实例中获得的统计量来代替Mini-Batch里面m个训练实例获得的mean和var的统计量 torch.no_grad() or torch.set_grad_enabled(False): Disable the gradient computation. In this mode, the result of every computation will have requires_grad=False, even when the inputs have requires_grad=True. # There is no different bewteen: with torch.no_grad(): &lt;code&gt; # and torch.set_grad_enabled(False) &lt;code&gt; torch.set_grad_enabled(True) # 只是torch.set_grad_enabled()可以选择是开还是关梯度计算， # torch.no_grad()只能选择关 torch.enable_grad(): Enables gradient calculation, if it has been disabled via no_grad() or set_grad_enabled(False). x = torch.tensor([1], requires_grad=True) with torch.no_grad(): with torch.enable_grad(): y = x * 2 y.requires_grad # 输出 True model.eval() 和 torch.no_grad() 可以一起使用： model = CNN() for e in num_epochs: # do training model.train() # evaluate model: model = model.eval() with torch.set_grad_enabled(False): logits, probas = model(testset_features) 2.1.4 model.zero_grad() 和 optimizer.zero_grad() https://pytorch.org/tutorials/beginner/former_torchies/autograd_tutorial.html optimizer.zero_grad() 有什么用 ? 一般的训练方式是进来一个batch更新一次梯度，所以每次计算梯度前都需要用 optimizer.zero_grad() 手动将梯度清零。如果不手动清零，pytorch会自动对梯度进行累加。 梯度累加可以模拟更大的batch size，在内存不够大的时候，是一种用更大batch size训练的trick，见 https://www.zhihu.com/question/303070254/answer/573037166 梯度累加可以减少multi-task时的内存消耗问题。因为当调用了.backward()后，computation graph就从内存释放了。这样进行multi-task时，在任意时刻，在内存中最少只存储一个graph。 见 https://www.zhihu.com/question/303070254/answer/608153308for idx, data in enumerate(train_loader): xs, ys = data optmizer.zero_grad() # 计算d(l1)/d(x) pred1 = model1(xs) #生成graph1 loss = loss_fn1(pred1, ys) loss.backward() #释放graph1 # 计算d(l2)/d(x) pred2 = model2(xs) #生成graph2 loss2 = loss_fn2(pred2, ys) loss.backward() #释放graph2 # 使用d(l1)/d(x)+d(l2)/d(x)进行优化 optmizer.step() model.zero_grad() 和 optimizer.zero_grad() 的区别 当optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)时，二者等效，其中SGD也可以换成其他优化器例如Adam。当一个model中用了多个optimizer时，model.zero_grad() 是将所有梯度清零，optimizer.zero_grad() 是清零一个optimizer 2.1.5 learning rate decay https://www.cnblogs.com/wanghui-garcia/p/10895397.html 一般会用到torch.optim.lr_scheduler.LambdaLR， torch.optim.lr_scheduler.StepLR， torch.optim.lr_scheduler.MultiStepLR，使用格式为： import torch.optim.lr_scheduler.StepLR scheduler = StepLR(optimizer, step_size=30, gamma=0.1) for epoch in range(100): scheduler.step() optimier.step() optimizer.zero_grad() (other training steps...) (other validate steps...) 查看 learning rate: print(optimizer.param_groups[0]['lr']) 2.1.6 hook https://zhuanlan.zhihu.com/p/75054200 pytorch 中，对于中间变量（由别的变量计算得到的变量）/ Module，一旦完成了反向传播，它就会被释放掉以节约内存。利用hook，我们不必改变网络输入输出的结构，就可方便地获取、改变网络中间层变量的梯度 Hook for Tensors：z.register_hook(hook_fn) 使用方式： y.register_hook(fn)，其中自定义函数fn(grad)返回Tensor或没有返回值 def save_grad(): def hook(grad): print(grad) return hook # register gradient hook for tensor y if y.requires_grad == True: y.register_hook(save_grad()) Hook for Modules： module.register_forward_hook(hook_fn)：获取前向传播时，module的输入输出 module.register_backward_hook(hook_fn)：执行反向传播时，module前后的梯度 module.register_forward_pre_hook(hook_fn)：获取前向传播执行前的hook，在 torch.nn.utils.prune 会用到，见 https://pytorch.org/tutorials/intermediate/pruning_tutorial.html 使用方法：编写 hook_fn 函数（包含打印或保存等操作）-&gt; 注册hook -&gt; 执行前向/方向传播 2.1.7 nn.Module 一个Net，也就是继承自 nn.Module 的类，当实例化后，本质上就是维护了以下8个字典(OrderedDict)，在上面和本小节都有介绍: https://www.jianshu.com/p/a4c745b6ea9b _parameters _buffers _backward_hooks _forward_hooks _forward_pre_hooks _state_dict_hooks _load_state_dict_pre_hooks _modules model.modules()：返回Generator，广度优先遍历模型所有子层for x in model.modules()： model.named_modules()：返回Generator，比 model.modules() 多返回了每个module的名字for name, layer in model.named_modules(): if isinstance(layer, nn.Conv2d): model.children()：返回Generator，只遍历model的子层（子层的子层不遍历了） model.named_children()：返回Generator， 比model.children() 多返回了每个child的名字 model.parameters()：返回Generator，迭代地返回所有参数，一般用于给optimizer传递参数 model.named_parameters()：返回Generator，比model.parameters() 多返回了每个参数的名字，weights和bias也加以了区分 model.state_dict()：返回OrderDict，一般用于模型保存for k,v in model.state_dict(): model.buffers()：返回OrderDict。反向传播不需要被optimizer更新的参数（和parameter正好相反），称之为buffer，用于存一些不变的模型参数（例如存BN的mean，存pruning时的mask）bn = nn.BatchNorm1d(2) input = torch.tensor(torch.rand(3, 2), requires_grad=True) output = bn(input) print(bn._buffers) # 输出 OrderedDict([('running_mean', tensor([0.0525, 0.0584])), ('running_var', tensor([0.9177, 0.9140])), ('num_batches_tracked', tensor(1))]) 注意： len([x for x in model.modules()]) 会比 len([[x for x in model.parameters()]) 大，因为前者遍历了 a hierarchy of model（包含中间节点），后者只遍历了 model graph 的叶节点 例子 打印网络每层名字，大小，是否需要梯度 for name, param in model.named_parameters(): print(name, ' ', param.size(), param.requires_grad) print(type(param), type(param.detach())) # &lt;class 'torch.nn.parameter.Parameter'&gt; &lt;class 'torch.Tensor'&gt; # torch.nn.parameter.Parameter 是 torch.Tensor 的子类，用了 .detach() 梯度就不反传了 初始化网络： https://blog.csdn.net/daydayjump/article/details/80899029 2.1.8 其他 torchvision 由以下四部分组成： torchvision.datasets， torchvision.models， torchvision.transforms， torchvision.utils 见 https://pytorch.org/docs/master/torchvision/transforms.html?highlight=torchvision%20transforms torchvision.transforms 包含很多类，其中 torchvision.transforms.Compose() 可以把多个步骤合在一起 例如 torchvision.transforms.Compose([transforms.CenterCrop(10), transforms.ToTensor()]) In PyTorch, every method that ends with an underscore (_) makes changes in-place, meaning, they will modify the underlying variable. 2.2 Tensor相关 2.2.1 一个例子 import torch x = torch.Tensor([[1.,2.,3.],[4.,5.,6.]]) x.requires_grad = True y = x + 1 z = y * y out = z.mean() loss = 20 - out loss.backward() print(x.data, '\\n', x.dtype, '\\n', x.device, '\\n', x.grad, '\\n', x.grad_fn, '\\n', x.requires_grad, '\\n') print(x) print(y) print(z) print(out) 运行得到: tensor([[1., 2., 3.], [4., 5., 6.]]) torch.float32 cpu tensor([[-0.6667, -1.0000, -1.3333], [-1.6667, -2.0000, -2.3333]]) None True tensor([[1., 2., 3.], [4., 5., 6.]], requires_grad=True) tensor([[2., 3., 4.], [5., 6., 7.]], grad_fn=&lt;AddBackward0&gt;) tensor([[ 4., 9., 16.], [25., 36., 49.]], grad_fn=&lt;MulBackward0&gt;) tensor(23.1667, grad_fn=&lt;MeanBackward1&gt;) x是一个tensor， x的核心部分 x.data 可以理解成一个n-dimensional array。 此外，tensor还有其他几个属性： x.dtpe, x.device, x.grad, x.grad_fn等， 其中： x.grad 是求得的梯度 x.requires_grad 表示该变量是否需要autograd y.grad_fn 记录了该变量求导应该用的function。 例如y由加法得到， y.grad_fn = &lt;AddBackward0&gt;; z由乘法得到， y.grad_fn = &lt;MulBackward0&gt; 2.2.2 tensor的操作 tensor 能像 numpy array 一样进行索引 max 操作 .max(k)表示求第k维的最大值，对于二维tensor，求列最大 k = 0，行最大 k = 1 import torch a = torch.tensor([[1, 2], [3, 4], [5, 6]]) print(a.max(1)) # 默认keepdim为false print(a.max(1)[0]) # 最大值 print(a.max(1)[1]) # 最大值对应的index print(a.max(1, keepdim = True)) 输出 torch.return_types.max(values=tensor([2, 4, 6]), indices=tensor([1, 1, 1])) tensor([2, 4, 6]) tensor([1, 1, 1]) torch.return_types.max(values=tensor([[2], [4], [6]]), indices=tensor([[1], [1], [1]])) 矩阵操作 用途 命令 创建随机数矩阵 x = torch.rand(5, 3) 创建正态分布随机数矩阵 x = torch.randn(2,4) 创建空矩阵 x = torch.empty(5, 3) 创建零矩阵并指定类型 x = torch.zeros(5, 3, dtype=torch.long) 直接指定元素值 x = torch.tensor([5.5, 0.02]) 维度变换 x = y.view(-1,10) 去掉个数为1的维度 x = y.squeeze() one-hot encoding/decoding pytorch.scatter_(), pytorch.gather() 2.2.3 Tensor 和 Numpy 转换 Tensor与numpy对象共享内存，但numpy只支持CPU，所以他们在CPU之间切换很快。但也意味着其中一个变化了，另外一个也会变。 tensor 和 python 对象转换： tensor.tolist()：多个元素的tensor tensor.item()：只能用于含一个元素的tensor（标量） Torch -&gt; NumPy: a = torch.ones(5) # Torch Tensor b = a.numpy() # NumPy Array Numpy -&gt; Torch: import numpy as np a = np.ones(5) # NumPy Array b = torch.from_numpy(a) # Torch Tensor 图像从cv2.imread()的numpy转换为可输入网络的tensor： cv2 numpy默认格式：H*W*C, BGR; torch tensor默认格式：C*H*W, RGB import cv2 import torchvision.transforms image_np = cv2.imread(&quot;1.jpg&quot;) # Method 1 image_tensor = transforms.Totensor()(image_np) # Method 2 image_np = image_np[:, :, ::-1] image_tensor = image_np.transpose((1,2,0)) 2.2.4 在 CPU 和 GPU 之间移动数据 # move the tensor to GPU x = x.to(&quot;cuda&quot;) # or x = x.cuda() # directly create a tensor on GPU device = 'cuda' if torch.cuda.is_available() else 'cpu' torch.manual_seed(42) a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device) b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device) # move the tensor to CPU x = x.to(&quot;cpu&quot;) # or x = x.cpu() 2.2.5 .detach(), .detach_() 和 .data 区别 https://www.cnblogs.com/wanghui-garcia/p/10677071.html https://zhuanlan.zhihu.com/p/83329768 .detach() 和 .detach_() detach_() 是对 Variable 本身的更改，detach() 则是生成了一个新的 Variable .detach() 和 .data 相同点： requires_grad 都为 false，即使之后重新将它的requires_grad置为true，它也不会具有梯度grad 都返回一个从当前计算图中分离下来的，新的Variable。但是仍指向原变量的存放位置，也即和原变量共享一块内存 .detach() 和 .data 不同点： .detach()之后修改会被autograd追踪，保证了只要在backward过程中没有报错，那么梯度的计算就是正确的 .data之后的修改不会被autograd追踪，可能会产生错误的梯度，所以 .data 不够安全，用 x.detach() 更好 .detach() 之后不进行修改： import torch a = torch.tensor([1, 2, 3.], requires_grad=True) out = a.sigmoid() c = out.detach() # 这时候没有对c进行更改，所以并不会影响backward() out.sum().backward() .detach() 之后进行in-place修改： import torch a = torch.tensor([1, 2, 3.], requires_grad=True) out = a.sigmoid() c = out.detach() c.zero_() print(c) # tensor([0., 0., 0.]) print(out) # tensor([0., 0., 0.], grad_fn=&lt;SigmoidBackward&gt;) out.sum().backward() # 报错 .data 之后进行修改 import torch a = torch.tensor([1, 2, 3.], requires_grad=True) out = a.sigmoid() c = out.data # 会发现c的修改同时也会影响out的值 c.zero_() print(c, out) # 不同之处在于.data的修改不会被autograd追踪，这样当进行backward()时它不会报错，会得到一个错误的backward值 out.sum().backward() print(a.grad) # tensor([0., 0., 0.]) 3. 代码分析 参考: https://github.com/pytorch/tutorials https://github.com/pytorch/examples http://pytorch.org/docs/ https://discuss.pytorch.org/ 3.1 A Toy Example of Back Propagation Only need to define the forward function, and the backward function is automatically defined. Define the network (step 1) import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() Process inputs (step 2) input = torch.randn(1, 1, 32, 32) out = net(input) Compute the loss (step 3) output = net(input) target = torch.randn(10) # a dummy target, for example target = target.view(1, -1) # reshape the dimension with -1 inferred from other dimensions (10/1=10, the same shape with input) criterion = nn.MSELoss() loss = criterion(output, target) Backprop and update the weights (step 4) import torch.optim as optim optimizer = optim.SGD(net.parameters(), lr=0.01) # optimizer obtains the references of parameters optimizer.zero_grad() # zero the gradient buffers loss.backward() # calculate the gradients of parameters optimizer.step() # Does the update 3.2 Steps to Train a Classifier Load the dataset (step 1) import torch import torchvision import torchvision.transforms as transforms transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))] ) trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) Define the network. Same as before. (step 2) import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() Define the loss function and optimizer. Same as before. (step 3) import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) Train the network (step 4) for epoch in range(2): # loop over the dataset multiple times running_loss = 0.0 for i, data in enumerate(trainloader, 0): # get the inputs inputs, labels = data # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # print statistics running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 Test the network (step 5) correct = 0 total = 0 with torch.no_grad(): # 因为Pytorch会自动计算梯度，但这里明确告诉它不用计算梯度了 for data in testloader: images, labels = data outputs = net(images) # 这里output是torch.autograd.Variable的类型 _, predicted = torch.max(outputs.data, 1) # output.data才是tensor格式，1代表在哪个维度求最大值 total += labels.size(0) # labels.size()=1 correct += (predicted == labels).sum().item() print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total)) Options: Train on GPU/GPUs 用多个GPU：net = nn.DataParallel(net) # training on the first cuda device device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) net.to(device) inputs, labels = inputs.to(device), labels.to(device) 3.3 Yolov3的实现摘要 import torch.nn as nn import torch.nn.functional as F def get_test_input(): # 读取图片，得到torch变量(略)# return img_ def parse_cfg(cfgfile): #block格式是字典，代表网络中的一个Module (一个Module可能有多层)。blocks是block组成的列表，代表整个cfg文件。 block = {} blocks = [] # 此处要进行一些cfg文件读取操作(略)# return blocks def create_modules(blocks): net_info = blocks[0] #读取cfg文件中的[net]信息 module_list = nn.ModuleList() #module_list存储了用blocks构建的整个网络，module_list对应于blocks[1:] output_filters = [] #记录之前每个层的卷积核数量 prev_filters = 3 #初始输入数据3通道。每次卷积都将prev_filters个通道变为filters个通道 for index, x in enumerate(blocks[1:]): #x是一个字典，与block类似 module = nn.Sequential() #A module could have many layers (Conv, BN, ReLU...) if (x[&quot;type&quot;] == &quot;convolutional&quot;): #卷积层 # 添加卷基层 conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias) module.add_module(&quot;conv_{0}&quot;.format(index), conv) #Adds a child module to the current module #添加BN层 bn = nn.BatchNorm2d(filters) module.add_module(&quot;batch_norm_{0}&quot;.format(index), bn) #其他层以此类推(略)# elif (x[&quot;type&quot;] == &quot;upsample&quot;): #上采样层 #写法同卷基层(略)# module_list.append(module) prev_filters = filters output_filters.append(filters) return (net_info, module_list) ","link":"https://kimokcheon.github.io/post/pytorch/"},{"title":"C++ OpenCV","content":"1. OpenCV头文件 cv.hpp和opencv.hpp是等同的关系。只不过，前者是早期opencv版本中的定义名称，而后者opencv.hpp则是3.0版本之后的表示方法。 cv.hpp和opencv.hpp都包含了一下头文件 #include &lt;opencv2/core.hpp&gt; #include &lt;opencv2/imgproc.hpp&gt; #include &lt;opencv2/video.hpp&gt; #include &lt;opencv2/objdetect.hpp&gt; #include &lt;opencv2/imgcodecs.hpp&gt; #include &lt;opencv2/highgui.hpp&gt; #include &lt;opencv2/ml.hpp&gt; 简言之，我们在编写代码的时候，或许只需要一个简单的#include&lt;opencv2/opencv.hpp&gt;就可以轻松的解决红色波浪线未定义字符的烦恼。 .hpp和.h文件差别是.hpp把还包含了函数实现。 2. Mat和Mat_ 2.1 Mat 图像的表示：最老的C接口的OpenCV版本中，用 IplImage ，需要手动管理内存。C++接口的OpenCV中，用 Mat ，不用手动管理内存。 浅拷贝：Mat对象的赋值运算或拷贝构造函数只拷贝Header，不拷贝矩阵数据，对一个对象的修改会影响其他对象。 Mat A, C; // creates just the header parts A = imread(argv[1], IMREAD_COLOR); // here we'll know the method used (allocate matrix) Mat B(A); // Use the copy constructor C = A; // Assignment operator 深拷贝：可用cv::Mat::clone()和cv::Mat::copyTo()实现图像矩阵数据的拷贝。 Mat F = A.clone(); Mat G; A.copyTo(G); 除此之外，cv::Mat还有如下常用属性： API reference: https://docs.opencv.org/3.1.0/d3/d63/classcv_1_1Mat.html 成员函数 解释 void cv::Mat::create (int rows, int cols, int type) 创建矩阵 _Tp&amp; cv::Mat::at (int i0, int i1) 例如用image.at&lt;Vec3b&gt;(y,x)[c]访问y行x列c通道的值 uchar * ptr() 行指针，例如image.ptr&lt;uchar&gt;(1)为指向第1行首地址的指针 int cv::Mat::channels () const 矩阵元素的通道数，例如RGB为三个通道 int cv::Mat::type () const 它是一系列的预定义的常量，命名规则为CV_+（位数）+（数据类型）+ C +（通道数），例如CV_8UC1 int cv::Mat::depth () const 返回矩阵元素的深度，例如一个8-bit signed element array，返回CV_8U 成员变量 解释 uchar* cv::Mat::data uchar类型的指针，指向Mat数据矩阵的首地址 int cv::Mat::dims Mat矩阵的维度，若Mat是一个二维矩阵，则 dims=2，三维则 dims=3 int cv::Mat::cols 矩阵列数，如果 dims&gt;2 为-1 int cv::Mat::rows 矩阵行数，如果 dims&gt;2 为-1 cv::Mat::step 步长，指为了便于访问矩阵元素，需要移动多少距离，例如多幅同样大小的图像组成的3维矩阵: step[0] 指从当前图像开始处到下一图像的开始处跨越多少字节 step[1] 指从当前图像行首到下一行首相距多少字节 step[2] 从当前像素到下一像素步长是多少 image.step这样的用法也就是image.step[0]的意思 cv::Mat:: size 是指多维矩阵中每一维的大小，例如多幅同样大小的图像组成的3维矩阵: size[0] 指有共有多少幅图像 size[1] 指单幅图像有多少行 size[3] 指单幅图像有多少列 cv::Mat下图像的遍历方法： //*********遍历方法1：.at 操作***********// for(int y = 0; y &lt; image.rows; y++) { for( int x = 0; x &lt; image.cols; x++) { for( int c = 0; c &lt; image.channels(); c++) { new_image.at&lt;Vec3b&gt;(y,x)[c] = saturate_cast&lt;uchar&gt;(alpha*image.at&lt;Vec3b&gt;(y,x)[c] + beta); // saturate_cast&lt;&gt;实现从一个类型到另一个类型的映射（saturate的意思是按比例缩放至saturation） } } } //*********更高效的遍历方法：用行指针***************// for (size_t y=0; y&lt;image.rows; y++) { // size_t在C语言中就有了，是一种用来记录大小的数据类型，此处也可用int代替 unsigned char* row_ptr = image.ptr&lt;unsigned char&gt; (y); // row_ptr是第y行的头指针 for（size_t x=0; x&lt;image.cols; x++）{ unsigned char* data_ptr = &amp;row_ptr[x * image.channels()]; // data_ptr为指向像素数据的指针 for (int c = 0; c != image.channels(); c++) { unsigned char data = data_ptr[c]; // data为I(x,y)第c个通道的值 } } } // unsigned char范围为0-255。 eg. 若image.depth() == CV_8U，则每个像素每个通道都是用0-255表示 // OpenCV库中定义Vec3b的语句：`typedef Vec&lt;uchar, 3&gt; cv::Vec3b`，所以`Vec3b`表示一个uchar类型的数组，长度为3。 //其中`cv::Vec&lt; _Tp, cn &gt;`是OpenCV中定义的一个类，继承了`cv::Matx&lt; _Tp, m, n &gt;`这个类。 2.2 Mat_ 一些代码中用到cv::Mat_，Mat_继承了Mat类，但比Mat类并没有更多的东西。只是在编译前就能确定元素类型时，用Mat_会更方便。 例如： Mat访问元素调用的是 Mat::at(int y,int x)， Mat image(100,100,CV_8U); image.at(1,2) = 2; Mat_访问元素调用的是 Mat_::operator()(int y,int x))， Mat_&lt;double&gt; image(20,20); image(1,2) = 3; template&lt;typename T&gt; class Mat_ : public Mat { public: // ... some specific methods // and // no new extra fields }; 3. 实践 OpenCV读取多个读取多个IP摄像头的视频流 https://zhuanlan.zhihu.com/p/38136322 用 cv2 写视频 https://blog.csdn.net/Arctic_Beacon/article/details/111587432 https://stackoverflow.com/questions/57235454/opencv-video-write-out-size-is-reduced filename_rgb = f&quot;{foldername}/rgb.avi&quot; fourcc_rgb = cv2.VideoWriter_fourcc(*'XVID') # size: `fourcc = 0` &gt; HFYU &gt;&gt; MJPG &gt;&gt; DIVX = XVID # fourcc_rgb = 0 # the raw video, no compression vout_rgb = cv2.VideoWriter() vout_rgb.open(filename_rgb, fourcc_rgb, 30, (640, 480), isColor=True) while 1: vout_rgb.write(rgbframe) ","link":"https://kimokcheon.github.io/post/c-opencv/"},{"title":"CUDA Installation","content":"CUDA 的内部工作原理:为什么能加速 https://www.jianshu.com/p/34a504af8d51 Installation https://blog.csdn.net/wanzhen4330/article/details/81699769 用Nvidia显卡配置Deep Learning环境分三步： 安装Nvidia Driver和CUDA Toolkit：Driver/CUDA toolkit 安装Library： cuDNN/TensorRT等 安装Framework：tensorflow/pytorch等 Driver &amp; CUDA toolkit 查看显卡型号：lspci | grep -i vga 查是显卡否支持CUDA: http://developer.nvidia.com/cuda-gpus 下载CUDA Installer并运行: https://developer.nvidia.com/cuda-toolkit-archivewget http://developer.download.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.243_418.87.00_linux.run sudo sh cuda_10.1.243_418.87.00_linux.run Installer中可选择是否安装driver，如果已经安装过了那就不安装driver 有时用toolkit安装驱动会报错，是版本问题（toolkit默认安装的驱动版本系统不支持），可以先下驱动安装了，再用toolkit安装cuda等 cuDNN / TensorRT cuDNN 下载需要的版本 https://developer.nvidia.com/rdp/cudnn-archive 解压下载的文件，可以看到cuda文件夹。做两件事：（1）将解压所得的cuda内的文件复制到cuda安装目录。（2）改权限 sudo cp cuda/include/cudnn*.h /usr/local/cuda/include/ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/ sudo chmod a+r /usr/local/cuda/include/cudnn*.h sudo chmod a+r /usr/local/cuda/lib64/libcudnn* TensorRT https://blog.csdn.net/zong596568821xp/article/details/86077553 用 tar 安装，下载后解压并配置环境变量，https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-tar 验证：cd TensorRT-8.2.4.2/samples/sampleMNIST, make CUDA_INSTALL_DIR=/usr/local/cuda （报错后再编译前先 make clean），生成的可执行文件在 bin 中 Conda 创建环境安装 Torch tensorflow 和 CUDA/cuDNN 版本兼容性：https://www.tensorflow.org/install/source_windows#gpu# conda 安装 https://www.jianshu.com/p/edaa744ea47d mkdir miniconda3 cd miniconda3 wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh chmod 777 Miniconda3-latest-Linux-x86_64.sh #给执行权限 bash Miniconda3-latest-Linux-x86_64.sh -u #运行 # conda 内安装 conda create -n ml python=3.7 conda config --set auto_activate_base false # 在 ~/.bashrc 最后一行加 conda activate ml # 进入 (ml) 后 pip3 install matplotlib numpy==1.19.5 scipy==1.7.3 scikit-learn==1.0.2 pandas pyyaml # 安装 nvidia driver 对应版本的 cuda/torch nvidia-smi nvcc --version # 上pytorch官网查找对应版本安装命令；发现是 9.0 版本，只能安pytocrh 1.1 conda install pytorch==1.1.0 torchvision==0.3.0 cudatoolkit=9.0 -c pytorch pip3 install tensorboard conda 常用命令，查询/退出/激活/删除 conda env list, conda deactivate, conda activate $ENV_NAME, conda env remove -n $ENV_NAME 检查是否安装成功 # torch-gpu, cudnn import torch from torch.backends import cudnn print(torch.cuda.is_available()) print(cudnn.is_available()) a = torch.tensor(1.) print(cudnn.is_acceptable(a.cuda())) # tensorflow-gpu import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' import tensorflow as tf print(tf.__version__) print(tf.__path__) print(tf.test.is_gpu_available()) A = tf.constant([[1, 2], [3, 4]]) B = tf.constant([[5, 6], [7, 8]]) C = tf.matmul(A, B) print(C) Tensorflow可能会提示warning，说TensorRT未安装，如果不用的话不用管： 2020-04-18 13:35:50.278790: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/xian/cuda-10.1/lib64 2020-04-18 13:35:50.278888: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/xian/cuda-10.1/lib64 2020-04-18 13:35:50.278903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Others Non-root下安装 在多个用户共用一台server的情况下，每个user可以安装不同的 CUDA Toolkit / cuDNN / tensorflow / pytorch 版本： Nvidia显卡driver必须要用root权限安装，多用户共用一个driver版本 其他的都用非root权限安装，并安装在user目录（CUDA Installer包的运行还是要用root权限，否则报错segmentation fault)。进入后，不勾选install driver，并且更改安装路径为user内部） 提前改变user目录的所有者：su root chown -R alex /home/alex ls -l 查看CUDA，cuDNN安装路径、版本等 如果安装在root目录： CUDA 版本：cat /usr/local/cuda/version.txt cuDNN 版本：cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 安装在non-root目录，手动搜索安装路径： find -name &quot;*cuda*&quot; find -name &quot;*cudnn*&quot; Driver/CUDA/cuDNN等的关系 Driver 安装之后，可用nvidia-smi查看。nvidia-smi中显示的CUDA version仅代表该 driver 兼容的 CUDA 版本，并不意味着 CUDA 已经安装。(The CUDA VERSION display within nvidia-smi was not added until driver 410.72. CUDA VERSION displayed by nvidia-smi associated with newer drivers is the DRIVER API COMPATIBILITY VERSION.) CUDA Installer内含特定版本Nvidia显卡驱动的，所以只选择下载CUDA Installer就足够了。如果想安装其他版本的显卡驱动就下载相应版本即可：https://www.nvidia.com/Download/index.aspx?lang=en-us NVIDIA显卡驱动和CUDA Toolkit本身不具有捆绑关系的，也不是一一对应。只不过是离线安装的CUDA Toolkit会默认携带与之匹配的最新的驱动程序。CUDA本质上只是一个工具包而已，所以我可以在同一个设备上安装很多个不同版本的CUDA工具包，例如 CUDA 9.0、CUDA 9.2、CUDA 10.0三个版本。一般情况下，我们直接安装最新版的显卡驱动，然后在线安装不同版本的CUDA即可。 cuDNN是一个SDK，是一个专门用于神经网络的加速包。它跟我们的CUDA没有一一对应的关系，即每一个版本的CUDA可能有好几个版本的cuDNN与之对应，但一般有一个最新版本的cuDNN版本与CUDA对应更好。 Using Docker Install CUDA driver-&gt; Install docker -&gt; Install nvidia-docker -&gt; pull images of CUDA tools: https://devblogs.nvidia.com/nvidia-docker-gpu-server-application-deployment-made-easy/ If meet problem in driver installation: https://blog.csdn.net/u014561933/article/details/79958130 ","link":"https://kimokcheon.github.io/post/cuda-install/"},{"title":"复变函数","content":"第一章 复变函数 1.1 复数及其运算 简单，略。 1.2 复变函数的连续性与可微性 1.2.1 复变函数 两种表示法： w=f(z)w=f(z) w=f(z) f(z)=u(x,y)+iv(x,y)f(z)=u(x,y)+iv(x,y) f(z)=u(x,y)+iv(x,y) 1.2.2 复变函数的连续性 1、 f(z)f(z)f(z)在z0z_0z0​点连续： lim⁡z→z0f(z)=f(z0),∀z:∣z−z0∣&lt;δ\\lim\\limits_{z\\to z_0}f(z)=f(z_0), \\forall z:|z-z_0|&lt;\\delta z→z0​lim​f(z)=f(z0​),∀z:∣z−z0​∣&lt;δ 2、设G⊂CG\\subset \\mathbb{C}G⊂C，定义： 内点：z0z_0z0​的一个足够小的邻域内所有点都在G内，则称z0z_0z0​为G的内点。 区域：G中的点都是G的内点，且G具有连通性，则称G为区域。 边界点：边界点不属于区域，但是以边界点为圆心的圆中恒有区域内的点。 边界：边界点的全体。 闭区域：区域+边界。 3、有界函数：设f(z)=u(x,y)+iv(x,y)f(z)=u(x,y)+iv(x,y)f(z)=u(x,y)+iv(x,y)是有界闭区域R上的连续函数，则它的模函数∥f(z)∥=u2(x,y)+v2(x,y)\\|f(z)\\|=\\sqrt{u^2(x,y)+v^2(x,y)}∥f(z)∥=u2(x,y)+v2(x,y)​是R上的连续函数且在R上取得最大值。 1.2.3 可微性 1、可导：若对点z0∈Gz_0\\in Gz0​∈G，极限 lim⁡z→z0f(z)−f(z0)z−z0\\lim\\limits_{z\\to z_0}\\frac{f(z)-f(z_0)}{z-z_0} z→z0​lim​z−z0​f(z)−f(z0​)​ 存在，则称函数f(z)f(z)f(z)在z0z_0z0​点可导。 注：f(z)=∥z∥2f(z)=\\|z\\|^2f(z)=∥z∥2仅在点z=0处可微。 2、可微必连续。 1.2.4 Cauchy-Riemann方程（★★★） 定理1.2.1 f(z)f(z)f(z)在z0z_0z0​处可微的充分必要条件：f(z)f(z)f(z)的实部u(z,y)u(z,y)u(z,y)和虚部v(x,y)v(x,y)v(x,y)均在(x0,y0)(x_0,y_0)(x0​,y0​)处可微，且满足Cauchy-Riemann方程： ux(x0,y0)=vy(x0,y0),uy(x0,y0)=−vx(x0,y0)u_x(x_0,y_0)=v_y(x_0,y_0), u_y(x_0,y_0)=-v_x(x_0,y_0) ux​(x0​,y0​)=vy​(x0​,y0​),uy​(x0​,y0​)=−vx​(x0​,y0​) 注：这时实际上有一个重要推论： f′(z0)=ux(x0,y0)+ivx(x0,y0),f&#x27;(z_0)=u_x(x_0,y_0)+iv_x(x_0,y_0), f′(z0​)=ux​(x0​,y0​)+ivx​(x0​,y0​), 或 f′(z0)=vy(x0,y0)−iuy(x0,y0)f&#x27;(z_0)=v_y(x_0,y_0)-iu_y(x_0,y_0) f′(z0​)=vy​(x0​,y0​)−iuy​(x0​,y0​) 1.3 解析函数 解析函数：如果f(z)f(z)f(z)在z0z_0z0​的某个邻域内逐点可导，则称f(z)f(z)f(z)在点z0z_0z0​是解析的（全纯的）。 整函数：如果f(z)f(z)f(z)在整个复平面C\\mathbb{C}C上是解析的，则称f(z)f(z)f(z)是整函数。 奇点：如果fff在点z0z_0z0​处不是解析的，但是在z0z_0z0​的任意邻域（极限情况：任意小）中的某些点处解析，则称z0z_0z0​是fff的一个奇点。 注： 1. 复变函数不可能在其定义域的边界上解析。我们说一个复变函数在闭区域Gˉ\\bar GGˉ上解析，是说它在包含Gˉ\\bar GGˉ的某个区域内解析。 2. f(z)=∥z∥2f(z)=\\|z\\|^2f(z)=∥z∥2处处不解析，因此没有奇点。 1.3.1 解析函数的四则运算 定理1.3.1 两个在区域GGG中解析的函数，四则运算（不除0）仍在GGG内解析，且有与实变函数形式上一致的求导公式。 定理1.3.2 考虑定义域内，函数复合后仍解析，且满足链式法则。 1.3.2 调和函数 调和函数：对一个实函数u(x,y)u(x,y)u(x,y)，若它在GGG上有连续的一阶和二阶偏导数，且满足Laplace方程： Δu=∂2u∂x2+∂2u∂y2\\Delta u=\\frac{\\partial^2u}{\\partial x^2}+\\frac{\\partial^2u}{\\partial y^2} Δu=∂x2∂2u​+∂y2∂2u​ 则称u(x,y)u(x,y)u(x,y)为区域GGG上的一个调和函数。 引理1.3.1 在某点z0z_0z0​处解析的函数fff在z0z_0z0​处具有任意阶连续偏导数。 定理1.3.3 GGG中的解析函数fff的实部和虚部都是调和函数，且满足Cauchy-Riemann方程。 共轭调和函数：在区域GGG内，称v(x,y)v(x,y)v(x,y)是u(x,y)u(x,y)u(x,y)的共轭调和函数，如果它们满足C-R方程。 定理1.3.4 在区域GGG中，f=u+ivf=u+ivf=u+iv是解析函数⇔\\Leftrightarrow⇔v是u的共轭调和函数。 1.3.3 初等函数 1、幂函数、指数函数、三角函数、双曲函数等基本的解析函数，都可以看成是相应的实变函数在复数域中的推广。 2、偏导数连续是一个极强的条件，它可以推出可微、可偏导、连续，它们三个中的任何一个不能推出偏导数连续。用图片表示如下（来源：知乎专栏 -- 二元微分：连续、可微、可偏导、偏导连续的超强通俗解析！）： 3、常见解析函数：全部初等函数、多数特殊函数（超几何函数、贝塞尔函数、伽马函数等） 4、常见非解析函数：绝对值函数（它在点0处不可微）、复共轭函数 第二章 复变函数的积分 2.1 复变函数的曲线积分 2.1.1 复变函数的定积分 定积分：复变函数的定积分定义如下： ∫abF(t)dt=∫abu(t)dt+i∫abv(t)dt\\int_a^bF(t)dt=\\int_a^bu(t)dt+i\\int_a^bv(t)dt ∫ab​F(t)dt=∫ab​u(t)dt+i∫ab​v(t)dt 性质： 1、∀a,b∈R\\forall a,b \\in \\mathbb{R}∀a,b∈R， ∫abF(t)dt=−∫baF(t)dt\\int_a^bF(t)dt=-\\int_b^aF(t)dt ∫ab​F(t)dt=−∫ba​F(t)dt 2、∀C1,C2\\forall C_1, C_2∀C1​,C2​， ∫ab[C1F(t)+C2G(t)]dt=C1∫abF(t)dt+C2∫abG(t)dt\\int_a^b[C_1F(t)+C_2G(t)]dt=C_1\\int_a^bF(t)dt+C_2\\int_a^bG(t)dt ∫ab​[C1​F(t)+C2​G(t)]dt=C1​∫ab​F(t)dt+C2​∫ab​G(t)dt 3、如果a&lt;ba&lt;ba&lt;b，那么 ∣∫abF(t)dt∣≤∫ab∣F(t)∣dt\\Bigg|\\int_a^bF(t)dt\\Bigg| \\leq \\int_a^b|F(t)|dt ∣∣∣∣∣​∫ab​F(t)dt∣∣∣∣∣​≤∫ab​∣F(t)∣dt 4、 Re∫abF(t)dt=∫abRe[F(t)]dtRe\\int_a^bF(t)dt=\\int_a^bRe[F(t)]dt Re∫ab​F(t)dt=∫ab​Re[F(t)]dt 2.1.2 曲线 曲线：复平面上的一条曲线CCC是指实轴上的一个区间（参数ttt）到复平面（x(t)+iy(t)x(t)+iy(t)x(t)+iy(t)）的一个连续映射： C:[a,b]→C,t↦z=z(t)C:[a,b]\\to\\mathbb{C},t\\mapsto z=z(t) C:[a,b]→C,t↦z=z(t) 简单曲线：曲线CCC不自交，即在(a,b)(a,b)(a,b)内，t1≠t2⇒z(t1)≠z(t2)t_1\\neq t_2 \\Rightarrow z(t_1) \\neq z(t_2)t1​​=t2​⇒z(t1​)​=z(t2​)。 光滑曲线：z=z(t)z=z(t)z=z(t)在[a,b][a,b][a,b]上有连续的导数，即x=x(t)x=x(t)x=x(t)和y=y(t)y=y(t)y=y(t)有连续的导数x′(t)x&#x27;(t)x′(t)和y′(t)y&#x27;(t)y′(t)，并且满足 ∣z′(t)∣2=[x′(t)]2+[y′(t)]2≠0,∀t∈[a,b]|z&#x27;(t)|^2=[x&#x27;(t)]^2+[y&#x27;(t)]^2\\neq 0, \\forall t\\in [a,b] ∣z′(t)∣2=[x′(t)]2+[y′(t)]2​=0,∀t∈[a,b] 逐段光滑曲线：如果有有限个点tj(j=0,1,⋯ ,n){t_j}(j=0,1,\\cdots,n)tj​(j=0,1,⋯,n)满足t0=a&lt;t1&lt;⋯&lt;tn−1&lt;tn=bt_0=a&lt;t_1&lt; \\cdots &lt;t_{n-1}&lt;t_n=bt0​=a&lt;t1​&lt;⋯&lt;tn−1​&lt;tn​=b并使得x=x(t)x=x(t)x=x(t)和y=y(t)y=y(t)y=y(t)限制在每一个闭区间[tj−1,tj][t_{j-1},t_j][tj−1​,tj​]上都对应一条光滑曲线弧，则称曲线CCC为逐段光滑曲线。 简单闭曲线：z(t)z(t)z(t)的起始值和终点值相等。 有定向曲线：规定了参数变化方向的曲线。 曲线的长度：因为∥z′(t)∥=[x′(t)]2+[y′(t)]2\\|z&#x27;(t)\\|=\\sqrt{[x&#x27;(t)]^2+[y&#x27;(t)]^2}∥z′(t)∥=[x′(t)]2+[y′(t)]2​，于是，一条光滑曲线CCC的长度LLL为 L=∫ab∣z′(t)∣dtL=\\int_a^b|z&#x27;(t)|dt L=∫ab​∣z′(t)∣dt Jordan曲线定理：任意简单闭曲线CCC把复平面分成两部分。 2.1.3 曲线积分 曲线积分：复变函数的定积分定义如下： ∫Cf(z)dz=∫abf(z(t))z′(t)dt\\int_Cf(z)dz=\\int_a^bf(z(t))z&#x27;(t)dt ∫C​f(z)dz=∫ab​f(z(t))z′(t)dt 将被积函数用u,v,x,yu,v,x,yu,v,x,y展开，得 ∫Cf(z)dz=∫C(udx−vdy)+i∫C(vdx+udy)\\int_Cf(z)dz=\\int_C(udx-vdy)+i\\int_C(vdx+udy) ∫C​f(z)dz=∫C​(udx−vdy)+i∫C​(vdx+udy) 性质： 1、∀γ∈C\\forall \\gamma \\in \\mathbb{C}∀γ∈C， ∫Cγf(z)dz=γ∫Cf(z)dz\\int_C\\gamma f(z)dz=\\gamma\\int_Cf(z)dz ∫C​γf(z)dz=γ∫C​f(z)dz 2、 ∫C[f(z)±g(z)]dz=∫Cf(z)dz±∫Cg(z)dz\\int_C[f(z)\\pm g(z)]dz=\\int_Cf(z)dz\\pm \\int_Cg(z)dz ∫C​[f(z)±g(z)]dz=∫C​f(z)dz±∫C​g(z)dz 3、如果CCC如下图所示 则 ∫Cf(z)dz=∫C1f(z)dz+∫C2f(z)dz\\int_Cf(z)dz=\\int_{C_1}f(z)dz+\\int_{C_2}f(z)dz ∫C​f(z)dz=∫C1​​f(z)dz+∫C2​​f(z)dz 4、 ∫−Cf(z)dz=−∫Cf(z)dz\\int_{-C}f(z)dz=-\\int_Cf(z)dz ∫−C​f(z)dz=−∫C​f(z)dz ML定理（★★★）：如果在曲线CCC上有∥f(z)∥≤M\\|f(z)\\| \\leq M∥f(z)∥≤M，且LLL是CCC的长度，那么 ∣∫Cf(z)dz∣≤ML\\Bigg|\\int_Cf(z)dz\\Bigg|\\leq ML ∣∣∣∣∣​∫C​f(z)dz∣∣∣∣∣​≤ML 2.2 积分与路径无关问题 积分与路径无关：设曲线CCC起点为α\\alphaα，终点为β\\betaβ，若曲线积分∫Cf(z)dz\\int_Cf(z)dz∫C​f(z)dz的值仅依赖于α\\alphaα和β\\betaβ，与CCC的选择无关，就称该积分与路径无关。 定理2.2.1 设函数f(z)f(z)f(z)在区域DDD内连续，则积分 ∫Cf(z)dz\\int_Cf(z)dz ∫C​f(z)dz 在DDD内与路径CCC无关⇔\\Leftrightarrow⇔ ∀\\forall∀简单闭曲线γ∈D\\gamma \\in Dγ∈D， ∫γf(z)dz=0\\int_{\\gamma}f(z)dz=0 ∫γ​f(z)dz=0 定理2.2.2 设f(z)f(z)f(z)在区域DDD内连续，则积分 ∫Cf(z)dz\\int_Cf(z)dz ∫C​f(z)dz 在DDD内与路径CCC无关⇔\\Leftrightarrow⇔ ∃\\exists∃解析函数F(z)∈DF(z)\\in DF(z)∈D，s.t.∀x∈D,F′(z)=f(z)s.t. \\forall x \\in D, F&#x27;(z)=f(z)s.t.∀x∈D,F′(z)=f(z)。 注： 1、当曲线积分与路径无关时，记 ∫Cf(z)dz=∫αβf(z)dz\\int_Cf(z)dz=\\int_\\alpha^\\beta f(z)dz ∫C​f(z)dz=∫αβ​f(z)dz 2、设f(z)f(z)f(z)在DDD内的曲线积分与路径无关，且F(z)F(z)F(z)是f(z)f(z)f(z)的原函数，则 ∫αβf(z)dz=F(β)−F(α)\\int_\\alpha^\\beta f(z)dz=F(\\beta)-F(\\alpha) ∫αβ​f(z)dz=F(β)−F(α) 2.3 Cauchy-Goursat定理 Green定理 设CCC是一条逆时针走向的简单闭曲线，DDD是由CCC围起的区域。如果P(x,y)P(x,y)P(x,y)和Q(x,y)Q(x,y)Q(x,y)是该闭区域上的实值连续函数，且有一阶连续偏导数，则 ∫CPdx+Qdy=∬D(Qx−Py)dxdy\\int_C Pdx+Qdy=\\iint_D(Q_x-P_y)dxdy ∫C​Pdx+Qdy=∬D​(Qx​−Py​)dxdy Cauchy-Goursat定理（★★★） 设DDD是一个单连通区域，而f(z)f(z)f(z)是区域DDD内的解析函数，又设CCC是DDD内的任意一条逐段光滑的简单闭曲线。则对于CCC的任意一种定向，都有 ∫Cf(z)dz=0\\int_C f(z)dz=0 ∫C​f(z)dz=0 2.3.1 Cauchy-Goursat定理的推广形式 单连通区域：区域DDD中的任意一条闭曲线内的点都是DDD的点，则称DDD为单连通区域。 多连通区域：不是单连通的区域。 定理2.3.1 设多连通区域DDD如下图所示， 其中CCC的定向为逆时针方向，其它边界曲线CiC_iCi​定向顺时针，则 ∫Cf(z)dz+∑k=1n∫Ckf(z)dz=0 \\int_C f(z)dz+\\sum_{k=1}^n\\int_{C_k}f(z)dz=0 ∫C​f(z)dz+k=1∑n​∫Ck​​f(z)dz=0 推论2.3.1（曲线变形） 设C1,C2C_1,C_2C1​,C2​是两条逐段光滑的简单闭曲线，定向逆时针，C2C_2C2​在C1C_1C1​内部，设DDD为两曲线之间的区域，如果f(z)f(z)f(z)在闭区域Dˉ\\bar DDˉ上解析，则 ∫C1f(z)dz=∫C2f(z)dz\\int_{C_1}f(z)dz=\\int_{C_2}f(z)dz ∫C1​​f(z)dz=∫C2​​f(z)dz 2.3.2 一个重要的常用积分 ∫C(z−a)ndz={0,n≠−1;2πi,n=−1. \\int_C (z-a)^ndz=\\left\\{ \\begin{aligned} &amp;0,&amp;n\\neq -1;\\\\ &amp;2\\pi i, &amp;n=-1. \\end{aligned} \\right. ∫C​(z−a)ndz={​0,2πi,​n​=−1;n=−1.​ 2.4 Cauchy积分公式 定理2.4.1 单连通区域DDD、解析函数fff、任意一条逐段光滑的简单闭曲线CCC、定向逆时针。对于CCC内任意一点zzz，有 f(z)=12πi∫Cf(ζ)ζ−zdζf(z)=\\frac{1}{2\\pi i}\\int_C\\frac{f(\\zeta)}{\\zeta -z}d\\zeta f(z)=2πi1​∫C​ζ−zf(ζ)​dζ 公式(30)(30)(30)被称为Cauchy积分公式。 注：Cauchy积分公式表明，解析函数在区域内一点的值可以用它在边界上的值表示出来。可以用它来计算一些闭曲线积分。 2.4.1 Cauchy积分公式的一般形式 定理2.4.2 区域DDD的边界由C0,C1,⋯ ,CnC_0,C_1,\\cdots,C_nC0​,C1​,⋯,Cn​组成，如图所示，定向为关于区域DDD的正向。 命C=⋃j=0nCjC=\\bigcup_{j=0}^nC_jC=⋃j=0n​Cj​，则对于DDD内任意一点zzz，有 f(z)=12πi∫Cf(ζ)ζ−zdζf(z)=\\frac{1}{2\\pi i}\\int_C\\frac{f(\\zeta)}{\\zeta -z}d\\zeta f(z)=2πi1​∫C​ζ−zf(ζ)​dζ 2.4.2 解析函数的导数及其Cauchy积分公式 解析函数的导数仍然是解析函数。 注：上面命题表明，复变函数在区域中关于自变量zzz处处可导（解析），意味着它无穷次可导。 定理2.4.3 设区域DDD如上图（定理2.4.2）所示。设f(z)f(z)f(z)在闭区域Dˉ\\bar DDˉ上解析。则 f(n)(z)=n!2πi∫Cf(ζ)(ζ−z)n+1dζf^{(n)}(z)=\\frac{n!}{2\\pi i}\\int_C\\frac{f(\\zeta)}{(\\zeta-z)^{n+1}}d\\zeta f(n)(z)=2πin!​∫C​(ζ−z)n+1f(ζ)​dζ 定理2.4.4 在区域DDD内，解析函数任意阶可导。特别地，它的导数仍解析。 2.4.3 代数基本定理的证明 定理2.4.5（代数基本定理） n(n≥1)n(n\\geq 1)n(n≥1)次多项式在复数域中至少有一个根。 证明思路. 1、证明 lim⁡R→∞∣p(Reiθ)∣=∞\\lim_{R\\to \\infty}|p(Re^{i\\theta })|=\\infty R→∞lim​∣p(Reiθ)∣=∞ 其中p(z)p(z)p(z)是nnn次多项式。 2、构造函数q(z)=1p(z)q(z)=\\frac{1}{p(z)}q(z)=p(z)1​，反证得q(0)=0(R→∞)q(0)=0(R\\to \\infty)q(0)=0(R→∞)，矛盾。 2.4.4 Cauchy积分公式的应用 定理2.4.6（Morera定理） 设f(z)f(z)f(z)在区域DDD内连续，若对DDD内任意一条逐段光滑的简单闭曲线，都有 ∫Cf(z)dz=0\\int_C f(z)dz=0 ∫C​f(z)dz=0 则f(z)f(z)f(z)在DDD内解析。 利用Morera定理，可以得到解析函数的一个充要条件。 定理2.4.7 设f(z)f(z)f(z)在单连通区域DDD内连续，则f(z)f(z)f(z)在DDD内解析⇔\\Leftrightarrow⇔对DDD内任意一条逐段光滑的简单闭曲线，都有 ∫Cf(z)dz=0\\int_C f(z)dz=0 ∫C​f(z)dz=0 定理2.4.8（Cauchy不等式） 设f(z)f(z)f(z)在圆盘UR={z:∥z−a∥&lt;R}U_R=\\{z:\\|z-a\\|&lt;R\\}UR​={z:∥z−a∥&lt;R}内解析，如果∥f(z)∥\\|f(z)\\|∥f(z)∥在DDD内有上界MMM，则 ∣f(n)(z)∣≤n!MRn,n=1,2,⋯|f^{(n)}(z)|\\leq \\frac{n!M}{R^n},n=1,2,\\cdots ∣f(n)(z)∣≤Rnn!M​,n=1,2,⋯ 定理2.4.9（Liouville定理） 模在C\\mathbb{C}C上有界的整函数f(z)f(z)f(z)必为常数。 2.4.5 解析函数的平均值公式与最大模原理 引理2.4.1（Gauss平均值定理） 设f(z)f(z)f(z)在闭圆Uˉ={z:∥z−z0∥≤R}\\bar U=\\{z:\\|z-z_0\\|\\leq R\\}Uˉ={z:∥z−z0​∥≤R}上解析，则f(z)f(z)f(z)在圆心z0z_0z0​处的值等于它在圆周上的值的算术平均，即 f(z0)=12π∫o2πf(z0+Reiθ)dθf(z_0)=\\frac{1}{2\\pi}\\int_o^{2\\pi}f(z_0+Re^{i\\theta})d\\theta f(z0​)=2π1​∫o2π​f(z0​+Reiθ)dθ 公式(37)(37)(37)被称为Gauss平均值公式。 利用Gauss平均值公式，可得到如下引理。 引理2.4.2 设f(z)f(z)f(z)在z0z_0z0​的某个邻域Uϵ={z:∥z−z0∥&lt;ϵ}U_{\\epsilon}=\\{z:\\|z-z_0\\|&lt;\\epsilon\\}Uϵ​={z:∥z−z0​∥&lt;ϵ}内解析。若对任意zzz，满足f(z)≤f(z0)f(z)\\leq f(z_0)f(z)≤f(z0​)，则f(z)=f(z0)f(z)=f(z_0)f(z)=f(z0​)。 利用引理2.4.2可证明最大模原理。 定理2.4.10（最大模原理） 设f(z)f(z)f(z)是区域DDD中的解析函数，且不是常数，则∥f(z)∥\\|f(z)\\|∥f(z)∥在DDD中的任意一点不可能达到最大值。 最大模原理也可以叙述成如下形式： 定理2.4.11 设DDD是一个有界区域，f(z)f(z)f(z)是DDD中的解析函数，且在闭区域Dˉ\\bar DDˉ中连续，则∥f(z)∥\\|f(z)\\|∥f(z)∥在边界∂D\\partial D∂D上取得最大值。 第三章 解析函数的级数展开 3.1 复级数 3.1.1 复数项级数 复数项无穷级数： ∑k=1∞zk=z1+z2+⋯+zn+⋯\\sum_{k=1}^{\\infty}z_k=z_1+z_2+\\cdots+z_n+\\cdots k=1∑∞​zk​=z1​+z2​+⋯+zn​+⋯ 若复数项无穷级数部分和数列收敛，则称此级数是收敛的。 定理3.1.1（Cauchy收敛准则） 复级数收敛⇔\\Leftrightarrow⇔ ∀ϵ&gt;0,∃N∈N,∀n≥N,∀p∈N,\\forall \\epsilon&gt;0, \\exists N\\in \\mathbb{N}, \\forall n\\geq N,\\forall p\\in \\mathbb{N},∀ϵ&gt;0,∃N∈N,∀n≥N,∀p∈N, ∑k=n+1n+pzk=∥zn+1+zn+1+⋯+zn+p∥&lt;ϵ\\sum_{k=n+1}^{n+p}z_k=\\|z_{n+1}+z_{n+1}+\\cdots+z_{n+p}\\|&lt;\\epsilon k=n+1∑n+p​zk​=∥zn+1​+zn+1​+⋯+zn+p​∥&lt;ϵ 推论3.1.1 复级数收敛的必要条件：lim⁡n→∞zn=0\\lim_{n\\to \\infty}z_n=0limn→∞​zn​=0。 绝对收敛：模的无穷级数和收敛。 注： 1、由三角不等式可得，复级数绝对收敛的充要条件是，∑k=1nxk\\sum_{k=1}^nx_k∑k=1n​xk​和∑k=1nyk\\sum_{k=1}^ny_k∑k=1n​yk​都绝对收敛； 2、绝对收敛的复级数绝对（必定）收敛。 3.1.2 复变函数项级数 复变函数项级数： ∑k=1∞fk(z)=f1(z)+f2(z)+⋯+fn(z)+⋯\\sum_{k=1}^{\\infty}f_k(z)=f_1(z)+f_2(z)+\\cdots+f_n(z)+\\cdots k=1∑∞​fk​(z)=f1​(z)+f2​(z)+⋯+fn​(z)+⋯ 复变函数项级数在z0z_0z0​收敛： ∑k=1∞fk(z0)=f1(z0)+f2(z0)+⋯+fn(z0)+⋯\\sum_{k=1}^{\\infty}f_k(z_0)=f_1(z_0)+f_2(z_0)+\\cdots+f_n(z_0)+\\cdots k=1∑∞​fk​(z0​)=f1​(z0​)+f2​(z0​)+⋯+fn​(z0​)+⋯ 复变函数项级数在EEE上收敛：复变函数项级数在EEE上每一点都收敛。这时级数和是一个函数，记为f(z)f(z)f(z)，即 ∑k=1∞fk(z)=f(z)\\sum_{k=1}^{\\infty}f_k(z)=f(z) k=1∑∞​fk​(z)=f(z) 称f(z)f(z)f(z)为和函数。 一致收敛：记部分和为 Sn(z)=∑k=1nfk(z)S_n(z)=\\sum_{k=1}^nf_k(z) Sn​(z)=k=1∑n​fk​(z) 若∀ϵ&gt;0\\forall \\epsilon&gt;0∀ϵ&gt;0，∃N=N(ϵ)\\exists N=N(\\epsilon)∃N=N(ϵ)仅与ϵ\\epsilonϵ有关，使得当n≥Nn\\geq Nn≥N时，∀z∈E\\forall z\\in E∀z∈E，都有 ∥Sn(z)−f(z)∥&lt;ϵ\\|S_n(z)-f(z)\\|&lt;\\epsilon ∥Sn​(z)−f(z)∥&lt;ϵ 则称复级数在EEE上一致收敛于f(z)f(z)f(z)。 内闭一致收敛：在EEE内任意一个闭区间上都一致收敛，则称复变函数项级数在EEE上内闭一致收敛。 复变函数项级数一致收敛的两个判定准则： 定理3.1.2（Cauchy一致收敛准则） 复变函数项级数在EEE上一致收敛⇔\\Leftrightarrow⇔∀ϵ&gt;0\\forall \\epsilon&gt;0∀ϵ&gt;0，∃N=N(ϵ)∈N\\exists N=N(\\epsilon) \\in \\mathbb{N}∃N=N(ϵ)∈N仅与ϵ\\epsilonϵ有关，当n≥Nn\\geq Nn≥N时，∀z∈E,p&gt;0\\forall z\\in E, p&gt;0∀z∈E,p&gt;0，都有 ∥∑k=n+1n+pfk(z)∥&lt;ϵ\\|\\sum_{k=n+1}^{n+p}f_k(z)\\|&lt;\\epsilon ∥k=n+1∑n+p​fk​(z)∥&lt;ϵ 定理3.1.3（Weierstrass判别法） 如果∀z∈E\\forall z \\in E∀z∈E，有 ∥fk(z)∥&lt;Mk\\|f_k(z)\\|&lt;M_k ∥fk​(z)∥&lt;Mk​ 且正数项级数∑k=1∞Mk\\sum_{k=1}^{\\infty}M_k∑k=1∞​Mk​收敛，则∑k=1∞fk(z)\\sum_{k=1}^{\\infty} f_k(z)∑k=1∞​fk​(z)在EEE上绝对一致收敛。这时∑k=1∞Mk\\sum_{k=1}^{\\infty}M_k∑k=1∞​Mk​称为∑k=1∞fk(z)\\sum_{k=1}^{\\infty} f_k(z)∑k=1∞​fk​(z)的优级数。 讨论复变函数项级数的性质： 定理3.1.4（极限与求和可交换） 若复变函数项级数在DDD内各项连续且内闭一致收敛，则和函数在DDD内也连续。即 lim⁡z→z0∑k=1∞fk(z)=f(z0)=∑k=1∞fk(z0)=∑k=1∞lim⁡z→z0fk(z)\\lim_{z\\to z_0}\\sum_{k=1}^{\\infty} f_k(z)=f(z_0)=\\sum_{k=1}^{\\infty}f_k(z_0)=\\sum_{k=1}^{\\infty}\\lim_{z\\to z_0}f_k(z) z→z0​lim​k=1∑∞​fk​(z)=f(z0​)=k=1∑∞​fk​(z0​)=k=1∑∞​z→z0​lim​fk​(z) 定理3.1.5（积分与求和可交换） 若复变函数项级数在逐段光滑的曲线CCC上各项连续且一致收敛，则沿CCC可对级数逐项积分。即 ∫Cf(z)dz=∑k=1∞∫Cfk(z)dz\\int_Cf(z)dz=\\sum_{k=1}^{\\infty}\\int_C f_k(z)dz ∫C​f(z)dz=k=1∑∞​∫C​fk​(z)dz 定理3.1.5（求导与求和可交换） 若复变函数项级数在DDD内各项解析且内闭一致收敛，则和函数在DDD内也解析。且可以对级数逐项求导至任意阶，即 f(k)(z)=∑n=1∞fn(k)(z),∀z∈D,k=1,2,⋯f^{(k)}(z)=\\sum_{n=1}^{\\infty}f_n^{(k)}(z),\\forall z\\in D,k=1,2,\\cdots f(k)(z)=n=1∑∞​fn(k)​(z),∀z∈D,k=1,2,⋯ 3.1.3 幂级数 幂级数： ∑n=0∞an(z−z0)n=a0+a1(z−z0)+a2(z−z0)2+⋯\\sum_{n=0}^{\\infty}a_n(z-z_0)^n=a_0+a_1(z-z_0)+a_2(z-z_0)^2+\\cdots n=0∑∞​an​(z−z0​)n=a0​+a1​(z−z0​)+a2​(z−z0​)2+⋯ 研究幂级数的收敛范围。 首先定义 L:=lim⁡sup⁡n→∞∥an∥1n=lim⁡n→∞‾∥an∥1nL:=\\lim\\sup_{n\\to \\infty}\\|a_n\\|^{\\frac{1}{n}}=\\overline{\\lim_{n\\to \\infty}}\\|a_n\\|^{\\frac{1}{n}} L:=limn→∞sup​∥an​∥n1​=n→∞lim​​∥an​∥n1​ 令R=1LR=\\frac{1}{L}R=L1​。 定理3.1.7 设R&gt;0R&gt;0R&gt;0。如果∥z−z0∥&lt;R\\|z-z_0\\|&lt;R∥z−z0​∥&lt;R，则幂级数在点zzz收敛；如果∥z−z0∥&gt;R\\|z-z_0\\|&gt;R∥z−z0​∥&gt;R，则幂级数在点zzz发散。 收敛半径：RRR 收敛圆： {z:∥z−z0∥&lt;R}\\{ z:\\|z-z_0\\|&lt;R\\} {z:∥z−z0​∥&lt;R} 注：在收敛圆边界上，幂级数可能收敛也可能发散。 定理3.1.8 幂级数在其收敛圆中内闭一致收敛。 定理3.1.9 幂级数(R&gt;0)(R&gt;0)(R&gt;0)的和函数在其收敛圆内解析，并可逐项求导。特别地， f(k)(z0)=k!ak,k=1,2,⋯f^{(k)}(z_0)=k!a_k,k=1,2,\\cdots f(k)(z0​)=k!ak​,k=1,2,⋯ 3.2 解析函数的Taylor级数展开 定理3.2.1 设f(z)f(z)f(z)在圆盘U={z:∥z−z0∥&lt;R}U=\\{z:\\|z-z_0\\|&lt;R\\}U={z:∥z−z0​∥&lt;R}可展开成幂级数 f(z)=∑n=0∞an(z−z0)nf(z)=\\sum_{n=0}^{\\infty}a_n(z-z_0)^n f(z)=n=0∑∞​an​(z−z0​)n 其中， an=f(n)(z0)n!a_n=\\frac{f^{(n)}(z_0)}{n!} an​=n!f(n)(z0​)​ 即，解析函数在其定义域内的任一点都可以展开成关于zzz的幂级数，展开式称为Taylor展开。 解析函数的Taylor展开式是唯一的。因此用任何方法求得的幂级数展开式必为Taylor展开式。 定理3.1.9与3.2.1共同给出了解析函数的一个充要条件： 定理3.2.2 f(z)f(z)f(z)在区域DDD中解析⇔\\Leftrightarrow⇔∀z0∈D\\forall z_0 \\in D∀z0​∈D，f(z)f(z)f(z)可以在z0z_0z0​的一个邻域内展开成幂级数。 总结：解析函数的充要条件： 定义：如果f(z)f(z)f(z)在z0z_0z0​的某个邻域内逐点可导，则称f(z)f(z)f(z)在点z0z_0z0​是解析的； 共轭调和：f(z)=u+ivf(z)=u+ivf(z)=u+iv在区域DDD中解析⇔\\Leftrightarrow⇔uuu是vvv的共轭调和函数； 积分为零：设f(z)f(z)f(z)在单连通区域DDD内连续，则f(z)f(z)f(z)在DDD内解析⇔\\Leftrightarrow⇔对DDD内任意一条逐段光滑的简单闭曲线，都有$$\\int_C f(z)dz=0$$ 幂级数展开：f(z)f(z)f(z)在区域DDD中解析⇔\\Leftrightarrow⇔∀z0∈D\\forall z_0 \\in D∀z0​∈D，f(z)f(z)f(z)可以在z0z_0z0​的一个邻域内展开成幂级数。 3.2.1 解析函数零点的孤立性 mmm阶零点：f(z0)=f′(z0)=f′′(z0)=⋯=f(m−1)(z0)=0f(z_0)=f&#x27;(z_0)=f&#x27;&#x27;(z_0)=\\cdots=f^{(m-1)}(z_0)=0f(z0​)=f′(z0​)=f′′(z0​)=⋯=f(m−1)(z0​)=0，但f(m)(z0)≠0f^{(m)}(z_0)\\neq 0f(m)(z0​)​=0，则称z0z_0z0​为f(z)f(z)f(z)的一个mmm阶零点。 定理3.2.3 设f(z)f(z)f(z)在z0z_0z0​点解析且不为零，则z0z_0z0​是f(z)f(z)f(z)的mmm阶零点⇔\\Leftrightarrow⇔在z0z_0z0​的某个邻域内有 f(z)=(z−z0)g(z),g(z)≠0.∀z∈Uf(z)=(z-z_0)g(z),g(z)\\neq 0.\\forall z\\in U f(z)=(z−z0​)g(z),g(z)​=0.∀z∈U 由此，存在z0z_0z0​的某个邻域，在此邻域中，z0z_0z0​是f(z)f(z)f(z)的唯一零点。这是解析函数特有的性质，零点孤立性定理： 定理3.2.4（零点孤立性定理） 设f(z)f(z)f(z)在点z0z_0z0​解析，且z0z_0z0​是f(z)f(z)f(z)的一个零点。如果f(z)f(z)f(z)在z0z_0z0​的领域内不恒为零，则存在z0z_0z0​的一个邻域UUU，在UUU中z0z_0z0​是f(z)f(z)f(z)的唯一零点。 引理3.2.1 设f(z)f(z)f(z)在区域DDD内解析，且z0∈Dz_0\\in Dz0​∈D。如果f(z)f(z)f(z)在z0z_0z0​的某个邻域Uδ(z0)U_{\\delta}(z_0)Uδ​(z0​)内恒为零，则它在整个区域DDD内恒为零。 利用零点孤立性定理和引理3.2.1，可以得到解析函数的唯一性定理： 定理3.2.5（解析函数的唯一性定理） 设f(z)f(z)f(z)与g(z)g(z)g(z)是区域DDD中的解析函数，且存在DDD中互不相同的无穷序列z1,z2,⋯ ,zn,⋯z_1,z_2,\\cdots,z_n,\\cdotsz1​,z2​,⋯,zn​,⋯使得f(zn)=g(zn),n=1,2,⋯f(z_n)=g(z_n),n=1,2,\\cdotsf(zn​)=g(zn​),n=1,2,⋯，若该序列有极限，即lim⁡n→∞zn=a\\lim_{n\\to \\infty}z_n=alimn→∞​zn​=a，则 f(z)≡g(z),∀z∈Df(z)\\equiv g(z),\\forall z \\in D f(z)≡g(z),∀z∈D 3.3 解析函数的Laurent级数展开 定理3.3.1（Laurent定理） 设f(z)f(z)f(z)在圆环域{z:r1&lt;z−z0&lt;r2}\\{z:r_1&lt;{z-z_0}&lt;r_2\\}{z:r1​&lt;z−z0​&lt;r2​}中解析(r1≥0,r2≤+∞)(r_1\\geq 0,r_2\\leq +\\infty )(r1​≥0,r2​≤+∞)，则有幂级数展开式 f(z)=∑n=0∞an(z−z0)n+∑n=1∞bn(z−z0)nf(z)=\\sum_{n=0}^{\\infty}a_n(z-z_0)^n+\\sum_{n=1}^{\\infty}\\frac{b_n}{(z-z_0)^n} f(z)=n=0∑∞​an​(z−z0​)n+n=1∑∞​(z−z0​)nbn​​ 其中， an=12πi∫Cρf(ζ)(ζ−z0)n+1dζa_n=\\frac{1}{2\\pi i}\\int_{C_{\\rho}}\\frac{f(\\zeta)}{(\\zeta-z_0)^{n+1}}d\\zeta an​=2πi1​∫Cρ​​(ζ−z0​)n+1f(ζ)​dζ bn=12πi∫Cρf(ζ)(ζ−z0)−n+1dζb_n=\\frac{1}{2\\pi i}\\int_{C_{\\rho}}\\frac{f(\\zeta)}{(\\zeta-z_0)^{-n+1}}d\\zeta bn​=2πi1​∫Cρ​​(ζ−z0​)−n+1f(ζ)​dζ UρU_{\\rho}Uρ​表示z0z_0z0​周围半径为ρ\\rhoρ的圆盘，其中r1&lt;ρ&lt;r2r_1&lt;\\rho&lt;r_2r1​&lt;ρ&lt;r2​。 注：Laurent级数亦可表达为下述形式： f(z)=∑n=−∞+∞cn(z−z0)nf(z)=\\sum_{n=-\\infty}^{+\\infty}c_n(z-z_0)^n f(z)=n=−∞∑+∞​cn​(z−z0​)n 其中 cn=12πi∫Cρf(ζ)(ζ−z0)n+1,n=0,±1,±2,⋯c_n=\\frac{1}{2\\pi i}\\int_{C_\\rho}\\frac{f(\\zeta)}{(\\zeta-z_0)^{n+1}},n=0,\\pm 1,\\pm 2,\\cdots cn​=2πi1​∫Cρ​​(ζ−z0​)n+1f(ζ)​,n=0,±1,±2,⋯ 定理3.3.2（Laurent级数的唯一性） 设f(z)f(z)f(z)在圆环域{z:r1&lt;z−z0&lt;r2}\\{z:r_1&lt;{z-z_0}&lt;r_2\\}{z:r1​&lt;z−z0​&lt;r2​}中解析。如果f(z)f(z)f(z)在UUU中有一个展开式 f(z)=∑n=−∞+∞dn(z−z0)nf(z)=\\sum_{n=-\\infty}^{+\\infty}d_n(z-z_0)^n f(z)=n=−∞∑+∞​dn​(z−z0​)n 则该展开式必为Laurent展开式，即dn=cn,n=0,±1,±2,⋯d_n=c_n,n=0,\\pm 1, \\pm 2,\\cdotsdn​=cn​,n=0,±1,±2,⋯ 第四章 留数定理及其应用 4.1 留数的概念 孤立奇点：若f(z)f(z)f(z)在z0z_0z0​附近但除去z0z_0z0​之外解析，则称z0z_0z0​为f(z)f(z)f(z)的孤立奇点。 留数：Laurent展开式中1z−z0\\frac{1}{z-z_0}z−z0​1​的系数b1b_1b1​称为f(z)f(z)f(z)在孤立奇点z0z_0z0​的留数，简称f(z)f(z)f(z)在z0z_0z0​的留数，记作Res(f;z0)Res(f;z_0)Res(f;z0​)。 留数可以用来计算曲线积分。如果能通过不计算f(z)f(z)f(z)的曲线积分的方式求得b1b_1b1​，我们就可以计算出： ∫Cf(z)dz=2πib1\\int_C f(z)dz=2\\pi ib_1 ∫C​f(z)dz=2πib1​ 4.2 留数定理 定理4.2.1（Cauchy留数定理） 设f(z)f(z)f(z)在单连通区域DDD中仅有有限个孤立奇点z1,z2,⋯ ,znz_1,z_2,\\cdots,z_nz1​,z2​,⋯,zn​，CCC是DDD中的一条逐段光滑的简单闭曲线。则 ∫Cf(z)dz=2πi∑k=1nRes(f;zk)\\int_C f(z)dz=2\\pi i\\sum_{k=1}^nRes(f;z_k) ∫C​f(z)dz=2πik=1∑n​Res(f;zk​) 4.3 留数的求法 主要部分（主部）：Laurent展开中 ψ(z)=∑n=1∞bn(z−z0)n\\psi(z)=\\sum_{n=1}^{\\infty}\\frac{b_n}{(z-z_0)^n} ψ(z)=n=1∑∞​(z−z0​)nbn​​ 这一部分级数被称为f(z)f(z)f(z)在孤立奇点z0z_0z0​的Laurent展开的主要部分，简称主部。 奇点的分类： mmm阶极点：主部系数仅有有限个不为零，即∃m,s.t.bm≠0,bm+1=bm+2=⋯=0\\exists m,s.t. b_m\\neq 0,b_{m+1}=b_{m+2}=\\cdots=0∃m,s.t.bm​​=0,bm+1​=bm+2​=⋯=0，则称z0z_0z0​为f(z)f(z)f(z)的一个mmm阶极点。 简单极点（单极点）：111阶极点。 本质奇点：bnb_nbn​中有无穷多个不为零。 可去奇点：bnb_nbn​全为零。这是若补充定义f(z0)=a0f(z_0)=a_0f(z0​)=a0​，则f(z)f(z)f(z)在点z0z_0z0​解析，Laurent级数变为Taylor级数。 我们下面给出计算留数的方法。分为两步：1、判断极点z0z_0z0​的阶数；2、根据阶数计算留数。 定义 ϕ(z)=(z−z0)mf(z)\\phi(z)=(z-z_0)^mf(z) ϕ(z)=(z−z0​)mf(z) 定理4.3.1 z0z_0z0​是f(z)f(z)f(z)的mmm阶极点⇔\\Leftrightarrow⇔ lim⁡z→z0ϕ(z)=A≠0\\lim_{z\\to z_0}\\phi(z)=A\\neq 0 z→z0​lim​ϕ(z)=A​=0 此时A=bmA=b_mA=bm​。 定理4.3.2 设z0z_0z0​是f(z)f(z)f(z)的mmm阶极点。则 Res(f;z0)=1(m−1)!ϕ(m−1)(z0)Res(f;z_0)=\\frac{1}{(m-1)!}\\phi^{(m-1)}(z_0) Res(f;z0​)=(m−1)!1​ϕ(m−1)(z0​) 特别地，当m=1m=1m=1时，有 Res(f;z0)=lim⁡z→z0(z−z0)f(z)=ϕ(z0)Res(f;z_0)=\\lim_{z\\to z_0}(z-z_0)f(z)=\\phi(z_0) Res(f;z0​)=z→z0​lim​(z−z0​)f(z)=ϕ(z0​) 注：定理4.3.1要求ϕ(z0)≠0\\phi(z_0) \\neq 0ϕ(z0​)​=0，因此不能盲目套用上述方法。可以考察函数f(z)=sinh⁡(z)z4f(z)=\\frac{\\sinh(z)}{z^4}f(z)=z4sinh(z)​，z0=0z_0=0z0​=0是它的333阶极点，Res(f;0)=16Res(f;0)=\\frac{1}{6}Res(f;0)=61​。 定理4.3.3 设p(z0)p(z_0)p(z0​)和f(z0)f(z_0)f(z0​)都在z0z_0z0​处解析，且p(z0)≠0p(z_0)\\neq 0p(z0​)​=0，则z0z_0z0​是p(z)/f(z)p(z)/f(z)p(z)/f(z)的mmm阶极点⇔\\Leftrightarrow⇔z0z_0z0​是f(z)f(z)f(z)的mmm阶零点。 定理4.3.4 设p(z0)p(z_0)p(z0​)和f(z0)f(z_0)f(z0​)都在z0z_0z0​处解析，且p(z0)≠0p(z_0)\\neq 0p(z0​)​=0。若f(z0)=0f(z_0)=0f(z0​)=0且f′(z0)≠0f&#x27;(z_0)\\neq 0f′(z0​)​=0，则z0z_0z0​是p(z)/f(z)p(z)/f(z)p(z)/f(z)的一个单极点，且其留数为p(z0)/f′(z0)p(z_0)/f&#x27;(z_0)p(z0​)/f′(z0​)。 4.4 留数定理的应用 4.4.1 反常积分 Cauchy主值： P.V.∫−∞+∞f(x)dx=lim⁡R→∞∫−RRf(x)dxP.V.\\int_{-\\infty}^{+\\infty}f(x)dx=\\lim_{R\\to \\infty}\\int_{-R}^Rf(x)dx P.V.∫−∞+∞​f(x)dx=R→∞lim​∫−RR​f(x)dx 注：可能有Cauchy主值本身存在但反常积分不存在的情况，如对某些奇函数的积分。 用留数定理计算实变函数反常积分大致步骤： 1、将实变函数f(x)f(x)f(x)延拓为复变函数f(z)f(z)f(z)，直接替换即可； 2、画积分围道（通常为含奇点的上半半圆），将积分∫Cf(z)dz\\int_Cf(z)dz∫C​f(z)dz拆成对半圆的积分∫CRf(z)dz\\int_{C_R}f(z)dz∫CR​​f(z)dz和沿x轴的积分∫−RRf(x)dx\\int_{-R}^Rf(x)dx∫−RR​f(x)dx； 3、用留数定理计算曲线积分∫Cf(z)dz\\int_Cf(z)dz∫C​f(z)dz； 4、用三角不等式和ML定理放缩证明lim⁡R→∞∫CRf(z)dz=0\\lim_{R\\to \\infty}\\int_{C_R}f(z)dz=0limR→∞​∫CR​​f(z)dz=0； 5、因此，当R→∞R\\to \\inftyR→∞时，∫−∞+∞(x)dx=∫Cf(z)dz\\int_{-\\infty}^{+\\infty}(x)dx=\\int_Cf(z)dz∫−∞+∞​(x)dx=∫C​f(z)dz。 4.4.2 三角函数积分 若要计算 ∫02πF(sin⁡θ,cos⁡θ)dθ\\int_0^{2\\pi}F(\\sin \\theta,\\cos \\theta)d\\theta ∫02π​F(sinθ,cosθ)dθ 可以做变量代换 z=eiθz=e^{i\\theta} z=eiθ 这样，原积分就变成了一个复变函数沿单位圆周CCC的曲线积分 ∫CF(z−z−12i,z+z−12)dziz\\int_C F(\\frac{z-z^{-1}}{2i},\\frac{z+z^{-1}}{2})\\frac{dz}{iz} ∫C​F(2iz−z−1​,2z+z−1​)izdz​ 然后可以用留数定理计算该复变函数曲线积分。 4.4.3 Jordan引理 若要计算下述形式的收敛的反常积分 ∫−∞+∞f(x)sin⁡(ax)dx,∫−∞+∞f(x)cos⁡(ax)dx\\int_{-\\infty}^{+\\infty}f(x)\\sin(ax)dx,\\int_{-\\infty}^{+\\infty}f(x)\\cos(ax)dx ∫−∞+∞​f(x)sin(ax)dx,∫−∞+∞​f(x)cos(ax)dx 注意到 Re∫−RRf(x)eiaxdx=∫−∞+∞f(x)cos⁡(ax)dxRe\\int_{-R}^R f(x)e^{iax}dx=\\int_{-\\infty}^{+\\infty}f(x)\\cos(ax)dx Re∫−RR​f(x)eiaxdx=∫−∞+∞​f(x)cos(ax)dx Im∫−RRf(x)eiaxdx=∫−∞+∞f(x)sin⁡(ax)dxIm\\int_{-R}^R f(x)e^{iax}dx=\\int_{-\\infty}^{+\\infty}f(x)\\sin(ax)dx Im∫−RR​f(x)eiaxdx=∫−∞+∞​f(x)sin(ax)dx 可以用这种方式得到f(z)f(z)f(z)，然后利用4.4.1节所述方法，取积分围道计算。 这里给出一个比ML定理更精细的放缩： Jordan引理 如果在上半圆周CRC_RCR​上有∥f(z)∥≤M\\|f(z)\\|\\leq M∥f(z)∥≤M且β&gt;0\\beta&gt;0β&gt;0，则 ∫CRf(z)eiβzdz&lt;Mπβ\\int_{C_R}f(z)e^{i\\beta z}dz&lt;\\frac{M\\pi}{\\beta} ∫CR​​f(z)eiβzdz&lt;βMπ​ ","link":"https://kimokcheon.github.io/post/fu-bian-han-shu/"},{"title":"Vim使用与调教过程","content":"背景 我对Vim并不陌生，也用Vim写过代码，但也只是靠i和:wq来做一些小的事情，比如写写commit message之类。如果能用vscode我还是用vscode的。我的确被别人安利过Vim，听过很多人说Vim熟练了会大大提升效率，它只用键盘。然而我还是望而却步：要学的东西太多了啊，这么多快捷键，很难在短时间内达到熟练。而且我觉得vscode已经很方便了，为啥要用Vim？ 那我为什么又要用Vim呢？还是因为两天前我抱着电脑在床上瞎看东西，突然触摸板失灵了。我又懒得去拿鼠标，就只能用键盘了。结果是，在浏览器里点链接要狂按Tab键，使用体验极差。这时我突然想起来，以前看过视频，有一个浏览器插件，安装之后就能像Vim一样用键盘浏览网页，也有hjkl移动等等类似Vim的功能。 狂按Tab键之后终于找到并且下载了这个插件，叫做Vimium。简单熟悉了一下主要功能，还不错。于是我又顺路去学了学Vim，并且简单地配置了一下。 Vim学习与配置 学习Vim：使用vimtutor Vim自带教程。在终端输入vimtutor并按回车键即可打开。 vimtutor看起来不短，但实际上是因为它编写的很详细。所以大约半小时就可以把整个教程过一遍。 看一遍基本能记住七成，隔一天再看一遍就记得差不多了。重点是多写点小程序什么的自己练手，教程上也说了，不要去记对应规则，而是通过写东西来练手、掌握。 配置Vim：颜色主题与插件 主题配色：onedark 听取了同学的建议，使用了onedark配色，GitHub链接：https://github.com/joshdick/onedark.vim。按照README文件的说明进行安装即可，装完感觉还是挺不错的。 这位同学还使用了treesitter高亮，之后再说罢，现在已经不赖了。 终端界面：ohmyzsh - agnoster 采用ohmyzsh的agnoster样式（按照官方文件的说法这应该是最花哨的样式了hhhh，不过真觉得挺好看的，我觉得也不花哨，还是足够简洁的）。 ohmyzsh的GitHub链接：https://github.com/ohmyzsh/ohmyzsh。按照README文件的说明来安装即可。 另外，注意要先安装zsh才能安装ohmyzsh，另外千万不要一时兴起直接用sudo apt remove把zsh卸载了，否则就打不开ubuntu终端了（血泪教训QAQ）。因为这样的文件会修改终端的配置，如果手滑修改了，要去找到/etc目录下的passwd（应该是叫这个）文件，把含有zsh的那一行中的zsh改成bash。 另外我还做了个小动作：让终端只显示相对路径，终端命令之前的“前摇”就简洁了很多了。 如果采用agnoster，要实现如上的效果，就得修改agnoster主题的配置文件，可参考教程：https://www.cnblogs.com/goldsunshine/p/9567613.html。 另外，要去掉主机名，即从原来的“用户名@主机名”变为仅显示用户名或者用户名也不显示，可以找到函数prompt_context()所在行（我的是从89行开始），if和fi中间那一行最后有个%n@%m，%n指代的是用户名，%m指代的是主机名，按照需求修改即可。 插件管理器：Vundle 我使用Vundle来管理插件，这里有一篇不错的Vundle安装和使用教程：https://cloud.tencent.com/developer/article/1669204。 自动补全插件：YouCompleteMe 我的Vim起初是裸奔的（谁的不是呢），然后因为没有自动补全提示很难受……于是一通google，发现大家还挺推荐YouCompleteMe（GitHub链接：https://github.com/ycm-core/YouCompleteMe）这个插件的，还有人直接说是Vim必备的几大神器之一。要用Vundle来安装，于是Vundle就顺理成章地成为我的插件管理器了。 另外，安装完YouCompleteMe之后，还要把设置文件（路径：~/.vimrc）再修改一下，在call vundle#begin()和call vundle#end()之间加入下面的语句，这样会有更好的体验： let g:ycm_show_diagnostics_ui = 0 let g:ycm_server_log_level = 'info' let g:ycm_min_num_identifier_candidate_chars = 2 let g:ycm_collect_identifiers_from_comments_and_strings = 1 let g:ycm_complete_in_strings=1 let g:ycm_key_invoke_completion = '&lt;c-z&gt;' noremap &lt;c-z&gt; &lt;NOP&gt; let g:ycm_semantic_triggers = { \\ 'c,cpp,python,java,go,erlang,perl': ['re!\\w{2}'], \\ 'cs,lua,javascript': ['re!\\w{2}'], \\ } 这个YouCompleteMe配置过程中还有可能遇到各种各样的问题，上网查或者自己看配置文件猜解决方法也能搞定。配置好之后使用体验也还是可以的（虽然我没感觉像传的那么神）。 “彩虹括号”插件：Rainbow Parenthesis Improved 后来我又通过Vundle安装了“彩虹括号”（Rainbow Parenthesis Improved，GitHub链接：https://github.com/luochen1990/rainbow）。这样一来看括号就舒服多了。 Vimium：浏览器仿Vim插件 我主用浏览器是chrome，在chrome应用商店可以找到Vimium，链接：https://chrome.google.com/webstore/detail/vimium/dbepggeogbaibhgnhhndojpepiihcmeb?hl=zh-CN。 可以按?键（即shift + /）调出使用说明。到该插件的GitHub仓库下查看README文件也有使用介绍：https://github.com/philc/vimium。 使用熟练之后还挺舒服的，尤其是靠在床上看电脑的时候。不过也有局限性，尤其是在看B站的时候。对我来说还是不能完全替代鼠标的，不过大多数场景下可以不用鼠标自由浏览，熟练之后切换标签页还是挺快的。 ","link":"https://kimokcheon.github.io/post/vim-shi-yong-yu-diao-jiao-guo-cheng/"},{"title":"CPP20","content":"Overview C++20 includes the following new language features: coroutines concepts designated initializers template syntax for lambdas range-based for loop with initializer [[likely]] and [[unlikely]] attributes deprecate implicit capture of this class types in non-type template parameters constexpr virtual functions explicit(bool) immediate functions using enum lambda capture of parameter pack char8_t constinit C++20 includes the following new library features: concepts library synchronized buffered outputstream std::span bit operations math constants std::is_constant_evaluated std::make_shared supports arrays starts_with and ends_with on strings check if associative container has element std::bit_cast std::midpoint std::to_array C++20 Language Features Coroutines Coroutines are special functions that can have their execution suspended and resumed. To define a coroutine, the co_return, co_await, or co_yield keywords must be present in the function's body. C++20's coroutines are stackless; unless optimized out by the compiler, their state is allocated on the heap. An example of a coroutine is a generator function, which yields (i.e. generates) a value at each invocation: generator&lt;int&gt; range(int start, int end) { while (start &lt; end) { co_yield start; start++; } // Implicit co_return at the end of this function: // co_return; } for (int n : range(0, 10)) { std::cout &lt;&lt; n &lt;&lt; std::endl; } The above range generator function generates values starting at start until end (exclusive), with each iteration step yielding the current value stored in start. The generator maintains its state across each invocation of range (in this case, the invocation is for each iteration in the for loop). co_yield takes the given expression, yields (i.e. returns) its value, and suspends the coroutine at that point. Upon resuming, execution continues after the co_yield. Another example of a coroutine is a task, which is an asynchronous computation that is executed when the task is awaited: task&lt;void&gt; echo(socket s) { for (;;) { auto data = co_await s.async_read(); co_await async_write(s, data); } // Implicit co_return at the end of this function: // co_return; } In this example, the co_await keyword is introduced. This keyword takes an expression and suspends execution if the thing you're awaiting on (in this case, the read or write) is not ready, otherwise you continue execution. (Note that under the hood, co_yield uses co_await.) Using a task to lazily evaluate a value: task&lt;int&gt; calculate_meaning_of_life() { co_return 42; } auto meaning_of_life = calculate_meaning_of_life(); // ... co_await meaning_of_life; // == 42 Note: While these examples illustrate how to use coroutines at a basic level, there is lots more going on when the code is compiled. These examples are not meant to be complete coverage of C++20's coroutines. Since the generator and task classes are not provided by the standard library yet, I used the cppcoro library to compile these examples. Concepts Concepts are named compile-time predicates which constrain types. They take the following form: template &lt; template-parameter-list &gt; concept concept-name = constraint-expression; where constraint-expression evaluates to a constexpr Boolean. Constraints should model semantic requirements, such as whether a type is a numeric or hashable. A compiler error results if a given type does not satisfy the concept it's bound by (i.e. constraint-expression returns false). Because constraints are evaluated at compile-time, they can provide more meaningful error messages and runtime safety. // `T` is not limited by any constraints. template &lt;typename T&gt; concept always_satisfied = true; // Limit `T` to integrals. template &lt;typename T&gt; concept integral = std::is_integral_v&lt;T&gt;; // Limit `T` to both the `integral` constraint and signedness. template &lt;typename T&gt; concept signed_integral = integral&lt;T&gt; &amp;&amp; std::is_signed_v&lt;T&gt;; // Limit `T` to both the `integral` constraint and the negation of the `signed_integral` constraint. template &lt;typename T&gt; concept unsigned_integral = integral&lt;T&gt; &amp;&amp; !signed_integral&lt;T&gt;; There are a variety of syntactic forms for enforcing concepts: // Forms for function parameters: // `T` is a constrained type template parameter. template &lt;my_concept T&gt; void f(T v); // `T` is a constrained type template parameter. template &lt;typename T&gt; requires my_concept&lt;T&gt; void f(T v); // `T` is a constrained type template parameter. template &lt;typename T&gt; void f(T v) requires my_concept&lt;T&gt;; // `v` is a constrained deduced parameter. void f(my_concept auto v); // `v` is a constrained non-type template parameter. template &lt;my_concept auto v&gt; void g(); // Forms for auto-deduced variables: // `foo` is a constrained auto-deduced value. my_concept auto foo = ...; // Forms for lambdas: // `T` is a constrained type template parameter. auto f = []&lt;my_concept T&gt; (T v) { // ... }; // `T` is a constrained type template parameter. auto f = []&lt;typename T&gt; requires my_concept&lt;T&gt; (T v) { // ... }; // `T` is a constrained type template parameter. auto f = []&lt;typename T&gt; (T v) requires my_concept&lt;T&gt; { // ... }; // `v` is a constrained deduced parameter. auto f = [](my_concept auto v) { // ... }; // `v` is a constrained non-type template parameter. auto g = []&lt;my_concept auto v&gt; () { // ... }; The requires keyword is used either to start a requires clause or a requires expression: template &lt;typename T&gt; requires my_concept&lt;T&gt; // `requires` clause. void f(T); template &lt;typename T&gt; concept callable = requires (T f) { f(); }; // `requires` expression. template &lt;typename T&gt; requires requires (T x) { x + x; } // `requires` clause and expression on same line. T add(T a, T b) { return a + b; } Note that the parameter list in a requires expression is optional. Each requirement in a requires expression are one of the following: Simple requirements - asserts that the given expression is valid. template &lt;typename T&gt; concept callable = requires (T f) { f(); }; Type requirements - denoted by the typename keyword followed by a type name, asserts that the given type name is valid. struct foo { int foo; }; struct bar { using value = int; value data; }; struct baz { using value = int; value data; }; // Using SFINAE, enable if `T` is a `baz`. template &lt;typename T, typename = std::enable_if_t&lt;std::is_same_v&lt;T, baz&gt;&gt;&gt; struct S {}; template &lt;typename T&gt; using Ref = T&amp;; template &lt;typename T&gt; concept C = requires { // Requirements on type `T`: typename T::value; // A) has an inner member named `value` typename S&lt;T&gt;; // B) must have a valid class template specialization for `S` typename Ref&lt;T&gt;; // C) must be a valid alias template substitution }; template &lt;C T&gt; void g(T a); g(foo{}); // ERROR: Fails requirement A. g(bar{}); // ERROR: Fails requirement B. g(baz{}); // PASS. Compound requirements - an expression in braces followed by a trailing return type or type constraint. template &lt;typename T&gt; concept C = requires(T x) { {*x} -&gt; std::convertible_to&lt;typename T::inner&gt;; // the type of the expression `*x` is convertible to `T::inner` {x + 1} -&gt; std::same_as&lt;int&gt;; // the expression `x + 1` satisfies `std::same_as&lt;decltype((x + 1))&gt;` {x * 1} -&gt; std::convertible_to&lt;T&gt;; // the type of the expression `x * 1` is convertible to `T` }; Nested requirements - denoted by the requires keyword, specify additional constraints (such as those on local parameter arguments). template &lt;typename T&gt; concept C = requires(T x) { requires std::same_as&lt;sizeof(x), size_t&gt;; }; See also: concepts library. Designated initializers C-style designated initializer syntax. Any member fields that are not explicitly listed in the designated initializer list are default-initialized. struct A { int x; int y; int z = 123; }; A a {.x = 1, .z = 2}; // a.x == 1, a.y == 0, a.z == 2 Template syntax for lambdas Use familiar template syntax in lambda expressions. auto f = []&lt;typename T&gt;(std::vector&lt;T&gt; v) { // ... }; Range-based for loop with initializer This feature simplifies common code patterns, helps keep scopes tight, and offers an elegant solution to a common lifetime problem. for (auto v = std::vector{1, 2, 3}; auto&amp; e : v) { std::cout &lt;&lt; e; } // prints &quot;123&quot; [[likely]] and [[unlikely]] attributes Provides a hint to the optimizer that the labelled statement has a high probability of being executed. switch (n) { case 1: // ... break; [[likely]] case 2: // n == 2 is considered to be arbitrarily more // ... // likely than any other value of n break; } If one of the likely/unlikely attributes appears after the right parenthesis of an if-statement, it indicates that the branch is likely/unlikely to have its substatement (body) executed. int random = get_random_number_between_x_and_y(0, 3); if (random &gt; 0) [[likely]] { // body of if statement // ... } It can also be applied to the substatement (body) of an iteration statement. while (unlikely_truthy_condition) [[unlikely]] { // body of while statement // ... } Deprecate implicit capture of this Implicitly capturing this in a lambda capture using [=] is now deprecated; prefer capturing explicitly using [=, this] or [=, *this]. struct int_value { int n = 0; auto getter_fn() { // BAD: // return [=]() { return n; }; // GOOD: return [=, *this]() { return n; }; } }; Class types in non-type template parameters Classes can now be used in non-type template parameters. Objects passed in as template arguments have the type const T, where T is the type of the object, and has static storage duration. struct foo { foo() = default; constexpr foo(int) {} }; template &lt;foo f&gt; auto get_foo() { return f; } get_foo(); // uses implicit constructor get_foo&lt;foo{123}&gt;(); constexpr virtual functions Virtual functions can now be constexpr and evaluated at compile-time. constexpr virtual functions can override non-constexpr virtual functions and vice-versa. struct X1 { virtual int f() const = 0; }; struct X2: public X1 { constexpr virtual int f() const { return 2; } }; struct X3: public X2 { virtual int f() const { return 3; } }; struct X4: public X3 { constexpr virtual int f() const { return 4; } }; constexpr X4 x4; x4.f(); // == 4 explicit(bool) Conditionally select at compile-time whether a constructor is made explicit or not. explicit(true) is the same as specifying explicit. struct foo { // Specify non-integral types (strings, floats, etc.) require explicit construction. template &lt;typename T&gt; explicit(!std::is_integral_v&lt;T&gt;) foo(T) {} }; foo a = 123; // OK foo b = &quot;123&quot;; // ERROR: explicit constructor is not a candidate (explicit specifier evaluates to true) foo c {&quot;123&quot;}; // OK Immediate functions Similar to constexpr functions, but functions with a consteval specifier must produce a constant. These are called immediate functions. consteval int sqr(int n) { return n * n; } constexpr int r = sqr(100); // OK int x = 100; int r2 = sqr(x); // ERROR: the value of 'x' is not usable in a constant expression // OK if `sqr` were a `constexpr` function using enum Bring an enum's members into scope to improve readability. Before: enum class rgba_color_channel { red, green, blue, alpha }; std::string_view to_string(rgba_color_channel channel) { switch (channel) { case rgba_color_channel::red: return &quot;red&quot;; case rgba_color_channel::green: return &quot;green&quot;; case rgba_color_channel::blue: return &quot;blue&quot;; case rgba_color_channel::alpha: return &quot;alpha&quot;; } } After: enum class rgba_color_channel { red, green, blue, alpha }; std::string_view to_string(rgba_color_channel my_channel) { switch (my_channel) { using enum rgba_color_channel; case red: return &quot;red&quot;; case green: return &quot;green&quot;; case blue: return &quot;blue&quot;; case alpha: return &quot;alpha&quot;; } } Lambda capture of parameter pack Capture parameter packs by value: template &lt;typename... Args&gt; auto f(Args&amp;&amp;... args){ // BY VALUE: return [...args = std::forward&lt;Args&gt;(args)] { // ... }; } Capture parameter packs by reference: template &lt;typename... Args&gt; auto f(Args&amp;&amp;... args){ // BY REFERENCE: return [&amp;...args = std::forward&lt;Args&gt;(args)] { // ... }; } char8_t Provides a standard type for representing UTF-8 strings. char8_t utf8_str[] = u8&quot;\\u0123&quot;; constinit The constinit specifier requires that a variable must be initialized at compile-time. const char* g() { return &quot;dynamic initialization&quot;; } constexpr const char* f(bool p) { return p ? &quot;constant initializer&quot; : g(); } constinit const char* c = f(true); // OK constinit const char* d = f(false); // ERROR: `g` is not constexpr, so `d` cannot be evaluated at compile-time. C++20 Library Features Concepts library Concepts are also provided by the standard library for building more complicated concepts. Some of these include: Core language concepts: same_as - specifies two types are the same. derived_from - specifies that a type is derived from another type. convertible_to - specifies that a type is implicitly convertible to another type. common_with - specifies that two types share a common type. integral - specifies that a type is an integral type. default_constructible - specifies that an object of a type can be default-constructed. Comparison concepts: boolean - specifies that a type can be used in Boolean contexts. equality_comparable - specifies that operator== is an equivalence relation. Object concepts: movable - specifies that an object of a type can be moved and swapped. copyable - specifies that an object of a type can be copied, moved, and swapped. semiregular - specifies that an object of a type can be copied, moved, swapped, and default constructed. regular - specifies that a type is regular, that is, it is both semiregular and equality_comparable. Callable concepts: invocable - specifies that a callable type can be invoked with a given set of argument types. predicate - specifies that a callable type is a Boolean predicate. See also: concepts. Synchronized buffered outputstream Buffers output operations for the wrapped output stream ensuring synchronization (i.e. no interleaving of output). std::osyncstream{std::cout} &lt;&lt; &quot;The value of x is:&quot; &lt;&lt; x &lt;&lt; std::endl; std::span A span is a view (i.e. non-owning) of a container providing bounds-checked access to a contiguous group of elements. Since views do not own their elements they are cheap to construct and copy -- a simplified way to think about views is they are holding references to their data. As opposed to maintaining a pointer/iterator and length field, a span wraps both of those up in a single object. Spans can be dynamically-sized or fixed-sized (known as their extent). Fixed-sized spans benefit from bounds-checking. Span doesn't propogate const so to construct a read-only span use std::span&lt;const T&gt;. Example: using a dynamically-sized span to print integers from various containers. void print_ints(std::span&lt;const int&gt; ints) { for (const auto n : ints) { std::cout &lt;&lt; n &lt;&lt; std::endl; } } print_ints(std::vector{ 1, 2, 3 }); print_ints(std::array&lt;int, 5&gt;{ 1, 2, 3, 4, 5 }); int a[10] = { 0 }; print_ints(a); // etc. Example: a statically-sized span will fail to compile for containers that don't match the extent of the span. void print_three_ints(std::span&lt;const int, 3&gt; ints) { for (const auto n : ints) { std::cout &lt;&lt; n &lt;&lt; std::endl; } } print_three_ints(std::vector{ 1, 2, 3 }); // ERROR print_three_ints(std::array&lt;int, 5&gt;{ 1, 2, 3, 4, 5 }); // ERROR int a[10] = { 0 }; print_three_ints(a); // ERROR std::array&lt;int, 3&gt; b = { 1, 2, 3 }; print_three_ints(b); // OK // You can construct a span manually if required: std::vector c{ 1, 2, 3 }; print_three_ints(std::span&lt;const int, 3&gt;{ c.data(), 3 }); // OK: set pointer and length field. print_three_ints(std::span&lt;const int, 3&gt;{ c.cbegin(), c.cend() }); // OK: use iterator pairs. Bit operations C++20 provides a new &lt;bit&gt; header which provides some bit operations including popcount. std::popcount(0u); // 0 std::popcount(1u); // 1 std::popcount(0b1111'0000u); // 4 Math constants Mathematical constants including PI, Euler's number, etc. defined in the &lt;numbers&gt; header. std::numbers::pi; // 3.14159... std::numbers::e; // 2.71828... std::is_constant_evaluated Predicate function which is truthy when it is called in a compile-time context. constexpr bool is_compile_time() { return std::is_constant_evaluated(); } constexpr bool a = is_compile_time(); // true bool b = is_compile_time(); // false std::make_shared supports arrays auto p = std::make_shared&lt;int[]&gt;(5); // pointer to `int[5]` // OR auto p = std::make_shared&lt;int[5]&gt;(); // pointer to `int[5]` starts_with and ends_with on strings Strings (and string views) now have the starts_with and ends_with member functions to check if a string starts or ends with the given string. std::string str = &quot;foobar&quot;; str.starts_with(&quot;foo&quot;); // true str.ends_with(&quot;baz&quot;); // false Check if associative container has element Associative containers such as sets and maps have a contains member function, which can be used instead of the &quot;find and check end of iterator&quot; idiom. std::map&lt;int, char&gt; map {{1, 'a'}, {2, 'b'}}; map.contains(2); // true map.contains(123); // false std::set&lt;int&gt; set {1, 2, 3}; set.contains(2); // true std::bit_cast A safer way to reinterpret an object from one type to another. float f = 123.0; int i = std::bit_cast&lt;int&gt;(f); std::midpoint Calculate the midpoint of two integers safely (without overflow). std::midpoint(1, 3); // == 2 std::to_array Converts the given array/&quot;array-like&quot; object to a std::array. std::to_array(&quot;foo&quot;); // returns `std::array&lt;char, 4&gt;` std::to_array&lt;int&gt;({1, 2, 3}); // returns `std::array&lt;int, 3&gt;` int a[] = {1, 2, 3}; std::to_array(a); // returns `std::array&lt;int, 3&gt;` Acknowledgements cppreference - especially useful for finding examples and documentation of new library features. C++ Rvalue References Explained - a great introduction I used to understand rvalue references, perfect forwarding, and move semantics. clang and gcc's standards support pages. Also included here are the proposals for language/library features that I used to help find a description of, what it's meant to fix, and some examples. Compiler explorer Scott Meyers' Effective Modern C++ - highly recommended book! Jason Turner's C++ Weekly - nice collection of C++-related videos. What can I do with a moved-from object? What are some uses of decltype(auto)? And many more SO posts I'm forgetting... ","link":"https://kimokcheon.github.io/post/cpp20/"},{"title":"CPP17","content":"Overview C++17 includes the following new language features: template argument deduction for class templates declaring non-type template parameters with auto folding expressions new rules for auto deduction from braced-init-list constexpr lambda lambda capture this by value inline variables nested namespaces structured bindings selection statements with initializer constexpr if utf-8 character literals direct-list-initialization of enums [[fallthrough]], [[nodiscard]], [[maybe_unused]] attributes __has_include class template argument deduction C++17 includes the following new library features: std::variant std::optional std::any std::string_view std::invoke std::apply std::filesystem std::byte splicing for maps and sets parallel algorithms std::sample std::clamp std::reduce prefix sum algorithms gcd and lcm std::not_fn string conversion to/from numbers C++17 Language Features Template argument deduction for class templates Automatic template argument deduction much like how it's done for functions, but now including class constructors. template &lt;typename T = float&gt; struct MyContainer { T val; MyContainer() : val{} {} MyContainer(T val) : val{val} {} // ... }; MyContainer c1 {1}; // OK MyContainer&lt;int&gt; MyContainer c2; // OK MyContainer&lt;float&gt; Declaring non-type template parameters with auto Following the deduction rules of auto, while respecting the non-type template parameter list of allowable types[*], template arguments can be deduced from the types of its arguments: template &lt;auto... seq&gt; struct my_integer_sequence { // Implementation here ... }; // Explicitly pass type `int` as template argument. auto seq = std::integer_sequence&lt;int, 0, 1, 2&gt;(); // Type is deduced to be `int`. auto seq2 = my_integer_sequence&lt;0, 1, 2&gt;(); * - For example, you cannot use a double as a template parameter type, which also makes this an invalid deduction using auto. Folding expressions A fold expression performs a fold of a template parameter pack over a binary operator. An expression of the form (... op e) or (e op ...), where op is a fold-operator and e is an unexpanded parameter pack, are called unary folds. An expression of the form (e1 op ... op e2), where op are fold-operators, is called a binary fold. Either e1 or e2 is an unexpanded parameter pack, but not both. template &lt;typename... Args&gt; bool logicalAnd(Args... args) { // Binary folding. return (true &amp;&amp; ... &amp;&amp; args); } bool b = true; bool&amp; b2 = b; logicalAnd(b, b2, true); // == true template &lt;typename... Args&gt; auto sum(Args... args) { // Unary folding. return (... + args); } sum(1.0, 2.0f, 3); // == 6.0 New rules for auto deduction from braced-init-list Changes to auto deduction when used with the uniform initialization syntax. Previously, auto x {3}; deduces a std::initializer_list&lt;int&gt;, which now deduces to int. auto x1 {1, 2, 3}; // error: not a single element auto x2 = {1, 2, 3}; // x2 is std::initializer_list&lt;int&gt; auto x3 {3}; // x3 is int auto x4 {3.0}; // x4 is double constexpr lambda Compile-time lambdas using constexpr. auto identity = [](int n) constexpr { return n; }; static_assert(identity(123) == 123); constexpr auto add = [](int x, int y) { auto L = [=] { return x; }; auto R = [=] { return y; }; return [=] { return L() + R(); }; }; static_assert(add(1, 2)() == 3); constexpr int addOne(int n) { return [n] { return n + 1; }(); } static_assert(addOne(1) == 2); Lambda capture this by value Capturing this in a lambda's environment was previously reference-only. An example of where this is problematic is asynchronous code using callbacks that require an object to be available, potentially past its lifetime. *this (C++17) will now make a copy of the current object, while this (C++11) continues to capture by reference. struct MyObj { int value {123}; auto getValueCopy() { return [*this] { return value; }; } auto getValueRef() { return [this] { return value; }; } }; MyObj mo; auto valueCopy = mo.getValueCopy(); auto valueRef = mo.getValueRef(); mo.value = 321; valueCopy(); // 123 valueRef(); // 321 Inline variables The inline specifier can be applied to variables as well as to functions. A variable declared inline has the same semantics as a function declared inline. // Disassembly example using compiler explorer. struct S { int x; }; inline S x1 = S{321}; // mov esi, dword ptr [x1] // x1: .long 321 S x2 = S{123}; // mov eax, dword ptr [.L_ZZ4mainE2x2] // mov dword ptr [rbp - 8], eax // .L_ZZ4mainE2x2: .long 123 It can also be used to declare and define a static member variable, such that it does not need to be initialized in the source file. struct S { S() : id{count++} {} ~S() { count--; } int id; static inline int count{0}; // declare and initialize count to 0 within the class }; Nested namespaces Using the namespace resolution operator to create nested namespace definitions. namespace A { namespace B { namespace C { int i; } } } The code above can be written like this: namespace A::B::C { int i; } Structured bindings A proposal for de-structuring initialization, that would allow writing auto [ x, y, z ] = expr; where the type of expr was a tuple-like object, whose elements would be bound to the variables x, y, and z (which this construct declares). Tuple-like objects include std::tuple, std::pair, std::array, and aggregate structures. using Coordinate = std::pair&lt;int, int&gt;; Coordinate origin() { return Coordinate{0, 0}; } const auto [ x, y ] = origin(); x; // == 0 y; // == 0 std::unordered_map&lt;std::string, int&gt; mapping { {&quot;a&quot;, 1}, {&quot;b&quot;, 2}, {&quot;c&quot;, 3} }; // Destructure by reference. for (const auto&amp; [key, value] : mapping) { // Do something with key and value } Selection statements with initializer New versions of the if and switch statements which simplify common code patterns and help users keep scopes tight. { std::lock_guard&lt;std::mutex&gt; lk(mx); if (v.empty()) v.push_back(val); } // vs. if (std::lock_guard&lt;std::mutex&gt; lk(mx); v.empty()) { v.push_back(val); } Foo gadget(args); switch (auto s = gadget.status()) { case OK: gadget.zip(); break; case Bad: throw BadFoo(s.message()); } // vs. switch (Foo gadget(args); auto s = gadget.status()) { case OK: gadget.zip(); break; case Bad: throw BadFoo(s.message()); } constexpr if Write code that is instantiated depending on a compile-time condition. template &lt;typename T&gt; constexpr bool isIntegral() { if constexpr (std::is_integral&lt;T&gt;::value) { return true; } else { return false; } } static_assert(isIntegral&lt;int&gt;() == true); static_assert(isIntegral&lt;char&gt;() == true); static_assert(isIntegral&lt;double&gt;() == false); struct S {}; static_assert(isIntegral&lt;S&gt;() == false); UTF-8 character literals A character literal that begins with u8 is a character literal of type char. The value of a UTF-8 character literal is equal to its ISO 10646 code point value. char x = u8'x'; Direct list initialization of enums Enums can now be initialized using braced syntax. enum byte : unsigned char {}; byte b {0}; // OK byte c {-1}; // ERROR byte d = byte{1}; // OK byte e = byte{256}; // ERROR [[fallthrough]], [[nodiscard]], [[maybe_unused]] attributes C++17 introduces three new attributes: [[fallthrough]], [[nodiscard]] and [[maybe_unused]]. [[fallthrough]] indicates to the compiler that falling through in a switch statement is intended behavior. This attribute may only be used in a switch statement, and must be placed before the next case/default label. switch (n) { case 1: // ... [[fallthrough]]; case 2: // ... break; case 3: // ... [[fallthrough]]; default: // ... } [[nodiscard]] issues a warning when either a function or class has this attribute and its return value is discarded. [[nodiscard]] bool do_something() { return is_success; // true for success, false for failure } do_something(); // warning: ignoring return value of 'bool do_something()', // declared with attribute 'nodiscard' // Only issues a warning when `error_info` is returned by value. struct [[nodiscard]] error_info { // ... }; error_info do_something() { error_info ei; // ... return ei; } do_something(); // warning: ignoring returned value of type 'error_info', // declared with attribute 'nodiscard' [[maybe_unused]] indicates to the compiler that a variable or parameter might be unused and is intended. void my_callback(std::string msg, [[maybe_unused]] bool error) { // Don't care if `msg` is an error message, just log it. log(msg); } __has_include __has_include (operand) operator may be used in #if and #elif expressions to check whether a header or source file (operand) is available for inclusion or not. One use case of this would be using two libraries that work the same way, using the backup/experimental one if the preferred one is not found on the system. #ifdef __has_include # if __has_include(&lt;optional&gt;) # include &lt;optional&gt; # define have_optional 1 # elif __has_include(&lt;experimental/optional&gt;) # include &lt;experimental/optional&gt; # define have_optional 1 # define experimental_optional # else # define have_optional 0 # endif #endif It can also be used to include headers existing under different names or locations on various platforms, without knowing which platform the program is running on, OpenGL headers are a good example for this which are located in OpenGL\\ directory on macOS and GL\\ on other platforms. #ifdef __has_include # if __has_include(&lt;OpenGL/gl.h&gt;) # include &lt;OpenGL/gl.h&gt; # include &lt;OpenGL/glu.h&gt; # elif __has_include(&lt;GL/gl.h&gt;) # include &lt;GL/gl.h&gt; # include &lt;GL/glu.h&gt; # else # error No suitable OpenGL headers found. # endif #endif Class template argument deduction Class template argument deduction (CTAD) allows the compiler to deduce template arguments from constructor arguments. std::vector v{ 1, 2, 3 }; // deduces std::vector&lt;int&gt; std::mutex mtx; auto lck = std::lock_guard{ mtx }; // deduces to std::lock_guard&lt;std::mutex&gt; auto p = new std::pair{ 1.0, 2.0 }; // deduces to std::pair&lt;double, double&gt; For user-defined types, deduction guides can be used to guide the compiler how to deduce template arguments if applicable: template &lt;typename T&gt; struct container { container(T t) {} template &lt;typename Iter&gt; container(Iter beg, Iter end); }; // deduction guide template &lt;template Iter&gt; container(Iter b, Iter e) -&gt; container&lt;typename std::iterator_traits&lt;Iter&gt;::value_type&gt;; container a{ 7 }; // OK: deduces container&lt;int&gt; std::vector&lt;double&gt; v{ 1.0, 2.0, 3.0 }; auto b = container{ v.begin(), v.end() }; // OK: deduces container&lt;double&gt; container c{ 5, 6 }; // ERROR: std::iterator_traits&lt;int&gt;::value_type is not a type C++17 Library Features std::variant The class template std::variant represents a type-safe union. An instance of std::variant at any given time holds a value of one of its alternative types (it's also possible for it to be valueless). std::variant&lt;int, double&gt; v{ 12 }; std::get&lt;int&gt;(v); // == 12 std::get&lt;0&gt;(v); // == 12 v = 12.0; std::get&lt;double&gt;(v); // == 12.0 std::get&lt;1&gt;(v); // == 12.0 std::optional The class template std::optional manages an optional contained value, i.e. a value that may or may not be present. A common use case for optional is the return value of a function that may fail. std::optional&lt;std::string&gt; create(bool b) { if (b) { return &quot;Godzilla&quot;; } else { return {}; } } create(false).value_or(&quot;empty&quot;); // == &quot;empty&quot; create(true).value(); // == &quot;Godzilla&quot; // optional-returning factory functions are usable as conditions of while and if if (auto str = create(true)) { // ... } std::any A type-safe container for single values of any type. std::any x {5}; x.has_value() // == true std::any_cast&lt;int&gt;(x) // == 5 std::any_cast&lt;int&amp;&gt;(x) = 10; std::any_cast&lt;int&gt;(x) // == 10 std::string_view A non-owning reference to a string. Useful for providing an abstraction on top of strings (e.g. for parsing). // Regular strings. std::string_view cppstr {&quot;foo&quot;}; // Wide strings. std::wstring_view wcstr_v {L&quot;baz&quot;}; // Character arrays. char array[3] = {'b', 'a', 'r'}; std::string_view array_v(array, std::size(array)); std::string str {&quot; trim me&quot;}; std::string_view v {str}; v.remove_prefix(std::min(v.find_first_not_of(&quot; &quot;), v.size())); str; // == &quot; trim me&quot; v; // == &quot;trim me&quot; std::invoke Invoke a Callable object with parameters. Examples of callable objects are std::function or lambdas; objects that can be called similarly to a regular function. template &lt;typename Callable&gt; class Proxy { Callable c_; public: Proxy(Callable c) : c_{ std::move(c) } {} template &lt;typename... Args&gt; decltype(auto) operator()(Args&amp;&amp;... args) { // ... return std::invoke(c_, std::forward&lt;Args&gt;(args)...); } }; const auto add = [](int x, int y) { return x + y; }; Proxy p{ add }; p(1, 2); // == 3 std::apply Invoke a Callable object with a tuple of arguments. auto add = [](int x, int y) { return x + y; }; std::apply(add, std::make_tuple(1, 2)); // == 3 std::filesystem The new std::filesystem library provides a standard way to manipulate files, directories, and paths in a filesystem. Here, a big file is copied to a temporary path if there is available space: const auto bigFilePath {&quot;bigFileToCopy&quot;}; if (std::filesystem::exists(bigFilePath)) { const auto bigFileSize {std::filesystem::file_size(bigFilePath)}; std::filesystem::path tmpPath {&quot;/tmp&quot;}; if (std::filesystem::space(tmpPath).available &gt; bigFileSize) { std::filesystem::create_directory(tmpPath.append(&quot;example&quot;)); std::filesystem::copy_file(bigFilePath, tmpPath.append(&quot;newFile&quot;)); } } std::byte The new std::byte type provides a standard way of representing data as a byte. Benefits of using std::byte over char or unsigned char is that it is not a character type, and is also not an arithmetic type; while the only operator overloads available are bitwise operations. std::byte a {0}; std::byte b {0xFF}; int i = std::to_integer&lt;int&gt;(b); // 0xFF std::byte c = a &amp; b; int j = std::to_integer&lt;int&gt;(c); // 0 Note that std::byte is simply an enum, and braced initialization of enums become possible thanks to direct-list-initialization of enums. Splicing for maps and sets Moving nodes and merging containers without the overhead of expensive copies, moves, or heap allocations/deallocations. Moving elements from one map to another: std::map&lt;int, string&gt; src {{1, &quot;one&quot;}, {2, &quot;two&quot;}, {3, &quot;buckle my shoe&quot;}}; std::map&lt;int, string&gt; dst {{3, &quot;three&quot;}}; dst.insert(src.extract(src.find(1))); // Cheap remove and insert of { 1, &quot;one&quot; } from `src` to `dst`. dst.insert(src.extract(2)); // Cheap remove and insert of { 2, &quot;two&quot; } from `src` to `dst`. // dst == { { 1, &quot;one&quot; }, { 2, &quot;two&quot; }, { 3, &quot;three&quot; } }; Inserting an entire set: std::set&lt;int&gt; src {1, 3, 5}; std::set&lt;int&gt; dst {2, 4, 5}; dst.merge(src); // src == { 5 } // dst == { 1, 2, 3, 4, 5 } Inserting elements which outlive the container: auto elementFactory() { std::set&lt;...&gt; s; s.emplace(...); return s.extract(s.begin()); } s2.insert(elementFactory()); Changing the key of a map element: std::map&lt;int, string&gt; m {{1, &quot;one&quot;}, {2, &quot;two&quot;}, {3, &quot;three&quot;}}; auto e = m.extract(2); e.key() = 4; m.insert(std::move(e)); // m == { { 1, &quot;one&quot; }, { 3, &quot;three&quot; }, { 4, &quot;two&quot; } } Parallel algorithms Many of the STL algorithms, such as the copy, find and sort methods, started to support the parallel execution policies: seq, par and par_unseq which translate to &quot;sequentially&quot;, &quot;parallel&quot; and &quot;parallel unsequenced&quot;. std::vector&lt;int&gt; longVector; // Find element using parallel execution policy auto result1 = std::find(std::execution::par, std::begin(longVector), std::end(longVector), 2); // Sort elements using sequential execution policy auto result2 = std::sort(std::execution::seq, std::begin(longVector), std::end(longVector)); std::sample Samples n elements in the given sequence (without replacement) where every element has an equal chance of being selected. const std::string ALLOWED_CHARS = &quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&quot;; std::string guid; // Sample 5 characters from ALLOWED_CHARS. std::sample(ALLOWED_CHARS.begin(), ALLOWED_CHARS.end(), std::back_inserter(guid), 5, std::mt19937{ std::random_device{}() }); std::cout &lt;&lt; guid; // e.g. G1fW2 std::clamp Clamp given value between a lower and upper bound. std::clamp(42, -1, 1); // == 1 std::clamp(-42, -1, 1); // == -1 std::clamp(0, -1, 1); // == 0 // `std::clamp` also accepts a custom comparator: std::clamp(0, -1, 1, std::less&lt;&gt;{}); // == 0 std::reduce Fold over a given range of elements. Conceptually similar to std::accumulate, but std::reduce will perform the fold in parallel. Due to the fold being done in parallel, if you specify a binary operation, it is required to be associative and commutative. A given binary operation also should not change any element or invalidate any iterators within the given range. The default binary operation is std::plus with an initial value of 0. const std::array&lt;int, 3&gt; a{ 1, 2, 3 }; std::reduce(std::cbegin(a), std::cend(a)); // == 6 // Using a custom binary op: std::reduce(std::cbegin(a), std::cend(a), 1, std::multiplies&lt;&gt;{}); // == 6 Additionally you can specify transformations for reducers: std::transform_reduce(std::cbegin(a), std::cend(a), 0, std::plus&lt;&gt;{}, times_ten); // == 60 const std::array&lt;int, 3&gt; b{ 1, 2, 3 }; const auto product_times_ten = [](const auto a, const auto b) { return a * b * 10; }; std::transform_reduce(std::cbegin(a), std::cend(a), std::cbegin(b), 0, std::plus&lt;&gt;{}, product_times_ten); // == 140 Prefix sum algorithms Support for prefix sums (both inclusive and exclusive scans) along with transformations. const std::array&lt;int, 3&gt; a{ 1, 2, 3 }; std::inclusive_scan(std::cbegin(a), std::cend(a), std::ostream_iterator&lt;int&gt;{ std::cout, &quot; &quot; }, std::plus&lt;&gt;{}); // 1 3 6 std::exclusive_scan(std::cbegin(a), std::cend(a), std::ostream_iterator&lt;int&gt;{ std::cout, &quot; &quot; }, 0, std::plus&lt;&gt;{}); // 0 1 3 const auto times_ten = [](const auto n) { return n * 10; }; std::transform_inclusive_scan(std::cbegin(a), std::cend(a), std::ostream_iterator&lt;int&gt;{ std::cout, &quot; &quot; }, std::plus&lt;&gt;{}, times_ten); // 10 30 60 std::transform_exclusive_scan(std::cbegin(a), std::cend(a), std::ostream_iterator&lt;int&gt;{ std::cout, &quot; &quot; }, 0, std::plus&lt;&gt;{}, times_ten); // 0 10 30 GCD and LCM Greatest common divisor (GCD) and least common multiple (LCM). const int p = 9; const int q = 3; std::gcd(p, q); // == 3 std::lcm(p, q); // == 9 std::not_fn Utility function that returns the negation of the result of the given function. const std::ostream_iterator&lt;int&gt; ostream_it{ std::cout, &quot; &quot; }; const auto is_even = [](const auto n) { return n % 2 == 0; }; std::vector&lt;int&gt; v{ 0, 1, 2, 3, 4 }; // Print all even numbers. std::copy_if(std::cbegin(v), std::cend(v), ostream_it, is_even); // 0 2 4 // Print all odd (not even) numbers. std::copy_if(std::cbegin(v), std::cend(v), ostream_it, std::not_fn(is_even)); // 1 3 String conversion to/from numbers Convert integrals and floats to a string or vice-versa. Conversions are non-throwing, do not allocate, and are more secure than the equivalents from the C standard library. Users are responsible for allocating enough storage required for std::to_chars, or the function will fail by setting the error code object in its return value. These functions allow you to optionally pass a base (defaults to base-10) or a format specifier for floating type input. std::to_chars returns a (non-const) char pointer which is one-past-the-end of the string that the function wrote to inside the given buffer, and an error code object. std::from_chars returns a const char pointer which on success is equal to the end pointer passed to the function, and an error code object. Both error code objects returned from these functions are equal to the default-initialized error code object on success. Convert the number 123 to a std::string: const int n = 123; // Can use any container, string, array, etc. std::string str; str.resize(3); // hold enough storage for each digit of `n` const auto [ ptr, ec ] = std::to_chars(str.data(), str.data() + str.size(), n); if (ec == std::errc{}) { std::cout &lt;&lt; str &lt;&lt; std::endl; } // 123 else { /* handle failure */ } Convert from a std::string with value &quot;123&quot; to an integer: const std::string str{ &quot;123&quot; }; int n; const auto [ ptr, ec ] = std::from_chars(str.data(), str.data() + str.size(), n); if (ec == std::errc{}) { std::cout &lt;&lt; n &lt;&lt; std::endl; } // 123 else { /* handle failure */ } Acknowledgements cppreference - especially useful for finding examples and documentation of new library features. C++ Rvalue References Explained - a great introduction I used to understand rvalue references, perfect forwarding, and move semantics. clang and gcc's standards support pages. Also included here are the proposals for language/library features that I used to help find a description of, what it's meant to fix, and some examples. Compiler explorer Scott Meyers' Effective Modern C++ - highly recommended book! Jason Turner's C++ Weekly - nice collection of C++-related videos. What can I do with a moved-from object? What are some uses of decltype(auto)? And many more SO posts I'm forgetting... ","link":"https://kimokcheon.github.io/post/cpp17/"},{"title":"CPP14","content":"Overview C++14 includes the following new language features: binary literals generic lambda expressions lambda capture initializers return type deduction decltype(auto) relaxing constraints on constexpr functions variable templates [[deprecated]] attribute C++14 includes the following new library features: user-defined literals for standard library types compile-time integer sequences std::make_unique C++14 Language Features Binary literals Binary literals provide a convenient way to represent a base-2 number. It is possible to separate digits with '. 0b110 // == 6 0b1111'1111 // == 255 Generic lambda expressions C++14 now allows the auto type-specifier in the parameter list, enabling polymorphic lambdas. auto identity = [](auto x) { return x; }; int three = identity(3); // == 3 std::string foo = identity(&quot;foo&quot;); // == &quot;foo&quot; Lambda capture initializers This allows creating lambda captures initialized with arbitrary expressions. The name given to the captured value does not need to be related to any variables in the enclosing scopes and introduces a new name inside the lambda body. The initializing expression is evaluated when the lambda is created (not when it is invoked). int factory(int i) { return i * 10; } auto f = [x = factory(2)] { return x; }; // returns 20 auto generator = [x = 0] () mutable { // this would not compile without 'mutable' as we are modifying x on each call return x++; }; auto a = generator(); // == 0 auto b = generator(); // == 1 auto c = generator(); // == 2 Because it is now possible to move (or forward) values into a lambda that could previously be only captured by copy or reference we can now capture move-only types in a lambda by value. Note that in the below example the p in the capture-list of task2 on the left-hand-side of = is a new variable private to the lambda body and does not refer to the original p. auto p = std::make_unique&lt;int&gt;(1); auto task1 = [=] { *p = 5; }; // ERROR: std::unique_ptr cannot be copied // vs. auto task2 = [p = std::move(p)] { *p = 5; }; // OK: p is move-constructed into the closure object // the original p is empty after task2 is created Using this reference-captures can have different names than the referenced variable. auto x = 1; auto f = [&amp;r = x, x = x * 10] { ++r; return r + x; }; f(); // sets x to 2 and returns 12 Return type deduction Using an auto return type in C++14, the compiler will attempt to deduce the type for you. With lambdas, you can now deduce its return type using auto, which makes returning a deduced reference or rvalue reference possible. // Deduce return type as `int`. auto f(int i) { return i; } template &lt;typename T&gt; auto&amp; f(T&amp; t) { return t; } // Returns a reference to a deduced type. auto g = [](auto&amp; x) -&gt; auto&amp; { return f(x); }; int y = 123; int&amp; z = g(y); // reference to `y` decltype(auto) The decltype(auto) type-specifier also deduces a type like auto does. However, it deduces return types while keeping their references and cv-qualifiers, while auto will not. const int x = 0; auto x1 = x; // int decltype(auto) x2 = x; // const int int y = 0; int&amp; y1 = y; auto y2 = y1; // int decltype(auto) y3 = y1; // int&amp; int&amp;&amp; z = 0; auto z1 = std::move(z); // int decltype(auto) z2 = std::move(z); // int&amp;&amp; // Note: Especially useful for generic code! // Return type is `int`. auto f(const int&amp; i) { return i; } // Return type is `const int&amp;`. decltype(auto) g(const int&amp; i) { return i; } int x = 123; static_assert(std::is_same&lt;const int&amp;, decltype(f(x))&gt;::value == 0); static_assert(std::is_same&lt;int, decltype(f(x))&gt;::value == 1); static_assert(std::is_same&lt;const int&amp;, decltype(g(x))&gt;::value == 1); See also: decltype (C++11). Relaxing constraints on constexpr functions In C++11, constexpr function bodies could only contain a very limited set of syntaxes, including (but not limited to): typedefs, usings, and a single return statement. In C++14, the set of allowable syntaxes expands greatly to include the most common syntax such as if statements, multiple returns, loops, etc. constexpr int factorial(int n) { if (n &lt;= 1) { return 1; } else { return n * factorial(n - 1); } } factorial(5); // == 120 Variable templates C++14 allows variables to be templated: template&lt;class T&gt; constexpr T pi = T(3.1415926535897932385); template&lt;class T&gt; constexpr T e = T(2.7182818284590452353); [[deprecated]] attribute C++14 introduces the [[deprecated]] attribute to indicate that a unit (function, class, etc.) is discouraged and likely yield compilation warnings. If a reason is provided, it will be included in the warnings. [[deprecated]] void old_method(); [[deprecated(&quot;Use new_method instead&quot;)]] void legacy_method(); C++14 Library Features User-defined literals for standard library types New user-defined literals for standard library types, including new built-in literals for chrono and basic_string. These can be constexpr meaning they can be used at compile-time. Some uses for these literals include compile-time integer parsing, binary literals, and imaginary number literals. using namespace std::chrono_literals; auto day = 24h; day.count(); // == 24 std::chrono::duration_cast&lt;std::chrono::minutes&gt;(day).count(); // == 1440 Compile-time integer sequences The class template std::integer_sequence represents a compile-time sequence of integers. There are a few helpers built on top: std::make_integer_sequence&lt;T, N&gt; - creates a sequence of 0, ..., N - 1 with type T. std::index_sequence_for&lt;T...&gt; - converts a template parameter pack into an integer sequence. Convert an array into a tuple: template&lt;typename Array, std::size_t... I&gt; decltype(auto) a2t_impl(const Array&amp; a, std::integer_sequence&lt;std::size_t, I...&gt;) { return std::make_tuple(a[I]...); } template&lt;typename T, std::size_t N, typename Indices = std::make_index_sequence&lt;N&gt;&gt; decltype(auto) a2t(const std::array&lt;T, N&gt;&amp; a) { return a2t_impl(a, Indices()); } std::make_unique std::make_unique is the recommended way to create instances of std::unique_ptrs due to the following reasons: Avoid having to use the new operator. Prevents code repetition when specifying the underlying type the pointer shall hold. Most importantly, it provides exception-safety. Suppose we were calling a function foo like so: foo(std::unique_ptr&lt;T&gt;{new T{}}, function_that_throws(), std::unique_ptr&lt;T&gt;{new T{}}); The compiler is free to call new T{}, then function_that_throws(), and so on... Since we have allocated data on the heap in the first construction of a T, we have introduced a leak here. With std::make_unique, we are given exception-safety: foo(std::make_unique&lt;T&gt;(), function_that_throws(), std::make_unique&lt;T&gt;()); See the section on smart pointers (C++11) for more information on std::unique_ptr and std::shared_ptr. Acknowledgements cppreference - especially useful for finding examples and documentation of new library features. C++ Rvalue References Explained - a great introduction I used to understand rvalue references, perfect forwarding, and move semantics. clang and gcc's standards support pages. Also included here are the proposals for language/library features that I used to help find a description of, what it's meant to fix, and some examples. Compiler explorer Scott Meyers' Effective Modern C++ - highly recommended book! Jason Turner's C++ Weekly - nice collection of C++-related videos. What can I do with a moved-from object? What are some uses of decltype(auto)? And many more SO posts I'm forgetting... ","link":"https://kimokcheon.github.io/post/cpp14/"},{"title":"CPP11","content":"Overview C++11 includes the following new language features: move semantics variadic templates rvalue references forwarding references initializer lists static assertions auto lambda expressions decltype type aliases nullptr strongly-typed enums attributes constexpr delegating constructors user-defined literals explicit virtual overrides final specifier default functions deleted functions range-based for loops special member functions for move semantics converting constructors explicit conversion functions inline-namespaces non-static data member initializers right angle brackets ref-qualified member functions trailing return types noexcept specifier char32_t and char16_t raw string literals C++11 includes the following new library features: std::move std::forward std::thread std::to_string type traits smart pointers std::chrono tuples std::tie std::array unordered containers std::make_shared std::ref memory model std::async std::begin/end C++11 Language Features Move semantics Moving an object means to transfer ownership of some resource it manages to another object. The first benefit of move semantics is performance optimization. When an object is about to reach the end of its lifetime, either because it's a temporary or by explicitly calling std::move, a move is often a cheaper way to transfer resources. For example, moving a std::vector is just copying some pointers and internal state over to the new vector -- copying would involve having to copy every single contained element in the vector, which is expensive and unnecessary if the old vector will soon be destroyed. Moves also make it possible for non-copyable types such as std::unique_ptrs (smart pointers) to guarantee at the language level that there is only ever one instance of a resource being managed at a time, while being able to transfer an instance between scopes. See the sections on: rvalue references, special member functions for move semantics, std::move, std::forward, forwarding references. Rvalue references C++11 introduces a new reference termed the rvalue reference. An rvalue reference to T, which is a non-template type parameter (such as int, or a user-defined type), is created with the syntax T&amp;&amp;. Rvalue references only bind to rvalues. Type deduction with lvalues and rvalues: int x = 0; // `x` is an lvalue of type `int` int&amp; xl = x; // `xl` is an lvalue of type `int&amp;` int&amp;&amp; xr = x; // compiler error -- `x` is an lvalue int&amp;&amp; xr2 = 0; // `xr2` is an lvalue of type `int&amp;&amp;` -- binds to the rvalue temporary, `0` void f(int&amp; x) {} void f(int&amp;&amp; x) {} f(x); // calls f(int&amp;) f(xl); // calls f(int&amp;) f(3); // calls f(int&amp;&amp;) f(std::move(x)); // calls f(int&amp;&amp;) f(xr2); // calls f(int&amp;) f(std::move(xr2)); // calls f(int&amp;&amp; x) See also: std::move, std::forward, forwarding references. Forwarding references Also known (unofficially) as universal references. A forwarding reference is created with the syntax T&amp;&amp; where T is a template type parameter, or using auto&amp;&amp;. This enables perfect forwarding: the ability to pass arguments while maintaining their value category (e.g. lvalues stay as lvalues, temporaries are forwarded as rvalues). Forwarding references allow a reference to bind to either an lvalue or rvalue depending on the type. Forwarding references follow the rules of reference collapsing: T&amp; &amp; becomes T&amp; T&amp; &amp;&amp; becomes T&amp; T&amp;&amp; &amp; becomes T&amp; T&amp;&amp; &amp;&amp; becomes T&amp;&amp; auto type deduction with lvalues and rvalues: int x = 0; // `x` is an lvalue of type `int` auto&amp;&amp; al = x; // `al` is an lvalue of type `int&amp;` -- binds to the lvalue, `x` auto&amp;&amp; ar = 0; // `ar` is an lvalue of type `int&amp;&amp;` -- binds to the rvalue temporary, `0` Template type parameter deduction with lvalues and rvalues: // Since C++14 or later: void f(auto&amp;&amp; t) { // ... } // Since C++11 or later: template &lt;typename T&gt; void f(T&amp;&amp; t) { // ... } int x = 0; f(0); // T is int, deduces as f(int &amp;&amp;) =&gt; f(int&amp;&amp;) f(x); // T is int&amp;, deduces as f(int&amp; &amp;&amp;) =&gt; f(int&amp;) int&amp; y = x; f(y); // T is int&amp;, deduces as f(int&amp; &amp;&amp;) =&gt; f(int&amp;) int&amp;&amp; z = 0; // NOTE: `z` is an lvalue with type `int&amp;&amp;`. f(z); // T is int&amp;, deduces as f(int&amp; &amp;&amp;) =&gt; f(int&amp;) f(std::move(z)); // T is int, deduces as f(int &amp;&amp;) =&gt; f(int&amp;&amp;) See also: std::move, std::forward, rvalue references. Variadic templates The ... syntax creates a parameter pack or expands one. A template parameter pack is a template parameter that accepts zero or more template arguments (non-types, types, or templates). A template with at least one parameter pack is called a variadic template. template &lt;typename... T&gt; struct arity { constexpr static int value = sizeof...(T); }; static_assert(arity&lt;&gt;::value == 0); static_assert(arity&lt;char, short, int&gt;::value == 3); An interesting use for this is creating an initializer list from a parameter pack in order to iterate over variadic function arguments. template &lt;typename First, typename... Args&gt; auto sum(const First first, const Args... args) -&gt; decltype(first) { const auto values = {first, args...}; return std::accumulate(values.begin(), values.end(), First{0}); } sum(1, 2, 3, 4, 5); // 15 sum(1, 2, 3); // 6 sum(1.5, 2.0, 3.7); // 7.2 Initializer lists A lightweight array-like container of elements created using a &quot;braced list&quot; syntax. For example, { 1, 2, 3 } creates a sequences of integers, that has type std::initializer_list&lt;int&gt;. Useful as a replacement to passing a vector of objects to a function. int sum(const std::initializer_list&lt;int&gt;&amp; list) { int total = 0; for (auto&amp; e : list) { total += e; } return total; } auto list = {1, 2, 3}; sum(list); // == 6 sum({1, 2, 3}); // == 6 sum({}); // == 0 Static assertions Assertions that are evaluated at compile-time. constexpr int x = 0; constexpr int y = 1; static_assert(x == y, &quot;x != y&quot;); auto auto-typed variables are deduced by the compiler according to the type of their initializer. auto a = 3.14; // double auto b = 1; // int auto&amp; c = b; // int&amp; auto d = { 0 }; // std::initializer_list&lt;int&gt; auto&amp;&amp; e = 1; // int&amp;&amp; auto&amp;&amp; f = b; // int&amp; auto g = new auto(123); // int* const auto h = 1; // const int auto i = 1, j = 2, k = 3; // int, int, int auto l = 1, m = true, n = 1.61; // error -- `l` deduced to be int, `m` is bool auto o; // error -- `o` requires initializer Extremely useful for readability, especially for complicated types: std::vector&lt;int&gt; v = ...; std::vector&lt;int&gt;::const_iterator cit = v.cbegin(); // vs. auto cit = v.cbegin(); Functions can also deduce the return type using auto. In C++11, a return type must be specified either explicitly, or using decltype like so: template &lt;typename X, typename Y&gt; auto add(X x, Y y) -&gt; decltype(x + y) { return x + y; } add(1, 2); // == 3 add(1, 2.0); // == 3.0 add(1.5, 1.5); // == 3.0 The trailing return type in the above example is the declared type (see section on decltype) of the expression x + y. For example, if x is an integer and y is a double, decltype(x + y) is a double. Therefore, the above function will deduce the type depending on what type the expression x + y yields. Notice that the trailing return type has access to its parameters, and this when appropriate. Lambda expressions A lambda is an unnamed function object capable of capturing variables in scope. It features: a capture list; an optional set of parameters with an optional trailing return type; and a body. Examples of capture lists: [] - captures nothing. [=] - capture local objects (local variables, parameters) in scope by value. [&amp;] - capture local objects (local variables, parameters) in scope by reference. [this] - capture this by reference. [a, &amp;b] - capture objects a by value, b by reference. int x = 1; auto getX = [=] { return x; }; getX(); // == 1 auto addX = [=](int y) { return x + y; }; addX(1); // == 2 auto getXRef = [&amp;]() -&gt; int&amp; { return x; }; getXRef(); // int&amp; to `x` By default, value-captures cannot be modified inside the lambda because the compiler-generated method is marked as const. The mutable keyword allows modifying captured variables. The keyword is placed after the parameter-list (which must be present even if it is empty). int x = 1; auto f1 = [&amp;x] { x = 2; }; // OK: x is a reference and modifies the original auto f2 = [x] { x = 2; }; // ERROR: the lambda can only perform const-operations on the captured value // vs. auto f3 = [x]() mutable { x = 2; }; // OK: the lambda can perform any operations on the captured value decltype decltype is an operator which returns the declared type of an expression passed to it. cv-qualifiers and references are maintained if they are part of the expression. Examples of decltype: int a = 1; // `a` is declared as type `int` decltype(a) b = a; // `decltype(a)` is `int` const int&amp; c = a; // `c` is declared as type `const int&amp;` decltype(c) d = a; // `decltype(c)` is `const int&amp;` decltype(123) e = 123; // `decltype(123)` is `int` int&amp;&amp; f = 1; // `f` is declared as type `int&amp;&amp;` decltype(f) g = 1; // `decltype(f) is `int&amp;&amp;` decltype((a)) h = g; // `decltype((a))` is int&amp; template &lt;typename X, typename Y&gt; auto add(X x, Y y) -&gt; decltype(x + y) { return x + y; } add(1, 2.0); // `decltype(x + y)` =&gt; `decltype(3.0)` =&gt; `double` See also: decltype(auto) (C++14). Type aliases Semantically similar to using a typedef however, type aliases with using are easier to read and are compatible with templates. template &lt;typename T&gt; using Vec = std::vector&lt;T&gt;; Vec&lt;int&gt; v; // std::vector&lt;int&gt; using String = std::string; String s {&quot;foo&quot;}; nullptr C++11 introduces a new null pointer type designed to replace C's NULL macro. nullptr itself is of type std::nullptr_t and can be implicitly converted into pointer types, and unlike NULL, not convertible to integral types except bool. void foo(int); void foo(char*); foo(NULL); // error -- ambiguous foo(nullptr); // calls foo(char*) Strongly-typed enums Type-safe enums that solve a variety of problems with C-style enums including: implicit conversions, inability to specify the underlying type, scope pollution. // Specifying underlying type as `unsigned int` enum class Color : unsigned int { Red = 0xff0000, Green = 0xff00, Blue = 0xff }; // `Red`/`Green` in `Alert` don't conflict with `Color` enum class Alert : bool { Red, Green }; Color c = Color::Red; Attributes Attributes provide a universal syntax over __attribute__(...), __declspec, etc. // `noreturn` attribute indicates `f` doesn't return. [[ noreturn ]] void f() { throw &quot;error&quot;; } constexpr Constant expressions are expressions that are possibly evaluated by the compiler at compile-time. Only non-complex computations can be carried out in a constant expression (these rules are progressively relaxed in later versions). Use the constexpr specifier to indicate the variable, function, etc. is a constant expression. constexpr int square(int x) { return x * x; } int square2(int x) { return x * x; } int a = square(2); // mov DWORD PTR [rbp-4], 4 int b = square2(2); // mov edi, 2 // call square2(int) // mov DWORD PTR [rbp-8], eax In the previous snippet, notice that the computation when calling square is carried out at compile-time, and then the result is embedded in the code generation, while square2 is called at run-time. constexpr values are those that the compiler can evaluate, but are not guaranteed to, at compile-time: const int x = 123; constexpr const int&amp; y = x; // error -- constexpr variable `y` must be initialized by a constant expression Constant expressions with classes: struct Complex { constexpr Complex(double r, double i) : re{r}, im{i} { } constexpr double real() { return re; } constexpr double imag() { return im; } private: double re; double im; }; constexpr Complex I(0, 1); Delegating constructors Constructors can now call other constructors in the same class using an initializer list. struct Foo { int foo; Foo(int foo) : foo{foo} {} Foo() : Foo(0) {} }; Foo foo; foo.foo; // == 0 User-defined literals User-defined literals allow you to extend the language and add your own syntax. To create a literal, define a T operator &quot;&quot; X(...) { ... } function that returns a type T, with a name X. Note that the name of this function defines the name of the literal. Any literal names not starting with an underscore are reserved and won't be invoked. There are rules on what parameters a user-defined literal function should accept, according to what type the literal is called on. Converting Celsius to Fahrenheit: // `unsigned long long` parameter required for integer literal. long long operator &quot;&quot; _celsius(unsigned long long tempCelsius) { return std::llround(tempCelsius * 1.8 + 32); } 24_celsius; // == 75 String to integer conversion: // `const char*` and `std::size_t` required as parameters. int operator &quot;&quot; _int(const char* str, std::size_t) { return std::stoi(str); } &quot;123&quot;_int; // == 123, with type `int` Explicit virtual overrides Specifies that a virtual function overrides another virtual function. If the virtual function does not override a parent's virtual function, throws a compiler error. struct A { virtual void foo(); void bar(); }; struct B : A { void foo() override; // correct -- B::foo overrides A::foo void bar() override; // error -- A::bar is not virtual void baz() override; // error -- B::baz does not override A::baz }; Final specifier Specifies that a virtual function cannot be overridden in a derived class or that a class cannot be inherited from. struct A { virtual void foo(); }; struct B : A { virtual void foo() final; }; struct C : B { virtual void foo(); // error -- declaration of 'foo' overrides a 'final' function }; Class cannot be inherited from. struct A final {}; struct B : A {}; // error -- base 'A' is marked 'final' Default functions A more elegant, efficient way to provide a default implementation of a function, such as a constructor. struct A { A() = default; A(int x) : x{x} {} int x {1}; }; A a; // a.x == 1 A a2 {123}; // a.x == 123 With inheritance: struct B { B() : x{1} {} int x; }; struct C : B { // Calls B::B C() = default; }; C c; // c.x == 1 Deleted functions A more elegant, efficient way to provide a deleted implementation of a function. Useful for preventing copies on objects. class A { int x; public: A(int x) : x{x} {}; A(const A&amp;) = delete; A&amp; operator=(const A&amp;) = delete; }; A x {123}; A y = x; // error -- call to deleted copy constructor y = x; // error -- operator= deleted Range-based for loops Syntactic sugar for iterating over a container's elements. std::array&lt;int, 5&gt; a {1, 2, 3, 4, 5}; for (int&amp; x : a) x *= 2; // a == { 2, 4, 6, 8, 10 } Note the difference when using int as opposed to int&amp;: std::array&lt;int, 5&gt; a {1, 2, 3, 4, 5}; for (int x : a) x *= 2; // a == { 1, 2, 3, 4, 5 } Special member functions for move semantics The copy constructor and copy assignment operator are called when copies are made, and with C++11's introduction of move semantics, there is now a move constructor and move assignment operator for moves. struct A { std::string s; A() : s{&quot;test&quot;} {} A(const A&amp; o) : s{o.s} {} A(A&amp;&amp; o) : s{std::move(o.s)} {} A&amp; operator=(A&amp;&amp; o) { s = std::move(o.s); return *this; } }; A f(A a) { return a; } A a1 = f(A{}); // move-constructed from rvalue temporary A a2 = std::move(a1); // move-constructed using std::move A a3 = A{}; a2 = std::move(a3); // move-assignment using std::move a1 = f(A{}); // move-assignment from rvalue temporary Converting constructors Converting constructors will convert values of braced list syntax into constructor arguments. struct A { A(int) {} A(int, int) {} A(int, int, int) {} }; A a {0, 0}; // calls A::A(int, int) A b(0, 0); // calls A::A(int, int) A c = {0, 0}; // calls A::A(int, int) A d {0, 0, 0}; // calls A::A(int, int, int) Note that the braced list syntax does not allow narrowing: struct A { A(int) {} }; A a(1.1); // OK A b {1.1}; // Error narrowing conversion from double to int Note that if a constructor accepts a std::initializer_list, it will be called instead: struct A { A(int) {} A(int, int) {} A(int, int, int) {} A(std::initializer_list&lt;int&gt;) {} }; A a {0, 0}; // calls A::A(std::initializer_list&lt;int&gt;) A b(0, 0); // calls A::A(int, int) A c = {0, 0}; // calls A::A(std::initializer_list&lt;int&gt;) A d {0, 0, 0}; // calls A::A(std::initializer_list&lt;int&gt;) Explicit conversion functions Conversion functions can now be made explicit using the explicit specifier. struct A { operator bool() const { return true; } }; struct B { explicit operator bool() const { return true; } }; A a; if (a); // OK calls A::operator bool() bool ba = a; // OK copy-initialization selects A::operator bool() B b; if (b); // OK calls B::operator bool() bool bb = b; // error copy-initialization does not consider B::operator bool() Inline namespaces All members of an inline namespace are treated as if they were part of its parent namespace, allowing specialization of functions and easing the process of versioning. This is a transitive property, if A contains B, which in turn contains C and both B and C are inline namespaces, C's members can be used as if they were on A. namespace Program { namespace Version1 { int getVersion() { return 1; } bool isFirstVersion() { return true; } } inline namespace Version2 { int getVersion() { return 2; } } } int version {Program::getVersion()}; // Uses getVersion() from Version2 int oldVersion {Program::Version1::getVersion()}; // Uses getVersion() from Version1 bool firstVersion {Program::isFirstVersion()}; // Does not compile when Version2 is added Non-static data member initializers Allows non-static data members to be initialized where they are declared, potentially cleaning up constructors of default initializations. // Default initialization prior to C++11 class Human { Human() : age{0} {} private: unsigned age; }; // Default initialization on C++11 class Human { private: unsigned age {0}; }; Right angle brackets C++11 is now able to infer when a series of right angle brackets is used as an operator or as a closing statement of typedef, without having to add whitespace. typedef std::map&lt;int, std::map &lt;int, std::map &lt;int, int&gt; &gt; &gt; cpp98LongTypedef; typedef std::map&lt;int, std::map &lt;int, std::map &lt;int, int&gt;&gt;&gt; cpp11LongTypedef; Ref-qualified member functions Member functions can now be qualified depending on whether *this is an lvalue or rvalue reference. struct Bar { // ... }; struct Foo { Bar getBar() &amp; { return bar; } Bar getBar() const&amp; { return bar; } Bar getBar() &amp;&amp; { return std::move(bar); } private: Bar bar; }; Foo foo{}; Bar bar = foo.getBar(); // calls `Bar getBar() &amp;` const Foo foo2{}; Bar bar2 = foo2.getBar(); // calls `Bar Foo::getBar() const&amp;` Foo{}.getBar(); // calls `Bar Foo::getBar() &amp;&amp;` std::move(foo).getBar(); // calls `Bar Foo::getBar() &amp;&amp;` std::move(foo2).getBar(); // calls `Bar Foo::getBar() const&amp;&amp;` Trailing return types C++11 allows functions and lambdas an alternative syntax for specifying their return types. int f() { return 123; } // vs. auto f() -&gt; int { return 123; } auto g = []() -&gt; int { return 123; }; This feature is especially useful when certain return types cannot be resolved: // NOTE: This does not compile! template &lt;typename T, typename U&gt; decltype(a + b) add(T a, U b) { return a + b; } // Trailing return types allows this: template &lt;typename T, typename U&gt; auto add(T a, U b) -&gt; decltype(a + b) { return a + b; } In C++14, decltype(auto) (C++14) can be used instead. Noexcept specifier The noexcept specifier specifies whether a function could throw exceptions. It is an improved version of throw(). void func1() noexcept; // does not throw void func2() noexcept(true); // does not throw void func3() throw(); // does not throw void func4() noexcept(false); // may throw Non-throwing functions are permitted to call potentially-throwing functions. Whenever an exception is thrown and the search for a handler encounters the outermost block of a non-throwing function, the function std::terminate is called. extern void f(); // potentially-throwing void g() noexcept { f(); // valid, even if f throws throw 42; // valid, effectively a call to std::terminate } char32_t and char16_t Provides standard types for representing UTF-8 strings. char32_t utf8_str[] = U&quot;\\u0123&quot;; char16_t utf8_str[] = u&quot;\\u0123&quot;; Raw string literals C++11 introduces a new way to declare string literals as &quot;raw string literals&quot;. Characters issued from an escape sequence (tabs, line feeds, single backslashes, etc.) can be inputted raw while preserving formatting. This is useful, for example, to write literary text, which might contain a lot of quotes or special formatting. This can make your string literals easier to read and maintain. A raw string literal is declared using the following syntax: R&quot;delimiter(raw_characters)delimiter&quot; where: delimiter is an optional sequence of characters made of any source character except parentheses, backslashes and spaces. raw_characters is any raw character sequence; must not contain the closing sequence &quot;)delimiter&quot;. Example: // msg1 and msg2 are equivalent. const char* msg1 = &quot;\\nHello,\\n\\tworld!\\n&quot;; const char* msg2 = R&quot;( Hello, world! )&quot;; C++11 Library Features std::move std::move indicates that the object passed to it may have its resources transferred. Using objects that have been moved from should be used with care, as they can be left in an unspecified state (see: What can I do with a moved-from object?). A definition of std::move (performing a move is nothing more than casting to an rvalue reference): template &lt;typename T&gt; typename remove_reference&lt;T&gt;::type&amp;&amp; move(T&amp;&amp; arg) { return static_cast&lt;typename remove_reference&lt;T&gt;::type&amp;&amp;&gt;(arg); } Transferring std::unique_ptrs: std::unique_ptr&lt;int&gt; p1 {new int{0}}; // in practice, use std::make_unique std::unique_ptr&lt;int&gt; p2 = p1; // error -- cannot copy unique pointers std::unique_ptr&lt;int&gt; p3 = std::move(p1); // move `p1` into `p3` // now unsafe to dereference object held by `p1` std::forward Returns the arguments passed to it while maintaining their value category and cv-qualifiers. Useful for generic code and factories. Used in conjunction with forwarding references. A definition of std::forward: template &lt;typename T&gt; T&amp;&amp; forward(typename remove_reference&lt;T&gt;::type&amp; arg) { return static_cast&lt;T&amp;&amp;&gt;(arg); } An example of a function wrapper which just forwards other A objects to a new A object's copy or move constructor: struct A { A() = default; A(const A&amp; o) { std::cout &lt;&lt; &quot;copied&quot; &lt;&lt; std::endl; } A(A&amp;&amp; o) { std::cout &lt;&lt; &quot;moved&quot; &lt;&lt; std::endl; } }; template &lt;typename T&gt; A wrapper(T&amp;&amp; arg) { return A{std::forward&lt;T&gt;(arg)}; } wrapper(A{}); // moved A a; wrapper(a); // copied wrapper(std::move(a)); // moved See also: forwarding references, rvalue references. std::thread The std::thread library provides a standard way to control threads, such as spawning and killing them. In the example below, multiple threads are spawned to do different calculations and then the program waits for all of them to finish. void foo(bool clause) { /* do something... */ } std::vector&lt;std::thread&gt; threadsVector; threadsVector.emplace_back([]() { // Lambda function that will be invoked }); threadsVector.emplace_back(foo, true); // thread will run foo(true) for (auto&amp; thread : threadsVector) { thread.join(); // Wait for threads to finish } std::to_string Converts a numeric argument to a std::string. std::to_string(1.2); // == &quot;1.2&quot; std::to_string(123); // == &quot;123&quot; Type traits Type traits defines a compile-time template-based interface to query or modify the properties of types. static_assert(std::is_integral&lt;int&gt;::value); static_assert(std::is_same&lt;int, int&gt;::value); static_assert(std::is_same&lt;std::conditional&lt;true, int, double&gt;::type, int&gt;::value); Smart pointers C++11 introduces new smart pointers: std::unique_ptr, std::shared_ptr, std::weak_ptr. std::auto_ptr now becomes deprecated and then eventually removed in C++17. std::unique_ptr is a non-copyable, movable pointer that manages its own heap-allocated memory. Note: Prefer using the std::make_X helper functions as opposed to using constructors. See the sections for std::make_unique and std::make_shared. std::unique_ptr&lt;Foo&gt; p1 { new Foo{} }; // `p1` owns `Foo` if (p1) { p1-&gt;bar(); } { std::unique_ptr&lt;Foo&gt; p2 {std::move(p1)}; // Now `p2` owns `Foo` f(*p2); p1 = std::move(p2); // Ownership returns to `p1` -- `p2` gets destroyed } if (p1) { p1-&gt;bar(); } // `Foo` instance is destroyed when `p1` goes out of scope A std::shared_ptr is a smart pointer that manages a resource that is shared across multiple owners. A shared pointer holds a control block which has a few components such as the managed object and a reference counter. All control block access is thread-safe, however, manipulating the managed object itself is not thread-safe. void foo(std::shared_ptr&lt;T&gt; t) { // Do something with `t`... } void bar(std::shared_ptr&lt;T&gt; t) { // Do something with `t`... } void baz(std::shared_ptr&lt;T&gt; t) { // Do something with `t`... } std::shared_ptr&lt;T&gt; p1 {new T{}}; // Perhaps these take place in another threads? foo(p1); bar(p1); baz(p1); std::chrono The chrono library contains a set of utility functions and types that deal with durations, clocks, and time points. One use case of this library is benchmarking code: std::chrono::time_point&lt;std::chrono::steady_clock&gt; start, end; start = std::chrono::steady_clock::now(); // Some computations... end = std::chrono::steady_clock::now(); std::chrono::duration&lt;double&gt; elapsed_seconds = end - start; double t = elapsed_seconds.count(); // t number of seconds, represented as a `double` Tuples Tuples are a fixed-size collection of heterogeneous values. Access the elements of a std::tuple by unpacking using std::tie, or using std::get. // `playerProfile` has type `std::tuple&lt;int, const char*, const char*&gt;`. auto playerProfile = std::make_tuple(51, &quot;Frans Nielsen&quot;, &quot;NYI&quot;); std::get&lt;0&gt;(playerProfile); // 51 std::get&lt;1&gt;(playerProfile); // &quot;Frans Nielsen&quot; std::get&lt;2&gt;(playerProfile); // &quot;NYI&quot; std::tie Creates a tuple of lvalue references. Useful for unpacking std::pair and std::tuple objects. Use std::ignore as a placeholder for ignored values. In C++17, structured bindings should be used instead. // With tuples... std::string playerName; std::tie(std::ignore, playerName, std::ignore) = std::make_tuple(91, &quot;John Tavares&quot;, &quot;NYI&quot;); // With pairs... std::string yes, no; std::tie(yes, no) = std::make_pair(&quot;yes&quot;, &quot;no&quot;); std::array std::array is a container built on top of a C-style array. Supports common container operations such as sorting. std::array&lt;int, 3&gt; a = {2, 1, 3}; std::sort(a.begin(), a.end()); // a == { 1, 2, 3 } for (int&amp; x : a) x *= 2; // a == { 2, 4, 6 } Unordered containers These containers maintain average constant-time complexity for search, insert, and remove operations. In order to achieve constant-time complexity, sacrifices order for speed by hashing elements into buckets. There are four unordered containers: unordered_set unordered_multiset unordered_map unordered_multimap std::make_shared std::make_shared is the recommended way to create instances of std::shared_ptrs due to the following reasons: Avoid having to use the new operator. Prevents code repetition when specifying the underlying type the pointer shall hold. It provides exception-safety. Suppose we were calling a function foo like so: foo(std::shared_ptr&lt;T&gt;{new T{}}, function_that_throws(), std::shared_ptr&lt;T&gt;{new T{}}); The compiler is free to call new T{}, then function_that_throws(), and so on... Since we have allocated data on the heap in the first construction of a T, we have introduced a leak here. With std::make_shared, we are given exception-safety: foo(std::make_shared&lt;T&gt;(), function_that_throws(), std::make_shared&lt;T&gt;()); Prevents having to do two allocations. When calling std::shared_ptr{ new T{} }, we have to allocate memory for T, then in the shared pointer we have to allocate memory for the control block within the pointer. See the section on smart pointers for more information on std::unique_ptr and std::shared_ptr. std::ref std::ref(val) is used to create object of type std::reference_wrapper that holds reference of val. Used in cases when usual reference passing using &amp; does not compile or &amp; is dropped due to type deduction. std::cref is similar but created reference wrapper holds a const reference to val. // create a container to store reference of objects. auto val = 99; auto _ref = std::ref(val); _ref++; auto _cref = std::cref(val); //_cref++; does not compile std::vector&lt;std::reference_wrapper&lt;int&gt;&gt;vec; // vector&lt;int&amp;&gt;vec does not compile vec.push_back(_ref); // vec.push_back(&amp;i) does not compile cout &lt;&lt; val &lt;&lt; endl; // prints 100 cout &lt;&lt; vec[0] &lt;&lt; endl; // prints 100 cout &lt;&lt; _cref; // prints 100 Memory model C++11 introduces a memory model for C++, which means library support for threading and atomic operations. Some of these operations include (but aren't limited to) atomic loads/stores, compare-and-swap, atomic flags, promises, futures, locks, and condition variables. See the sections on: std::thread std::async std::async runs the given function either asynchronously or lazily-evaluated, then returns a std::future which holds the result of that function call. The first parameter is the policy which can be: std::launch::async | std::launch::deferred It is up to the implementation whether to perform asynchronous execution or lazy evaluation. std::launch::async Run the callable object on a new thread. std::launch::deferred Perform lazy evaluation on the current thread. int foo() { /* Do something here, then return the result. */ return 1000; } auto handle = std::async(std::launch::async, foo); // create an async task auto result = handle.get(); // wait for the result std::begin/end std::begin and std::end free functions were added to return begin and end iterators of a container generically. These functions also work with raw arrays which do not have begin and end member functions. template &lt;typename T&gt; int CountTwos(const T&amp; container) { return std::count_if(std::begin(container), std::end(container), [](int item) { return item == 2; }); } std::vector&lt;int&gt; vec = {2, 2, 43, 435, 4543, 534}; int arr[8] = {2, 43, 45, 435, 32, 32, 32, 32}; auto a = CountTwos(vec); // 2 auto b = CountTwos(arr); // 1 Acknowledgements cppreference - especially useful for finding examples and documentation of new library features. C++ Rvalue References Explained - a great introduction I used to understand rvalue references, perfect forwarding, and move semantics. clang and gcc's standards support pages. Also included here are the proposals for language/library features that I used to help find a description of, what it's meant to fix, and some examples. Compiler explorer Scott Meyers' Effective Modern C++ - highly recommended book! Jason Turner's C++ Weekly - nice collection of C++-related videos. What can I do with a moved-from object? What are some uses of decltype(auto)? And many more SO posts I'm forgetting... ","link":"https://kimokcheon.github.io/post/cpp11/"},{"title":"Character Inpainting based on Deep Learning","content":"Background 图像修复是对受损图像的缺失区域进行重建的过程，研究多集中在自然图像和人脸图像的修复。根据是否指定遮挡部分，分为基于mask的图像修复和盲图像修复。 文字修复是指恢复不完整的文字的遮挡或染色的部分，使其拥有正确语义，在古籍文献数字化过程中起着重要作用。目前文字修复算法多集中在手写汉字和场景文本的修复，且很多思想都借鉴了图像修复的方法。 Dataset 公开数据集。CASIA-HWDB手写体汉字库、Char74K英文字符识别数据集，并随机生成mask遮挡。 合成数据集。利用字体文件合成文字数据集，并随机生成mask遮挡。 真实数据集。收集真实的拓片或石刻碑文数据集。 图像修复研究现状 主流图像修复思想 联合多种损失函数（L1损失、对抗损失、风格损失、感知损失等）。 感知损失利用高级语义特征衡量图像差异，使用在ImageNet上预训练过的VGG-19网络激活层输出 风格损失多用于风格迁移任务，利用格雷姆矩阵计算图像特征之间相似度 先重建整体先验信息（边缘、线条、分割图等），后用其指导后续的图像修复。 利用注意力机制（多尺度注意力等）。 总结 目前的文字修复仅修复灰度文字图像，不考虑背景修复。 古籍文本图像的修复受数据集的限制研究较少，如何同时修复正确语义的文字以及纹理一致的背景有待研究。 Reference [1]Chang J, Gu Y, Zhang Y, et al. Chinese Handwriting Imitation with Hierarchical Generative Adversarial Network[C]//BMVC. 2018: 290. [2]Li J, Song G, Zhang M. Occluded offline handwritten Chinese character recognition using deep convolutional generative adversarial network and improved GoogLeNet[J]. Neural Computing and Applications, 2020, 32: 4805-4819. [3]Song G, Li J, Wang Z. Occluded offline handwritten Chinese character inpainting via generative adversarial network and self-attention mechanism[J]. Neurocomputing, 2020, 415: 146-156. [4]Wang J, Pan G, Sun D, et al. Chinese Character Inpainting with Contextual Semantic Constraints[C]//Proceedings of the 29th ACM International Conference on Multimedia. 2021: 1829-1837. [5]Li H, Zhong Z, Guan W, et al. Generative character inpainting guided by structural information[J]. The Visual Computer, 2021, 37: 2895-2906. [6]Sun J, Xue F, Li J, et al. TSINIT: a two-stage Inpainting network for incomplete text[J]. IEEE Transactions on Multimedia, 2022. ","link":"https://kimokcheon.github.io/post/character-inpainting-based-on-deep-learning/"},{"title":"Data Augmentation Thesis ","content":"Introduction 这是2022 fall 论文研读课程的PPT摘录，算是假期读的一些论文留档。 What is data augmentation? “Techniques are used to enhance the amount of data by adding slightly changed copies of previously existing data or freshly produced synthetic data from existing data,” according to Wikipedia. Background 数据增强的作用 With the development of hardware performance, deep learning can usually get better results driven by big data. When a model is excessively complex, such as having too many parameters compared to the number of training samples, over-fitting might happen and weaken its generalization ability. 数据增强主要有两个作用，第一个是在当前深度学习的背景下，大量数据的投入在大部分时候能得到更好的结果。为了提高模型的性能，实验者会根据现有的数据集进行增广，扩充原本的数据集。 同时，由于现有任务越来越复杂，使用的网络也越来越复杂。虽然复杂网络大多数会增加模型的性能，但是复杂网络参数多，容易造成过拟合现象。 在这种情况下数据增强得到的大量的数据会丰富数据的多样性，让他们的分布范围更广，有助于减小过拟合，增加模型的泛化能力。 数据增强的手段 Image space augmentation Geometric Transformations Color Space Transformations RandomRrase / GridMask Mixup / Cutmix Mosaic Feature space augmentation MoEx GAN-based Data Augmentation NAS-based Data Augmentation AutoAugment Fast AutoAugment DADA Other MixMatch FeatMatch UDA 目前的数据增强手段（主要针对于图像） Geometric Transformations：就是图像翻转，裁剪，旋转和平移翻转，旋转，裁剪，缩放，平移，抖动 Color Space Transformations：对比度，锐化，白平衡，色彩抖动，随机色彩处理和许多其他技术来更改图像的色彩空间。 Mixup就是将两张图像进行mix操作，提供数据的丰富性；Cutmix就是将一部分区域cut掉但不填充0像素而是随机填充训练集中的其他数据的区域像素值，分类结果按一定的比例分配。 Mosaic：是将四张图片进行随机裁剪，再拼接到一张图上作为训练数据，这样做的好处是丰富了图片的背景。 GAN 由两个网络组成：生成器和鉴别器。生成器的工作是生成仅具有噪声作为输入的伪造数据。鉴别器接收真实图像和伪图像（由发生器产生）作为输入，并学会识别图像是伪图像还是真实图像。 AutoAugment是Google提出的自动选择最优数据增强方案的研究，它的基本思路是使用强化学习从数据本身寻找最佳图像变换策略，对于不同的任务学习不同的增强方法。 在实验中发现： - 对于门牌数字识别等任务，研究表明剪切和平移等几何变换能够获得最佳效果。 - 对于ImageNet中的图像分类任务，AutoAugment学习到了不使用剪切，也不完全反转颜色，因为这些变换会导致图像失真。AutoAugment学习到的是侧重于微调颜色和色相分布。 MixMatch：半监督学习领域的Mixup FeatMatch：半监督学习领域的MoEx Random Erasing Data Augmentation (AAAI 2020) 首先介绍一种非常常见的方法，随机擦除。这篇论文其实在2017年就发表在arxiv上了，但是作者正式发表是在aaai2020上。从17年发表出来，随机擦除就被证明是非常有效的一种数据增强方式。这篇论文介绍了在当时而言一种新的训练卷积神经网络的数据增强方法。论文的出发点是模拟现实场景中遮挡的问题，随机擦除的做法是，在训练阶段，在图像中随机选择一个矩形区域，并用随机值擦除它的像素。在此过程中，生成不同遮挡程度的训练图像，降低了过拟合的风险，使模型对遮挡具有鲁棒性。这个方法可以与大多数基于CNN的识别模型集成。随机擦除虽然简单，但它是对常用的数据增强技术(如随机裁剪和翻转)的补充，在图像分类、目标检测和人员再识别方面，与强大的baseline相比，可以产生持续的改进。可以看到不管是对图像分类，行人重识别, 目标检测，还是对多种增强方法的集成，随机擦除的部分一定是在图像内部，不会超过图像的外部。 随机裁剪是一种有效的数据增强方法，它减少了背景在CNN决策中的贡献，可以基于对象的部分存在而不是聚焦于整个对象来建立学习模型。D这幅图是随机擦除与随机裁剪的组合。与随机裁剪相比，随机擦除保留了物体的整体结构，只是遮挡了物体的某些部分。另外，擦除区域的像素被重新分配随机值，这可以看作是给图像添加了噪声。随机擦除会和Dropout有点像，dropout是在训练过程中丢掉神经元，相比于 dropout，随机擦除更像是在图像的层次进行的 dropout，但是优点在于(1)在连续的矩形区域上操作。(2)目标是使得模型对噪声和遮挡更加鲁棒 训练中，随机擦除有一定的概率性， ppp 的概率将被随机擦除， 1−p1−p1−p 的概率是保持不变。 假设图像的面积是 S=W×HS=W×HS=W×H ，随机初始化擦除的面积为 SeS_eSe​ ，其中 SeS_eSe​, SSS 的范围在 sls_lsl​ 与 shs_hsh​ 之间，擦除矩形的长宽比在 r1r_1r1​ 与 r2r_2r2​ 之间，设置为 rer_ere​ ，则可求得长 He=Se×reH_e=S_e \\times r_eHe​=Se​×re​ ，宽 We=Se×reW_e = S_e \\times r_eWe​=Se​×re​ 。随机初始化一个点 P=(xe,ye)P=(x_e,y_e)P=(xe​,ye​) ，并且需要保证这个点所画的框在图像内。 Ie=(xe,ye,xe+We,ye+He)I_e=(x_e,y_e,x_e+W_e,y_e+H_e)Ie​=(xe​,ye​,xe​+We​,ye​+He​) 作为选择的区域。 结果可见，可见加入了随机擦除方法，模型的测试错误率下降了 接下来是一个消融实验，分别对比了用随机数填充、ImageNet平均值填充、0填充（黑色）、255填充（白色）。最终实验认为采用随机数填充的方式更好。 Improved Regularization of Convolutional Neural Networks with Cutout (2017) 下一篇文章cutout只发表在了arxiv上。Cutout的出发点和随机擦除一样，也是模拟遮挡，目的是提高泛化能力，实现上比Random Erasing简单，因为随机擦除需要控制生成矩阵的大小，使其保证在图像中，而cutout不需要，作者发现cutout区域的大小比形状重要，文中的具体操作是cutout在每个batchsize中只用随机选择一个固定大小的正方形区域，然后采用全0填充就OK了 本文和随机擦除几乎同时发表，难分高下(不同场景下谁好难说)，区别在于在cutout中，擦除矩形区域存在一定概率不完全在原图像中的。而在Random Erasing中，擦除矩形区域一定在原图像内。Cutout变相的实现了任意大小的擦除，以及保留更多重要区域。 作者其实开发了一个早期做法，具体是：在训练的每个epoch过程中，保存每张图片对应的特征图，在下一个训练回合，对每张图片的特征图进行上采样到和原图一样大，然后使用阈值切分为二值图，盖在原图上再输入到cnn中进行训练，有点自适应的意味。 随机擦除和cutout主要动机来自对象遮挡问题，这在许多计算机视觉任务中很常见，例如对象识别、跟踪或人体姿态估计。 通过生成模拟被遮挡示例的新图像，不仅可以更好地为模型在现实世界中遇到遮挡做好准备，而且该模型还学会了在做出决策时考虑更多的图像上下文。 mixup: BEYOND EMPIRICAL RISK MINIMIZATION (ICLR 2018) 接下来要介绍的是mixup。Mixup作者介绍的背景是这样的：只要学习机（如神经网络）的规模随着训练数据数量的增加而增加，那么网络收敛性就是可以得到保证的。但是大规模神经网络很容易出现的问题是，它是去记忆（而不是泛化）训练数据。Mixup主要是解决这个问题。从这幅图可以看到mixup将猫和狗两个不同类别的图像融合在一起了。与之前论文不同，mixup不仅可以对同类图像进行融合增强，还可以对不同类的图像进行增强。 论文给的公式显示对于图像x我们通过对两张图象的像素点进行加权获得新的x，而对标签也使用相同的加权系数形成新的标签。这为不同的类提供了连续的数据样本，直观地扩展了给定训练集的分布，从而使网络在测试阶段更加稳健。 AUGMIX: A Simple Data Processing Method To Improve Robustness And Uncertainty (ICLR 2020) Mixup有一个缺点,就是无法保证合成的图片的语义信息.很容易这个新生成的样本是无效的.为了保证合成图片的语义信息，deepmind提出了一种新的数据增强方法。 如果只是级联不同的数据增强，最后得到的图像往往偏离原图，变得失真（如下图所示），而AugMix通过混合不同增强的图像可以减轻这个问题，而且不损失图像多样性。 在增强的过程中,作者先随机从若干个传统增强操作集中选取1~3个操作,然后将这些操作堆叠起来,形成不同深度的操作序列(按论文里的说法是三个序列{op1,op12,op123}).论文默认有三条链(K=3),每条链会从{op1,op12,op123}集合中均匀随机抽取一个序列. 融合的过程则是,先使用Dirichlet(1,1,1)分布随机抽取3个权值wi,根据Dirichlet分布的性质,权值和为1. 会跨接到最后一步与Xaug按权相加,权值来自从Beta(1,1)分布中取样,相加后得到最后的新样本Xaugmix,至此所有步骤完成.值得注意的是,Dirichlet(1,1,1)和Beta(1,1)其实都等同于均匀之后按照权值wi将三条链按权相加得到Xaug. 最后就是损失函数的构建了. 用zero初始化一个和原始图像一样大小的图像xaug；并根据Dirichlet分布随机生成k个权重(w1,w2,...,wk),用来混合不同的图像； 从定义的数据增强中随机选择3个：op1,op2,op3，用这3个op组合出不同深度的操作，其中op12为op1+op2，而op123=op1+op2+op3，这样op1,op12,op123为深度分别是1，2，3的增强组合链，随机选择其中一个组合链来增强图像，并混合增强后的图像：xaug+=wi⋅chain(xori)； 多步骤2重复k次，这相当于混合了k个不同增强后的图像； 根据beta分布随机生成权重m，然后将上述得到的图像和原始图像进行混合：xaugmix=mxori+(1−m)xaug。 会很自然的想到，由于作者是从同一个原始样本中使用AugMix得到的不同的新样本，那么这些新样本应该具有相似的语义,这里作者假设对原始图像做了两次AugMix,得到增强图像1, 和增强图像2,这三个样本输入模型后得到的结果的分布理应是相似,为了控制他们相似，作者在损失函数中引入了JS散度 那为什么使用两个新扩增的样本,不是一个,也不是三个?作者的说法是实验中两个比一个好,三个的话增加了计算开销,但性能提升的效果并不强. 相对于Mixup, AugMix选择只使用一张图片作为原始样本进行数据增强,好处是得到的新样本能保持语义信息,即保证新生成的样本是有意义的,不会生成一些至少在人的角度看上去属于崩坏的样本.同时也的确在样本空间中对已有的样本点进行扩散填充,提高了模型的泛化性能与稳定性. 这篇文章有两个比较重要的点 第一个是：约束了增强前后样本的一致性 第二个是：不是对所有样本都进行一样的数据增强操作 Enhancing Audio Augmentation Methods with Consistency Learning (ICASSP 2021) 在ICASSP2021中，有一篇论文同样考虑到了数据增强前后的样本分布相似的问题，体现在论文的题目的“一致性”上。这篇论文在对每个实例 x 应用两个变换，给出三元组 (x, x1, x2)。一致性学习的目标是确保 G(x)、G(x1) 和 G(x2) 不会彼此发散。 这两篇论文不再像之前论文那样只注重样本多样的变化，他还考虑了数据增强前后分布一致的问题。希望增强过后原本的语义信息尽可能少的改变。 毫无疑问数据增强对于训练CNN非常有效，大家也在不断发明新的数据增强方法拿到一份数据集，我们凭借之前的经验组合不同的增强方法形成一个数据增强策略，通常可以得到一个还不错的baseline。但如何更进一步，让模型再提升1-2个百分点就很困难了。之前大家是同轨进行一些数据增强效果的可视化，选定一个潜在的优化方向（比如旋转的幅度是否过大了），然后调整对应的超参数进行一组对比实验。当问题发展到这个阶段时，人工优化的成本已经很高而且很可能收效甚微了。针对这个问题，开始有人尝试借助AutoML这个新技术来进行数据增强策略的筛选。 KeepAugment: A Simple Information-PreservingData Augmentation Approach（CVPR2021） 尽管数据增强会增加有效数据的大小并增加训练的数据的多样性，但仍不可避免地在训练过程中引入具有噪声和歧义的增强样本，从而在推理过程中损害为增强数据的性能。keepAugment提出了一种简单但是高效的方法，以提高增强图像的保真度 KeepAugment的主要思想很简单：先设定一个阈值，然后通过原图的显著图，提取一个整体重要性得分大于的区域，最后对原图进行数据增强的过程中保留这个区域的原图。 keepAugment的思路是通过saliency map测量矩形区域内的重要性，并确保在数据增强后保留重要性得分高的重要区域 这篇文章分析表明现有的数据增强方法可能会引入噪音或者歧义的增强样本，从而限制了它们提高整体性能的能力。因此作者使用saliency map来衡量每个区域的重要性，并提出避免避免区域级数据增强方法（例如cutout）切割重要区域；或从原始数据中粘贴关键区域以进行图像级数据增强（例如RandAugment） KeepAugment的思路是通过saliency map（如图1 a4和b4）测量图像中矩形区域的重要性，并确保在数据增强后保留重要性得分最高的矩形区域。 对于Cutout，作者通过避免剪切重要区域来实现这一点（请参见图1 a5和b5）;对于图像级转换，例如RandAugment，作者通过将重要区域粘贴到转换图像的顶部来实现此目的 从上面的思路中不难分析出KeepAugment主要可以分为（1）计算saliency map（2）保留重要的矩形区域这两个步骤。其中第二步又可以根据数据增强方式分为Selective-Cut，Selective-Paste。 KeepAugment 通过 vanilla gradient 方法获取saliency map，具体来说，给定图像x及其对应标签logit value ly(x)，KeepAugment 将gi,j(x,y)g_{i,j}(x, y)gi,j​(x,y)设为vanilla gradients的绝对值∣δxly(x)∣| \\delta x ly(x)|∣δxly(x)∣。对于RBG图像，采用通道最大值，以获取每个像素（i，j）的单个显着性值。重要性得分定义的公式如下所示：随机选择一个区域，并计算其重要性得分，直到找到一个重要性得分小于指定阈值的区域，然后cut这个区域即可 KeepAugment对于区域级的数据增强方法(如：cutout), 我们通过确保被切割的区域不会具有较大的重要性得分来控制数据增强的保真度。这实际上是通过实现的，在算法1中，我们随机采样要切割的区域S，直到其重要性得分I(S,x,y)小于给定的阈值τ。相应的数据增强定义如下：是切割的区域S的binary mask，随机选择一个区域，并计算其重要性得分，直到找到一个重要性得分大于指定阈值的区域，然后对原图进行全图变换，最后把这个区域粘贴替换掉变换后图像的对应区域 因为图像级变换共同修改了整个图像，所以我们通过粘贴具有较高重要性的随机区域来确保变换的保真度，Algorithm 1(b） 显示了如何在实践中实现此目标的方法，其中绘制图像级别的增强数据x0 = A(x)，对满足阈值τ的I(S, x, y)&gt;τ的区域S进行均匀采样，然后将原始图像x的regionS粘贴到x'，从而得出 KeepAugment的思路是通过saliency map测量图像中矩形区域的重要性，并确保在数据增强后保留重要性得分最高的矩形区域。 对于Cutout，作者通过避免剪切重要区域来实现这一点（请参见图1 a5和b5）;对于图像级转换，例如RandAugment，作者通过将重要区域粘贴到转换图像的顶部来实现此目的 从上面的思路中不难分析出KeepAugment主要可以分为（1）计算saliency map（2）保留重要的矩形区域这两个步骤。其中第二步又可以根据数据增强方式分为Selective-Cut，Selective-Paste。 KeepAugment 通过 vanilla gradient 方法获取saliency map，具体来说，给定图像x及其对应标签logit value ly(x)，KeepAugment 将gij(x, y)设为vanilla gradients的绝对值| ∇x ly(x)|。对于RBG图像，采用通道最大值，以获取每个像素（i，j）的单个显着性值。重要性得分定义的公式如下所示： KeepAugment对于区域级的数据增强方法(如：cutout), 我们通过确保被切割的区域不会具有较大的重要性得分来控制数据增强的保真度。这实际上是通过**Algorithm 1(a）**实现的，在算法1中，我们随机采样要切割的区域S，直到其重要性得分I(S,x,y)小于给定的阈值τ。相应的数据增强定义如下：是切割的区域S的binary mask， 因为图像级变换共同修改了整个图像，所以我们通过粘贴具有较高重要性的随机区域来确保变换的保真度，Algorithm 1(b） 显示了如何在实践中实现此目标的方法，其中绘制图像级别的增强数据x0 = A(x)，对满足阈值τ的I(S, x, y)&gt;τ的区域S进行均匀采样，然后将原始图像x的regionS粘贴到x'，从而得出 作者在CIFAR-10数据集上使用Cutout和RandAugment两种方法进行实验，分析数据增强方式的强度与准确性Acc的关系,其中cutout的强度由Cutout length控制，RandAugment的强度由Distortion magnitude控制， 正如通常所期望的，在两种情况下，泛化（原始数据的训练和测试准确性之间的差距）都会随着变换幅度的增加而提高。但是，当变换的幅度太大时（对于Cutout≥16，对于RandAugment≥12），训练精度（蓝线）和测试精度（红线）开始退化，表明增强的数据没有在这种情况下，较长的时间持续地表示干净的训练数据，以使增强数据上的训练损失不能再替代干净数据上的训练损失。 对于Selective-Cut的阈值，小阈值得到的效果较好，这是因为避免了cut掉重要的区域，但随着阈值的增大，这种限制就变弱了，也就很有可能cut掉重要区域，因此性能就有所下降；对于Selective-Paste的阈值，小阈值效果提升不明显，因为找到的区域可能不是最重要的，随着阈值提高，性能逐渐提升的也明显了，但进一步提高阈值则不在提升性能，这可能是因为重要性得分最高的区域不一定对模型帮助最大，反而又可能漏掉一些更重要的区域。 SapAugment: Learning A Sample Adaptive Policy for Data Augmentation (ICASSP 2021) 在ICASSP2021一篇论文上，作者强调了对样本进行不同的数据增强操作。作者认为高训练损失的难样本已经提供了强大的训练信号来更新模型参数，并且应该受到轻度或不增强的干扰。用强增强扰动一个困难的样本也可能使它很难学习。此外，训练损失低的样本应该受到更强的增强的干扰，以提供对各种条件的更强鲁棒性。根据此，作者提出了一种学习样本自适应增强策略的新方法——SapAugment。论文的策略是根据数据样本的训练损失调整增强参数。例如在高斯噪声的例子中，一个难样本会被一个低方差噪声扰乱，一个容易样本被一个高方差噪声扰动。 A hard sample with high training loss already provides strong training signal to update the model parameters and should be perturbed with mild or no augmentation. A sample with low training loss should be perturbed by a stronger augmentation to provide more robustness to a variety of conditions. 输入一个样本x，第一次的时候随机初始化各种数据增强的概率，进过一次训练后，会产生样本的loss，这个loss会通过sample-adaptive这个函数映射一个λ值，用于下一次增强方法。λ决定的是每个增强方法的强度。 例如对于time masking，增强量是应用mask的大小。而且sapaugment是针对一个batch而言的，不同batch的增强强度不同，提高了模型了鲁棒性。 Conclusion Purpose: Focus more on an image’s global context instead of local information - Retention of semantic information ： Regions rich in semantic information have a greater impact on target scores than other regions - Do not add irrelevant data - Apply the different augmentation ： adapts the augmentation parameters based on the training loss of the data samples - Different samples are trained to fit their data enhancement methods 注重增强样本前后语义信息的保留：语义信息丰富的区域比其他区域对目标分数的影响更大 在使用增强技术时，我们必须确保不增加不相关的数据：不再对所有样本进行相同的增强强度 对不同的样本训练出适合他们的数据增强方式 Reference [1]Zhong, Zhun, et al. &quot; Random erasing data augmentation. &quot; Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 07. 2020. [2]DeVries, Terrance, and Graham W. Taylor. &quot;Improved regularization of convolutional neural networks with cutout.&quot; arXiv preprint arXiv:1708.04552 (2017). [3]Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412, 2017 [4]Hendrycks, Dan, et al. &quot;Augmix: A simple data processing method to improve robustness and uncertainty.&quot; arXiv preprint arXiv:1912.02781 (2019). [5]T. Iqbal, K. Helwani, A. Krishnaswamy and W. Wang, &quot;Enhancing Audio Augmentation Methods with Consistency Learning,&quot; ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2021, pp. 646-650. [6]Gong, Chengyue, et al. &quot;Keepaugment: A simple information-preserving data augmentation approach.&quot; Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021. [7]T. -Y. Hu et al., &quot;SapAugment: Learning A Sample Adaptive Policy for Data Augmentation,&quot; ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2021, pp. 4040-4044. ","link":"https://kimokcheon.github.io/post/shu-ju-zeng-qiang-lun-wen-chuan-jiang/"},{"title":"Linux下C++文件操作","content":"GCC编译器 安装 sudo apt update # 通过以下命令安装编译器和调试器 sudo apt install build-essential gdb # 以下命令确认每个软件是否安装成功 # 如果成功，则显示版本号 gcc --version g++ --version gdb --version 利用g++分步编译cpp # -E 选项指示编译器仅对输入文件进行预处理 g++ -E test.cpp -o test.i //.i文件 # -S 编译选项告诉 g++ 在为 C++ 代码产生了汇编语言文件后停止编译 # g++ 产生的汇编语言文件的缺省扩展名是 .s g++ -S test.i -o test.s # -c 选项告诉 g++ 仅把源代码编译为机器语言的目标代码 # 缺省时 g++ 建立的目标代码文件有一个 .o 的扩展名。 g++ -c test.s -o test.o # -o 编译选项来为将产生的可执行文件用指定的文件名 g++ test.o -o test 重要的编译参数 # -g 选项告诉 GCC 产生能被 GNU 调试器GDB使用的调试信息，以调试程序。 # 产生带调试信息的可执行文件test g++ -g test.cpp ## 所谓优化，例如省略掉代码中从未使用过的变量、直接将常量表达式用结果值代替等等，这些操作 会缩减目标文件所包含的代码量，提高最终生成的可执行文件的运行效率。 # -O 选项告诉 g++ 对源代码进行基本优化。这些优化在大多数情况下都会使程序执行的更快。 -O2 选项告诉 g++ 产生尽可能小和尽可能快的代码。 如-O2，-O3，-On（n 常为0–3） # -O 同时减小代码的长度和执行时间，其效果等价于-O1 # -O0 表示不做优化 # -O1 为默认优化 # -O2 除了完成-O1的优化之外，还进行一些额外的调整工作，如指令调整等。 # -O3 则包括循环展开和其他一些与处理特性相关的优化工作。 # 选项将使编译的速度比使用 -O 时慢， 但通常产生的代码执行速度会更快。 # 使用 -O2优化源代码，并输出可执行文件 g++ -O2 test.cpp # -l参数(小写)就是用来指定程序要链接的库，-l参数紧接着就是库名 # 在/lib和/usr/lib和/usr/local/lib里的库直接用-l参数就能链接 # 链接glog库 g++ -lglog test.cpp # 如果库文件没放在上面三个目录里，需要使用-L参数(大写)指定库文件所在目录 # -L参数跟着的是库文件所在的目录名 # 链接mytest库，libmytest.so在/home/bing/mytestlibfolder目录下 g++ -L/home/bing/mytestlibfolder -lmytest test.cpp # -I # /usr/include目录一般是不用指定的，gcc知道去那里找，但 是如果头文件不在/usr/icnclude 里我们就要用-I参数指定了，比如头文件放在/myinclude目录里，那编译命令行就要加上I/myinclude 参数了，如果不加你会得到一个”xxxx.h: No such file or directory”的错 误。-I参数可以用相对路径，比如头文件在当前 目录，可以用-I.来指定。上面我们提到的–cflags参 数就是用来生成-I参数的。 g++ -I/myinclude test.cpp # 打印出gcc提供的警告信息 g++ -Wall test.cpp # 关闭所有警告信息 g++ -w test.cpp # 使用 c++11 标准编译 test.cpp g++ -std=c++11 test.cpp # 指定即将产生的文件名 # 指定输出可执行文件名为test g++ test.cpp -o test 编译举例 # 最初目录结构 . ├── include │ └── Swap.h ├── main.cpp └── src └── Swap.cpp 直接编译 # 将 main.cpp src/Swap.cpp 编译为可执行文件 g++ main.cpp src/Swap.cpp -Iinclude # 运行a.out ./a.out # 将 main.cpp src/Swap.cpp 编译为可执行文件 附带一堆参数 g++ main.cpp src/Swap.cpp -Iinclude -std=c++11 -O2 -Wall -o b.out # 运行 b.out ./b.out 生成库文件编译 静态库 ## 进入src目录下 $cd src # 汇编，生成Swap.o文件 g++ Swap.cpp -c -I../include # 生成静态库libSwap.a ar rs libSwap.a Swap.o ## 回到上级目录 $cd .. # 链接，生成可执行文件:staticmain g++ main.cpp -Iinclude -Lsrc -lSwap -o staticmain 动态库 ## 进入src目录下 $cd src # 生成动态库libSwap.so g++ Swap.cpp -I../include -fPIC -shared -o libSwap.so ## 上面命令等价于以下两条命令 # gcc Swap.cpp -I../include -c -fPIC # gcc -shared -o libSwap.so Swap.o ## 回到上级目录 $cd .. # 链接，生成可执行文件:sharemain g++ main.cpp -Iinclude -Lsrc -lSwap -o sharemain GDB调试器 $(gdb)help(h) # 查看命令帮助，具体命令查询在gdb中输入help + 命令 $(gdb)run(r) # 重新开始运行文件（run-text：加载文本文件，run-bin：加载二进制文 件） $(gdb)start # 单步执行，运行程序，停在第一行执行语句 $(gdb)list(l) # 查看原代码（list-n,从第n行开始查看代码。list+ 函数名：查看具体函 数） $(gdb)set # 设置变量的值 $(gdb)next(n) # 单步调试（逐过程，函数直接执行） $(gdb)step(s) # 单步调试（逐语句：跳入自定义函数内部执行） $(gdb)backtrace(bt) # 查看函数的调用的栈帧和层级关系 $(gdb)frame(f) # 切换函数的栈帧 $(gdb)info(i) # 查看函数内部局部变量的数值 $(gdb)finish # 结束当前函数，返回到函数调用点 $(gdb)continue(c) # 继续运行 $(gdb)print(p) # 打印值及地址 $(gdb)quit(q) # 退出gdb $(gdb)break+num(b) # 在第num行设置断点 $(gdb)info breakpoints # 查看当前设置的所有断点 $(gdb)delete breakpoints num(d) # 删除第num个断点 $(gdb)display # 追踪查看具体变量值 $(gdb)undisplay # 取消追踪观察变量 $(gdb)watch # 被设置观察点的变量发生修改时，打印显示 $(gdb)i watch # 显示观察点 $(gdb)enable breakpoints # 启用断点 $(gdb)disable breakpoints # 禁用断点 $(gdb)x # 查看内存x/20xw 显示20个单元，16进制，4字节每单元 $(gdb)run argv[1] argv[2] # 调试时命令行传参 $(gdb)set follow-fork-mode child#Makefile项目管理：选择跟踪父子进程（fork()） CMake 安装 # 通过以下命令安装编译器和调试器 sudo apt install cmake # 确认是否安装成功 # 如果成功，则显示版本号 cmake --version 重要指令 # CMake最小版本要求为2.8.3 cmake_minimum_required(VERSION 2.8.3) # 指定工程名为HELLOWORLD project(HELLOWORLD) # 定义SRC变量，其值为sayhello.cpp hello.cpp set(SRC sayhello.cpp hello.cpp) # 将/usr/include/myincludefolder 和 ./include 添加到头文件搜索路径 include_directories(/usr/include/myincludefolder ./include) # 将/usr/lib/mylibfolder 和 ./lib 添加到库文件搜索路径 link_directories(/usr/lib/mylibfolder ./lib) # 通过变量 SRC 生成 libhello.so 共享库 add_library(hello SHARED ${SRC}) # 添加编译参数 -Wall -std=c++11 -O2 add_compile_options(-Wall -std=c++11 -O2) # 编译main.cpp生成可执行文件main add_executable(main main.cpp) # 将hello动态库文件链接到可执行文件main target_link_libraries(main hello) # 添加src子目录，src中需有一个CMakeLists.txt add_subdirectory(src) # 定义SRC变量，其值为当前目录下所有的源代码文件 aux_source_directory(. SRC) # 编译SRC变量所代表的源代码文件，生成main可执行文件 add_executable(main ${SRC}) # 在CMAKE_CXX_FLAGS编译选项后追加-std=c++11 set( CMAKE_CXX_FLAGS &quot;${CMAKE_CXX_FLAGS} -std=c++11&quot;) # 设定编译类型为debug，调试时需要选择debug set(CMAKE_BUILD_TYPE Debug) # 设定编译类型为release，发布时需要选择release set(CMAKE_BUILD_TYPE Release) 构建方法 内部构件 ## 内部构建 # 在当前目录下，编译本目录的CMakeLists.txt，生成Makefile和其他文件 cmake . # 执行make命令，生成target make 外部构建 ## 外部构建 # 1. 在当前目录下，创建build文件夹 mkdir build # 2. 进入到build文件夹 cd build # 3. 编译上级目录的CMakeLists.txt，生成Makefile和其他文件 cmake .. # 4. 执行make命令，生成target make CMake代码实践 最小CMake工程 # Set the minimum version of CMake that can be used cmake_minimum_required(VERSION 3.0) # Set the project name project (HELLO) # Add an executable add_executable(hello_cmake main.cpp) 多目录工程 - 直接编译 # Set the minimum version of CMake that can be used cmake_minimum_required(VERSION 3.0) #project name project(SWAP) #head file pat include_directories( include ) #source directory files to var add_subdirectory( src DIR_SRCS ) #add executable file add_executable(swap_02 ${TEST_MATH}) #add link library target_link_libraries(${FS_BUILD_BINARY_PREFIX}sqrt ${LIBRARIES}) 多目录工程 - 生成库编译 # Set the minimum version of CMake that can be used cmake_minimum_required(VERSION 3.0) #project name project(SWAP_LIBRARY) #add compile options add_compile_options(&quot;-Wall -std=c++11&quot;) #set CMAKE_BUILD_TYPE set( CMAKE_BUILD_TYPE Debug ) # set output binary path set(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin) ############################################################ # Create a library ############################################################ #Generate the static library from the library sources add_library( swap_library STATIC src/Swap.cpp ) target_include_directories( swap_lib PUBLIC ${PROJECT_SOURCE_DIR}/include ) ############################################################ # Create an executable ############################################################ # Add an executable with the above sources add_executable( swap_01 main.cpp ) # link the new swap_01 target with the swap_lib target target_link_libraries( swap_01 swap_liby ) ","link":"https://kimokcheon.github.io/post/linux-xia-cwen-jian-cao-zuo/"},{"title":"Effective Modern C++学习笔记","content":"Effective Modern C++学习笔记 1、型别推导 条款01、理解模板型别推导 函数模板形如： template&lt;typename T&gt; void f(ParamType param); f(expr)//调用 编译器通过expr推导两个型别，即T、ParamType 情况1：ParamType 是指针或引用，但不是万能引用 template&lt;typename T&gt; void f(T&amp; param) //void f(T* param) const char name[]=&quot;Lucas&quot;; f(name);//T:const char [6],param:const char&amp; [6] template&lt;typename T,std::size_t N&gt; constexpr std::size_t arraySize(T (&amp;)[N])noexcept{//数组形参未取名字 return N; } std::array&lt;int,arraySize(name)&gt;map;//编译期推导元素个数 特性：T保留常量性，忽略引用性。可以推导出数组型别！ template&lt;typename T&gt; void f(const T&amp; param) 此时T型别推导不会包含const 情况二：ParamType 是万能引用 template&lt;typename T&gt; void f(T&amp;&amp; parma) int x=27; const int cx=x; const int&amp; rx=x; f(x);//T:int&amp;,param:int&amp; f(cx);//T:const int&amp;,param:const int&amp; f(rx);//T:const int&amp;,param:const int&amp; f(27);//T:int,param:int &amp;&amp; 情况三：ParamType 既非指针也非引用 template&lt;typename T&gt; void f(T param); int x=27; const int cx=x; const int&amp; rx=x; const char* const ptr=&quot;Fun with pointers&quot;; f(x);//T:int,param:int f(cx);//T:int,param:int f(rx);//T:int,param:int f(ptr);//T:const char *,param:const char * 忽略const和volatile，但保留指针指向对象的cv特性。数组与函数都会推导为对应指针。 条款2：理解auto型别推导 auto相当于T，变量的型别相当于ParamType ​ 唯一区别：auto会假定用大括号括起的初始化表达式代表一个std::initiallizer_list，但模板型别推导不会。 在函数返回值以及lambda式形参中使用auto，意思是使用模板型别推导。 条款3：理解decltype decltype返回给定名字或表达式的确切型别 主要用途在于声明那些返回值型别依赖于形参型别的函数模板 template&lt;typename Container,typename Index&gt; decltype(auto) authAndAccess(Container&amp;&amp; c,Index i){ authenticateUser(); return std::forward&lt;Container&gt;(c)[i]; } 2、auto 条款5：优先选用auto，而非显式型别声明 用例： auto derefLess = [](const auto&amp; p1,const auto&amp; p2){ return *p1&lt;*p2; } std::unordered_map&lt;std::string,int&gt;m; for(const auto&amp;p:m){...} 但是要防止写出： auto someVar = “隐形”代理型别表达式; //例： std::vector&lt;bool&gt; features(const Widget&amp; w); Widget w; auto highPriority=features(w)[5];//highPriority类型为std::vector&lt;bool&gt;::reference而不是bool! //强制转换解决 auto sum=static_cast&lt;Matrix&gt;(m1+m2+m3+m4); 3、转向现代C++ 条款7：在创建对象时注意区分（）和 {} {}特性：统一性、禁止隐式窄化型别转换、调用没有形参的构造函数 与（）典型区别 std::vector&lt;int&gt; v1(10,20);//10个元素，值全为20 std::vector&lt;int&gt; v2{10,20};//2个元素，10、20 条款8：优先选用nullptr 相对于0或NULL，优先选用nullptr 避免在整型和指针型别之间重载 条款9：优先选用别名声明，而非typedef typedef不支持模板化，但using支持 条款10：优先选用限定作用域的枚举型别，而非不限作用域的枚举型别 enum class Color{black,white,red}; auto white=false; Color c=Color::white; auto c=Color::white; 限定作用域的枚举型别总是可以进行前置声明。 条款11：优先选用删除函数，而非private未定义函数 template&lt;&gt; void processPointer&lt;void&gt;(void*)=delete; 任何函数都可以删除，包括非成员函数和模板具现。 条款12：为意在改写的函数添加override声明，意在禁止用作基类的函数添加final声明 条款13：优先选用const_iterator template&lt;typename C,typename V&gt; void findAndInsert(C&amp; container,const V&amp; targetVal,const V&amp; insertVal){ using std::cbegin; using std:cend; auto it=std::find(cbegin(container),cend(container),targetVal); container.insert(it,insertVal); } 条款14：只要函数不会发射异常，就为其加上noexcept声明 条款15：只要有可能使用constexpr，就使用它 条款16：保证const成员函数的线程安全性 引入mutex防止data race class Polynomial{ public: using RootsType = std::vector&lt;double&gt;; RootsType roots() const{ std::lock_guard&lt;std::mutex&gt;g(m); if(!rootAreValid){ ... rootsAreValid = true; } return rootVals; } private: mutable std::mutex m; mutable bool rootsAreValid{false}; mutable RootsType rootVals{}; }; 使用std::atomic成本更低，但如果有两个或更多变量或内存区域需要作为一整个单位进行操作时，就要使用互斥量。 class Point{ public: ... double distanceFromOrigin() const noexcept{ ++callCount; return std::sqrt((x*x)+(y*y)); } private: mutable std::atomic&lt;unsigned&gt; callCount{0}; double x,y; }; 4.智能指针 条款18：使用std:unique_ptr管理具备专属所有权的资源 std::unique_ptr是小巧、高速、具备只移型别的智能指针，对托管资源实施专属所有权语义。 可以直解通过std::shared_ptr&lt;…&gt;强制转换 条款19：使用std::shared_ptr管理具备共享所有权资源 share_ptr是unique_ptr尺寸的两倍，还会带来控制块的开销，并要求原子化的引用计数操作。 避免使用裸指针型别的变量创建std::shared_ptr 条款20：对于类似std::shared_ptr但有可能空悬的指针使用std::weak_ptr std::weak_ptr可能的用武之地包括缓存、观察者列表，以及避免std::shared_ptr指针环路（非严格继承谱系） 条款21：优先选用std::make_unique和std::make_shared，而非直接使用new auto upw1(std::make_unique&lt;Widget&gt;()); auto spw1(std::make_shared&lt;Widget&gt;()); 在需要定制删除器以及期望直接传递大括号初始化物时，不建议使用make系列函数 条款22：使用Pimpl习惯用法时，将特殊成员函数的定义放到实现文件中 Pimpl技巧：把某类的数据成员用一个指涉到某实现类的指针替代，然后把原来在主类中的数据成员放置到实现类中，并通过指针间接访问这些数据成员。 class Widget{ //位于头文件“widget.h&quot;中 public: widget(); ~widget(); widget(Widget&amp;&amp; rhs); Widget&amp; operator=(Widget&amp;&amp; rhs); Widget(const Widget&amp; rhs); Widget&amp; operator=(const Widget&amp; rhs); private: struct Impl; std::unique_ptr&lt;Impl&gt;pImpl; } #include &quot;widget.h&quot; //位于头文件“widget.cpp”中 #include &quot;gadget.h&quot; #include &lt;string&gt; #include &lt;vector&gt; struct Widget::Impl{...}; Widget::Widget():pImpl(std::make_unique&lt;Impl&gt;()){}; Widget::~Widget()=default; Widget::Widget(Widget&amp;&amp; rhs)=default; Widget&amp; Widget::operator=(Widget&amp;&amp; rhs)=default; Widget::Widget(const Widget&amp; rhs):pImpl(std::make_unique&lt;Impl&gt;(*rhs.pImpl)){} Widget&amp; Widget::operator=(const Widget&amp;rhs){ *pImpl=*rhs.pImpl; return *this; } 使用#include指令包含widget.h后客户代码如下: #include &quot;widget.h&quot; Widget w1; auto w2(std::move(w1)); w1=std::move(w2); ... 5、右值引用、移动语义和完美转发 条款23：理解std::move和std::forward std::move和std::forward都仅仅执行强制型别转换的函数模板，std::move无条件将实参强制转换为右值，而std::forword则仅在某个特定条件满足时才执行同一个强制转换，在运行期，两者都不会做任何操作。 move:如果想让某个对象执行移动操作的能力，则不要将其声明为常量 template&lt;typename T&gt; decltype(auto) move(T&amp;&amp; param){ using ReturnType = remove_reference_t&lt;T&gt;&amp;&amp;; return static_cast&lt;ReturnType&gt;(param); } forward:当且仅当用来初始化param的实参是个右值的条件下，把param强制转换成右值型别。 template&lt;typename T&gt; T&amp;&amp; forward(remove_reference_t&lt;T&gt;&amp; param){ return static_cast&lt;T&amp;&amp;&gt;(param); } 条款25：针对右值引用实施std::move，针对万能引用实施std::forward 针对右值引用的最后一次使用实施move，针对万能引用的最后一次使用实施forward 若局部对象可能适用于返回值优化，则请勿针对其实施move或forward 条款26：避免依万能引用型别进行重载 把万能引用作为重载候选型别，几乎总会让该重载版本在始料未及的情况下被调用到 完美转发构造函数的问题尤为严重，它们会劫持派生类中对基类的复制和移动构造函数的调用 替代方案包括使用彼此不同的函数名字、传递const T&amp;型别的形参、传值和标签分派 条款28：理解引用折叠 如果任一引用为左值引用，则结果为左值引用。否则为右值引用。（两&amp;消去） 条款30：熟悉完美转发的失败情形 大括号初始化物。但可以通过auto声明局部变量，然后将该局部变量传递给转发函数 0和NULL作空指针，可以改为nullptr 仅有声明的整型static const 成员变量 重载的函数名字和模板名字 位域 6、lambda 表达式 条款31：避免默认捕获模式 按引用捕获可能导致空悬引用。一旦由lambda式所创建的闭包越过了该局部变量或形参的生命期，那么闭包内的引用就会空悬。 template&lt;typename C&gt; void workWithContainer(const C&amp; container){ auto calc1=computeSomeValue1(); auto calc2=computeSomeValue2(); auto divisor=computeDivisor(calc1,calc2); using std::begin; using std::end; if(std::all_of(begin(container),end(container), //注意不能超过divisor的生命周期 [&amp;](const auto&amp; value){ return value%divisor==0; }) ){ ... } else { ... } } 按值捕获只能针对于在创建lambda式的作用域可见的非静态局部变量（包括形参），依然可能会空悬。 filters.emplace_back([=](int value){return value%divisor==0;}); 条款32：使用初始化捕获将对象移入闭包 auto func=[pw=std::make_unique&lt;widget&gt;()]{ return pw-&gt;isValidated()&amp;&amp;pw-&gt;isArchived(); }; 条款33：对auto&amp;&amp;型别的形参使用decltype，以std::forward之 auto f=[](auto&amp;&amp; param){ return func(normalize(std::forward&lt;decltype(param)&gt;(param))); }; auto f=[](auto&amp;&amp;... params){ return func(normalize(std::forward&lt;decltype(params)&gt;(params)...)); };//接受多个形参 补充：c++20起lambda可以使用模板 ![2022-09-25 19-44-07 的屏幕截图](/home/rack/笔记/Effective C++/2022-09-25 19-44-07 的屏幕截图.png) // generic lambda, operator() is a template with two parameters auto f = []&lt;class T&gt;(T a, auto&amp;&amp; b) { return a &lt; b; }; // generic lambda, operator() is a template with one parameter pack auto f = []&lt;typename... Ts&gt;(Ts&amp;&amp;... ts) { return func(std::forward&lt;Ts&gt;(ts)...); }; 7、并发API 条款35：优先选用基于任务而非基于线程的程序设计 基于线程： int doAsyncWork(); std::thread t(doAsyncWork); 基于任务： auto fut = std::async(doAsyncWork); 条款36：如果异步是有必要的，则指定std::launch::async std::launch::async启动策略意味着函数必须以异步方式运行，即在另一线程之上执行 std::launch::deferred启动策略意味函数只会在std::async所返回的期值的get或wait得到调用时才运行。 std::async的默认启动策略是上述两者进行或运算的结果 auto fut = std::async(std::launch::async, f); 条款40：对并发使用std::atomic，对特种内存使用volatile 将第一个任务的可用性传递给第二个任务 std::atomic&lt;bool&gt; valAvailable(false); auto imptValue = computeImportantValue(); valAvailable = true; std::atomic型别对象的运用会对代码可以如何重新排序施加限制 std::atimic的复制操作被删除了，且移动操作没有显式声明，可以从x中取值并置入y中 std::atomic&lt;int&gt; x; std::atomic&lt;int&gt; y(x.load()); y.store(x.load()); 常规内存：如果你向某个内存位置写入例值，该值会一直保留在那里，直到它被覆盖为止 auto y = x; y = x; x = 10; x = 20; 编译器可以径自把这段代码视作如下代码 auto y = x; x = 20; 特种内存：常用于内存映射I/O，如于外部设备（外部传感器、显示器、打印机和网络端口）通信，而非读入或写入常规内存（即RAM） 而volatile的用处就是告诉编译器，正在处理的是特种内存，不要对在此内存上的操作做任何优化。 8、微调 条款41：针对可复制的形参，在移动成本低并且一定会被复制的前提下， 考虑将其按值传递 经由构造复制形参的成本可能比经由赋值复制形参高出很多。 按值传递肯定会导致切片问题，所有基类型别特别不适用于按值传递！！！ class Widget{...}; class SpecialWidget: public Widget {...}; void processWidget(Widget w); SpecialWidget sw; processWidget(sw); //processWidget看到的只是一个Widget而非SpecialWidget类型的对象！ 条款42：考虑置入而非插入 置入函数在以下几个前提成立时，极有可能会运行得更快： 待添加的值是以构造而非赋值方式加入容器 传递的实参型别与容器持有之物的型别不同 容器不会由于存在重复值而拒绝待添加的值 置入函数可能会执行在插入函数中会被拒绝的型别转换，所以使用置入函数时，要特别小心去保证传递了正确的实参。 ","link":"https://kimokcheon.github.io/post/effective-modern-cxue-xi-bi-ji/"},{"title":"Effective C++学习笔记","content":"Effective C++学习笔记 偷一手展鹏的笔记 1、让自己习惯C++ 条款02、替换掉define 1、单纯常量用const替换define 2、对于形似函数的宏，用inline代替define 条款03、尽可能多使用const： 1、const用法： const char*p;//const data char const *p;//const data char *const p;//const pointer const char *const p;//const data,const pointer const std::vector&lt;int&gt;::iterator iter;//const data std::vector&lt;int&gt;::const_iterator Citer;//const pointer 2、当const和non-const实质等价时，令non-const版本调用const版本可以避免代码重复 条款04、确保对象在使用时已被初始化 1、构造函数最好使用成员初值列，而不在构造函数里使用赋值 2、为免除“跨编译单元之初始化次序”问题，用local static替换non-local static（Singleton模式）： 将non-local static对象搬到专属函数内，这些函数返回reference指向它所含的对象。 若被频繁调用，可以inline 解决多线程下“等待某事发生”的麻烦，可以在单线程启动阶段手动调用所有reference-returning函数 2、构造/析构/赋值运算 条款06、明确拒绝不想使用编辑器自动生成的函数 将对应成员函数声明为private并不予实现 条款07、为多态基类声明virtual析构函数 若为具备多态性的基类（polymorphic base classes）必须声明virtual析构函数，否则不要声明 条款09、不在构造和析构过程中调用virtual函数 条款10、令operator=（+=、-=、*=）返回一个reference to *this 可以实现连锁形式 条款11、在operator=中处理“自我赋值” 写法一： class Widget { ... void swap(Widget&amp; rhs);//交换*this和rhs ... }; Widget&amp; Widget::operator=(const Widget&amp; rhs) { Widget temp(rhs); swap(temp); return *this; } 写法二： Widget&amp; Widget::operator=(Widget rhs) {//关键是这里是pass by value swap(rhs); return *this; } 3、资源管理 条款13，14，15、以对象管理资源（RAII:资源获取时机便是初始化时机） 1、auto_ptr智能指针使用 void f(){ ... std::auto_ptr&lt;...&gt;p(create()); ... } 由于auto_ptr被销毁后会自动删除所指之物，所以一定要注意别让多个auto_ptr指向同一对象 2、RCSP（引用计数型）：tr1::shared_ptr、tr1::weak_ptr(不计入计数的计算) void f() { ... std::tr1::shared_ptr&lt;...&gt;p(create()); ... } 但它们的析构函数内都是delete，而不是delete[]，若需要”动态分配数组“，可以使用vector和string 3、以RAII原则建立资源管理类。对于非heap-based的资源（无法使用智能指针），RAII原则提倡：抑制copying、施行引用计数法 4、若遇到直接访问资源的APIs，需要将智能指针转化为指针，显式转换更安全，隐式转换对用户更方便。 显式转换方法(智能指针自带get()函数)： class A { public: ... B get() const {return f;} ... } A f(...); change(f.get()); 隐式转换方法： class A { public: ... operator B() const {return f;} ... } A f1(...); B f2 = f1; 条款16：new和delete对应 new对应delete，new[]对应delete[] 条款17：以独立语句将newed的对象置入智能指针 4、设计与声明 条款20：尽量以pass-by-reference-to-const替换pass-by-value 1、前者更加高效，且可以避免对象切割问题（derived class对象特性切割，仅留下base class的错误） 2、以上规则不适用于内置类型，STL迭代器和函数对象。对它们而言，pass-by-value往往比较适当 条款21：必须返回对象时，不要返回其reference 条款22：将成员变量声明为private 1、不封装意味着不可改变，愈多东西被封装，我们改变那些东西的能力就越大。 2、越是广泛使用的class越需要封装，这样才能从改用一个较佳实现版本中收益。 3、protected并不比public更具有封装性 条款23：宁以non-member、non-friend替换member函数 1、member函数封装性低于non-member、non-friend。 2、让函数“成为class的non-member”并不意味它不可以是另一个class的member，比较自然的做法是将这个non-member函数位于class所在的同一个namespace中。 我们称之为“便利函数”，namespace是可以跨文件的,故可以将不同类型的便利函数写于不同文件。 条款24：若所有参数皆需类型转换，请采用non-member函数 1、class中的operator运算符重载只有当参数位于参数列内，这个参数才是隐式类型转换的合格参与者。 2、当operator成为non-member函数时，便允许编译器在每一个实参身上执行隐式类型转换 class Rational { ... }; const Rational operator*(const Rational&amp; lhs, const Rational&amp; rhs){ return Rational(lhs.numerator() * rhs.numerator(), lhs.denominator() * rhs.denominator()); } 条款25：写出不抛异常的swap函数 1、swap原是STL一部分，现在成为异常安全性编程的脊柱，以及用来成为处理自我赋值可能性的一个常见机制（见条款11） 标准程序库提供的swap namespace std { template&lt;typename T&gt; void swap(T &amp;a, T &amp;b){ T temp(a); a = b; b = temp; } } 但对于某些类型，这些复制过于慢了，改进方法中的典型是“pimpl手法”（pointer to implementation)，如针对指针全特化 class A { public: ... void swap(A &amp;other){ using std::swap; swap(pImpl, other.pImpl);//核心是化为指针swap加速 } ... } namespace std { template&lt;&gt; void swap&lt;A&gt;(A &amp;a,A &amp;b){ //swap(a.pImpl,b.pImpl);无法通过编译，访问private a.swap(b); } } 但假如A是class templates而不是class时，对function templates偏特化是行不通的 namespace std { template&lt;typename T&gt; void swap&lt; A&lt;T&gt; &gt;(A&lt;T&gt;&amp;a,A&lt;T&gt;&amp;b){//对std::swap偏特化 a.swap(b); } }//错误，不合法 namespace B { ... template&lt;typename T&gt; class A{...};//同前，内含swap成员函数 ... template&lt;typename T&gt; void swap(A&lt;T&gt; &amp;a,A&lt;T&gt; &amp;b){//non-member swap函数 a.swap(b); //并不属于std命名空间 } } 对于调用swap的函数而言，需要查找到合适的swap版本（调用T专属版本，并在该版本不存在时调用std内的[特化版&gt;一般化]版本） template&lt;typename T&gt; void doSomething(T &amp;obj1, T &amp;obj2){ using std::swap;//让std::swap在函数内曝光，可以针对T将std::swap特化，特化版会优先与一般化版本选中 ... swap(obj1, obj2);//赤裸裸调用swap！ ... } 2、注意成员版的swap绝不可抛出异常。自定义的swap往往提供的不仅是高效置换对象值的办法，而且不抛出异常，这两个特性是连在一起的。 5、实现 条款26：尽可能延后变量定义式的出现 条款27：尽可能少做转型动作 1、尽量用新式转型 转型风格： (T)expression//旧式转型 const_cast&lt;T&gt;(expression)//常量性转除 dynamic_cast&lt;T&gt;(expression)//安全向下转型 static_cast&lt;T&gt;(expression)//强迫隐式转换 2、如果转型是必要的，试着将它隐藏于某个函数背后 条款28：避免返回handles指向对象内部成分 1、避免返回handles指向对象内部可以增加封装性，且将发生“虚吊号码牌”可能性降到最低。 成员函数返回reference时，private的成员变量封装性相当于public，即使成员函数为const，也可以被修改 handle不一定比所指对象更长寿，可能会导致虚吊 条款30：透彻了解inline 1、将inline限制在小型、被频繁调用的函数上。”82法则“平均一个程序将80%的执行时间花费在20%的代码上。 2、不要只因为function templates出现在头文件，就将它们声明为inline 条款31：将编译依存关系降到最低 1、相依于声明式，不要相依于定义式，其手段有Handle classes和Interface classes，可以解除接口和实现之间的耦合关系 C++没有将接口从实现中分离，如果头文件中任何一个改变，或头文件所依赖的其他头文件有任何改变，那么有依存关系的所有文件都将重新编译！ Handle classes： 将一个类分为两个类，一个只提供接口，另一个负责实现接口。 尽量以class声明式替换class定义式 为声明式和定义式提供不同的头文件，包含声明式的头文件一般命名为“...fwd.h&quot;（针对template声明式，c++提供了关键词export） #include&quot;A.h&quot; #include&quot;AImpl.h&quot; A::A(...):pImpl(new AImple(...)){} ... A::B()const{ return pImpl-&gt;B(); } Interface class 令Person(举例)成为一种特殊的abstract base class，通常不带成员变量，没有构造函数，只有一个virtual析构函数，和一组pure virtual函数，用来叙述整个接口，并通常调用一个特殊函数（下面的create），此函数扮演”真正将被具现化“的那个derived classes的构造函数角色，通常称为factory function，且往往在interface class中被声明为static。 class Person{ public: virtual ~Person(); virtual std::string name() const=0; virtual std::string address() const=0; static std::tr1::shared_ptr&lt;Person&gt;create(const std::string&amp; name,cosnt Date&amp; birthday,const Address&amp; addr); ... }; class RealPerson:public Person{ public: RealPerson(const std::string&amp; name, const Date&amp; birthday,const Address&amp; addr) :theName(name),theBirthDay(birthday),theAddress(addr){} virtual ~RealPerson(){} std::string name() const; std::string birthDate() const; std::string address() const; private: std::string theName; Date theBirthDate; Address theAddress; } std::tr1::shared_ptr&lt;Person&gt; Person::create(const std::string&amp; name,cosnt Date&amp; birthday,const Address&amp; addr){ return std::tr1::shared_ptr&lt;Person&gt;(new RealPerson(name,birthday,addr)); } int main(){ std::string name; Date dateOfBirth; Address address; ... std::tr1::shared_ptr&lt;Person&gt;pp(Person::create(name,dateOfBirth,address)); ... std::cout &lt;&lt; pp-&gt;name() &lt;&lt; &quot; was born on &quot; &lt;&lt; pp-&gt;birthDate() &lt;&lt; &quot; and now lives at &quot; &lt;&lt; pp-&gt;address(); ... } 6、继承与面向对象设计 条款32：确保public继承塑模出is-a关系 条款33：避免遮掩继承而来的名称 1、derived classes内的名称会遮掩base classes内的名称 2、为了让被遮掩的名称再见天日，可使用using声明式或转交函数 class B:public A{ public: using A::f1; using A:f3; virtual void f1(); void f3(); virtual void f2(){A::f2();} ... }; 条款34：区分接口继承和实现继承 1、pure virtual函数只具体指定接口继承 条款35：考虑virtual函数以外的其他选择 1、Template Method设计模式的表现形式non-virtual interface（NVI)：让public函数成为non-virtual(称为wrapper)，并调用一个private virtual函数进行实际工作 class A{ public: int B() const{ ... B_dosomething(); ... } private: virtual ... B_dosomething() const { ... } }; NVI手法可以在derived classes重新定义private virtual函数，但并不会调用！当virtual函数必须是public时不能使用该手法（如析构函数） 2、由Function Pointers实现Strategy设计模式（扩展内容较多，具体见设计模式） 简而言之，函数不再是类继承体系内的成员函数，而是通过指针调用，也就意味着这些函数并未特别访问对象的内部成分 优点：每个对象可以拥有自己的函数、可以在运行期改变函数 缺点：为了获得部分non-public成员变量必须降低封装性 通过tr1::function替换指针，可以允许用户用任何兼容的可调用物代替函数，所谓兼容指参数和返回类型可以被隐式转换为之前的形式 条款36：绝不重新定义继承而来的non-virtual函数 条款37：绝不重新定义继承而来的缺省参数值 缺省函数值永远是静态绑定！ 条款38：通过组合塑模出has-a或“is-implemented-in-terms-of” 1、在应用域（如人、汽车、视频画面），组合意味has-a。在实现域（如缓冲区、互斥器、查找树），组合意味is-implemented-in-terms-of 条款39：明智而审慎地使用private继承 1、private继承也意味着is-implemented-in-terms-of 2、尽可能使用复合，必要时才使用private继承。当derived classes需要访问protected base class的成员，或需要重新定义继承而来的virtual函数，或需要使对象尺寸最小化时，才更适合private继承 条款40：明智而审慎地使用多重继承 1、多重继承比单一继承更复杂。可能导致歧义性，以及对virtual继承的需要。 2、合理利用public继承Interface class，private继承某个协助实现的class。 7、模板与泛型编程 条款41：了解隐式接口和编译期多态 1、显式接口指在源码中明确可见，对virtual函数调用将表现出运行期多态。而在泛型编程的世界，隐式接口和编译器多态居多，与template变量相关的表达式便是变量必须支持的隐式接口，而涉及该变量的任何函数调用，有可能造成template具现化，由于发生在编译期，称为编译期多态。 template&lt;typename T&gt; void A(T&amp;w) { if(w.size() &gt; 10 &amp;&amp; w != ...) ...//必须提供一个名为size的成员函数，且返回int，必须支持一个operator!=函数，或许&amp;&amp;也可能被重载 } 条款42：了解typename的双重意义 1、声明template参数时class和typename完全等价 2、嵌套从属名称在缺省情况下不是类型，可能导致解析困难，而typename可以告诉编译器它是一个类型，但不可以出现在base、calsses、list内的嵌套从属名称前，也不可以在成员初值列中作为base class修饰符 template&lt;typename IterT&gt; void A(IterT iter) { typedef typename std::iterator_traits&lt;IterT&gt;::value_type value_type;//traits class(见条款47) value_type A(*iter); ... } 条款43：学习处理模板化基类内的名称 1、解析 derived class template定义式时，编译器对base classes template内容毫无所悉-----可能存在特化版本。可以在base class函数调用前加上this-&gt;或using声明式告诉编译器存在该函数。 条款44：将于参数无关的代码抽离templates 1、任何template都不该与某个造成膨胀的template参数产生相依关系。 2、通过以函数参数或class成员变量替换template参数可以消除因非类型模板参数而造成的代码膨胀。 3、参数类型造成的代码膨胀可以通过让带有完全相同二进制表述的具体类型共享实现码降低。 条款46：需要类型转换时请为模板定义非成员函数 1、template实参推导过程中从不将隐式类型转换函数纳入考虑。为了让类型转换可能发生在所有实参上，我们需要non-member函数，而为了让它被自动具现化，需要把它声明在class内部，故只能声明为friend。template只声明函数而未提供定义式时，连接器找不到该函数，故只能用inline的方法。对与函数复杂的情况可以令friend函数调用辅助函数。 template&lt;typename T&gt;class Rational; template&lt;typename T&gt; const Rational&lt;T&gt; doMultiply(const Rational&lt;T&gt;&amp; lhs, const Rational&lt;T&gt;&amp; rhs) { return Rational&lt;T&gt;(lhs.numerator() * rhs.numerator(), lhs.denominator() * rhs.denominator());//此处不一定需要inline } template&lt;typename T&gt; class Rational { public: ... friend const Rational&lt;T&gt; operator*(const Rational&lt;T&gt;&amp; lhs,const Rational&lt;T&gt;&amp; rhs) { return doMultiply(lhs, rhs); } ... } 条款47：请使用traits classes表现类型信息 1、traits允许你在编译期间获取某些类型信息，可以在编译期对类型执行if...else测试。但traits技术必须也能够施行于内置类型上（如指针），而无法施行于嵌套类型。 2、习惯上，traits总是被实现为structs。 3、Traits广泛用于标准程序库（50个以上），如iterator_traits,提供iterator_category、value_type;char_traits用来保存字符类型的相关信息;numeric_limits用来保存数值类型的相关信息。Tr1导入了许多新的traits classes，包括is_fundamental(判断T是否为内置类型)，is_array(判断T是否为数组类型)，以及is_base_of&lt;T1,T2&gt;(T1和T2相同，抑或T1是T2的base class) 条款48：认识template元编程（扩展较多，详见泛型编程、模板元编程相关书籍） 1、模板元编程可将工作由运行期移往编译期，因而得以实现早期错误侦测和更高的执行效率。 8、定制new和delete 条款49：了解new-handler行为 1、set_new_handler允许客户指定一个函数，在内存分配无法满足时调用。 2、可以建立一个”mixin”风格的base class，将则个base class转换为template，每个derived class将获得实体互异的class data复件 mixin风格：模板参数不被使用且只有static成员和函数的模板类 class A:public NewHandlerSupport&lt;A&gt; {//CPTP(怪异的循环模板模式) ... }; 条款51：编写new和delete时需固守常规 1、operator new应该内含一个无穷循环，并在其中尝试分配内存，如果它无法满足内存需求，就该调用new-handler 2、operator delete应该在收到null指针时不要做任何事。 条款52：写了placement new也要写placement delete 1、如果operator new接受的参数初了一定会有的size_t外还有其他，就称为placement new，placement delete同理。要对应着声明。 2、当你声明了placement new和placement delete，请确保不要无意识遮掩了它们的正常版本。 9、杂项讨论 条款53：不要轻忽编译器警告 1、请确保了解警告意图说出的精确意义。 条款54：让自己熟悉包括TR1在内的标准程序库 条款55：熟悉boost 1、boost是一个社群，也是一个网站。 2、它提供了许多TR1组件实现品，以及其他许多程序库。 ","link":"https://kimokcheon.github.io/post/effective-cxue-xi-bi-ji/"},{"title":"数据分析类题目的流程","content":"数据预处理 这一步是针对数据中的异常值和缺失值做出清洗和补充，常见的缺失值填充方法有：剔除法、均值法、最小邻居法等等，异常值通常是直接剔除。 数据分析 在我们建模之前一定要对数据进行数据分析，依照数据分析的结果来建模，这样才能保证我们模型最终的结果是合理的、完善的；其次一篇正规的建模论文绝对不是上来就讲解模型，而是先要分析数据，从分析中引出我们的模型这样才显得有理有据；最后数据分析这一部分能可视化数据，在论文中放上几张我们可视化的图片能使我们的文章更加美观更加有说服力。 那么常见的数据分析有以下几种： 统计性描述 统计性描述就是用一些表格和常见的图形（如折线、柱状、饼图）来描绘这批数据的均值、中位数、方差、偏度、峰度以及集中趋势和离散趋势。 正态检验 假设检验中用的比较多的是正态检验，很多模型在使用时都要求数值服从或近似服从正态分布，所以在建模前需要进行正态性检验。一般地，进行正态检验都是使用spss做P-P图、Q-Q图。 回归分析 Tips 可解释性比work重要，传统的机器学习思路比深度学习好 推式子可以用matlab辅助，让表达式精简且无错 大部分课程里面教的决策树模型比如CART、ID3等，这类模型工业界几乎不用，树模型用的最多的是GBDT、XGBoost和LightGBM。GBDT金融科技领域用的多，LightGBM目前销量预测领域用的多。 一定要有数学思想，包括模型和算法。要模型特点分析，求解结果的验证分析，查阅文献得到的重要特征和数据分析得到的特征互相应征。多元线性回归结果（基准）+神经网络比较 陈述问题除了简单的统计描述或者图形外，应当由统计规律的提取以及理由的陈述或者分析 写作不用word自带，用axmath或者mathtype（第三方编辑器），解决公式上浮 减低代码查重率，优缺点自己总结，流程步骤多流程图（重点）（降重）附件转为图片 数学建模是工程数学 ，不能太理想化 ，但也不能太复杂，一般建模是核心模型加惩罚项 注意模型对应的数据分布 一般小样本内部预测用插值和拟合，大样本内部预测用回归模型。移动平均法属于时间序列分析的内容， 时间序列分析一般用作大样本外部预测， 就是对未来的预测，灰色理论用于小样本的外部预测，神经网络用于超大样本的未来预测。可以把这些预测方法归纳一下，对于建模，主要考虑这些方法的适用性 灰色系统主要用来解决少数据的预测问题；层次分析法主要用来解决综合分析类的问题； 模糊数学可以用来做模糊综合评判， 模糊聚类分析和模糊线性规划； 蒙特卡洛方法主要是一种计算机仿真方法， 通常在排队论问题使用； 神经网路可以用来分类， 预测， 建立模型等等； .算法选择参考首当其冲应该选择的就是逻辑回归，如果它的效果不怎么样，那么可以将它的结果作为基准来参考，在基础上与其他算法进行比较;然后试试决策树(随机森林)看看是否可以大幅度提升你的模型性能。即便最后你并没有把它当做为最终模型，你也可以使用随机森林来移除噪声变量，做特征选择;如果特征的数量和观测样本特别多，那么当资源和时间充足时(这个前提很重要)，使用SVM不失为一种选择。通常情况下: GBDT&gt; =SVM&gt; = RF&gt; =Adaboost&gt; =Ote 算法固然重要，但好的数据却要优于好的算法，设计优良特征是大有裨益的。假如你有一个超大数据集，那么无论你使用哪种算法可能对分类性能都没太大影响 通过数据的初始处理发现题目所给的数据中存在空缺，对于数据的统计问题，数据的空缺是不可忽视的地方，要综合考虑空缺数据的作用以及给数据统计造成的影响大小，乔珠峰、田凤占和黄厚宽[1]等人指出：如果缺失的数据占总数据量的比例较小，认为缺失数据对原始数据的处理影响较小，可以忽略不计，如果缺失数据在总数据量中所占比例较大可能对原始数据的处理造成很大的影响，不能直接忽略，需要通过填补来完善数据才能进行计算。 对每个部分共计多少数据，缺失多少数据，删除多少数据以及剩余多少完整数据进行研究， 鼓励创新，但要切实，不要离题搞标新立异。数模创新可出现在： 建模中，模型本身，简化的好方法、好策略等； 模型求解中； 结果表示、分析、检验，模型检验； 推广部分。 ","link":"https://kimokcheon.github.io/post/shu-ju-fen-xi-lei-ti-mu-de-liu-cheng/"},{"title":"数学建模写作","content":"数学建模写作 首页：论文标题 + 摘要 + 关键词 论文标题 基于所使用的主要模型或者方法作为标题 最好不要超过20个字，但以表达准确为第一要求 摘要 1000字左右 美赛500——600词 解决了什么问题？应用了什么方法？得到了什么结果？ 大概可以分为三部分 开头段 第一句话简单交代题目背景（可选） 第二句话交代团队所做的事情 第三句话可以说解决这个问题的实际意义（少部分有） 重要性2&gt;1&gt;3 可以选择将一三句合并 中间段（分别针对各个问题进行阐述） 三要素， 即： 解决了什么问题？应用了什么方法？得到了什么结果？ (1) 解决了什么问题 直接用一句话概括我们要求解的问题（较少见到） 不单独提出我们要解决的是什么问题，因为在后面的两个要素中会提到（最常见到） 可以指出题目中的问题是什么类型的问题（极少见到） (2) 应用了什么方法 ​ 紧扣题目本身 以什么什么为目标 以什么什么为约束条件 (3) 得到了什么结果 需要计算出数值答案类——直接给出结果（可加入误差分析、灵敏度分析、置信区间等） 开放的问题——主要的结论，有明确支持的观点（有数值支撑更好）（（如果完整答案很长，可以在摘要中写出最重要的部分，然后有一句话引导读者在正文或者附录中查看完整结果）） 结尾段（可选） 可以总结全文、介绍论文亮点、也可以对类似的问题进行适当的推广 常见的废话 本文模型的结果较优-&gt;结果是···相较于···论文中的结果，在···方面提升了···% 本文用了比较好的方法-&gt; 本文的模型灵敏度较好-&gt; 关键词 ​ 关键词一般4-6个，可以放论文中的主要模型（3-5），也可以放论文里面出现次数较多，能体现论文的主要内容的词（1-2） 一、问题重述 常规做法 ​ 在原问题上采用删除替换等方式来重新组织语言 进阶做法 ​ 丰富题目背景，结合自己的分析思路来重新描述问题 二、问题分析 题目中包含的信息和条件 利用信息和条件对题目做整体分析 确定用什么方法建立模型 一般是每个问题单独分析一段 分析过程要简明扼要 不需要放置结论 建议在文字说明的同时用图形或者图表列出思维过程 三、模型假设 ​ 简化问题，使模型更加合理化 语言要严格、确切 假设是建立数学模型所必须的，最终结果与假设之间有很强的因果关系 假设应验证其合理性 可以引用别人的文献或者资料 可以使用实际数据进行绘图或者进行假设检验 常见情况 题目明确给出了假设条件 排除生活中的小概率事件 仅考虑题目中的核心元素，不考虑次要因素的影响（过于简化的模型会使得论文没有优势和亮点） 使用模型中要求的假设 对模型中的参数形式进行假设（高斯分布或者常数等）（如果能在论文中用数据验证这些假设更好） 和题目联系很紧密的一些假设，主要是为了简化模型 四、符号说明 ​ 将论文中出现的符号整合到表格中 ​ 符号——意义——单位 ​ 临时变量可以不放 ​ 下文中首次出现变量时也需要解释 五、模型准备 ​ 大部分论文没有这个部分可以介绍模型理论或者背景知识，可以整合进入模型建立里面 五、模型的建立与求解 模型的建立 ​ 自己建立模型-&gt;目标函数 + 约束条件(对约束条件进行说明) ​ 使用别人已经建立好的模型-&gt;紧密联系问题，切记无脑套用 + 用图片来介绍模型 模型的求解 如果用到了启发式算法（智能优化算法）求解的话，一定要见要写明算法步骤，并结合具体的问题来阐明计算的思路 初始可行解 新解的产生 关键函数及参数的确定 求解结果及分析 求解的结果应该在论文中突出的展示出来（有图表最好） 有具体答案的问题比较简单——直接放上数值计算结果 如果是开放类问题的话——一定要对结果进行阐明和解释 六、模型的分析与检验 模型的分析 灵敏度分析 误差分析（预测问题和数值计算类问题） 误差来源 模型的检验 使用模型之前应该进行的检验 对模型结果进行检验 七、模型的评价（、改进与推广） 模型的评价 ​ 模型的优缺点 模型的改进 ​ 针对模型中缺点哪些可以改进的地方 模型的推广 ​ 将原题的要求进行扩展，进一步讨论模型的实用性和可行性 八、参考文献 ​ 科技论文的规范列出参考文献 引用的内容需要在正文中标注出来 不要引用别人的博客（看起来不规范） 不能引用前辈论文里面的内容 九、附录 ​ ","link":"https://kimokcheon.github.io/post/shu-xue-jian-mo-xie-zuo/"},{"title":"利用WSL+Docker/原生Linux+Docker配置Linux C++课程实验环境","content":"2023 Spring年当C++实验助教的代码环境配置方案，课程主页. 本次代码环境配置方案采取WSL+docker/原生linux+docker方案进行实践环境配置，力求还原真实C++代码开发的流程与情形。编辑器/IDE推荐：VScode/Clion/Vim 为什么使用Linux+Docker Why Linux C++在Linux系统中的应用广泛: Linux是一 个开放源代码的操作系统，许多开源软件、服务器和设备都是使用C+ +编写的。学习C++在Linux系统中的应用可以帮助您更深入地了解和理解Linux系统。 开发工具支持: Linux上有许多强大的开发工具，如GNU编译器、Make工具、GDB调试器等，它们对于C++开发非常友好。通过在Linux环境下学习C++,您可以更加深入地了解这些工具的使用，提高开发效率。 系统编程: Linux系统编程是C++开发的重要领域之一。学习C++在Linux环境下的编程可以帮助您更好地了解系统编程的相关概念和技术，如进程管理、内存管理、文件操作等。 开源社区: Linux社区是一 个庞大的开源社区，拥有数以万计的开源项目。在Linux环境下学习C++可以帮助您更好地参与到开源社区中，学习和贡献更多的开源项目。 跨平台开发: C++是一种跨平台语言，可以在Windows、 Linux、 Mac OS等操作系统中运行。在Linux环境下学习C++可以帮助您更好地了解C+ +在不同操作系统中的应用和开发。 Docker Docker基本概念 Dockerr是一个用于开发、配置、运行的开放平台。Docker将应用与环境相隔离，让应用程序可以得到快速交付。 通俗地讲，Docker是一个虚拟环境容器，可以将你的开发环境、代码、配置文件一并打包放到这个容器中，并发布和应用到任意平台中。 What can Docker do? 开发：Docker可以当成轻量级的虚拟机，拥有独立的环境；折磨人的科研环境配置的过程使用docker可以大大简化 部署：利用Docker可以将程序所需的环境和配置进行打包，方便大规模部署 Why Docker 隔离性: Docker容器提供了隔离的环境，避免了应用程序之间的冲突，也可以保证应用程序的稳定性。 可移植性: Docker容器可以在任何平台上运行，包括云、物理服务器、虚拟机等。 快速部署: Docker容器可以快速地创建和部署，可以避免复杂的配置和安装流程。 资源利用率: Docker容器可以共享操作系统内核，因此它们相对于虚拟机来说更轻量级，更节省资源。 版本控制: Docker容器可以使用版本控制来管理应用程序的变更和升级，方便进行回滚和 理。 微服务架构: Docker容器适合构建微服务架构，可以将应用程序拆分成多个小的、独立的容器来管理和维护。 Docker的基本组成 Docker主要由镜像（image）、容器（container）、仓库（repositor y）这三个部分组成 一个类比： 仓库是大家上传镜像、分享镜像的地方，相当于github。dockerhub上面有一些重要的镜像 镜像——类比C++中的类模板，用于创造容器（container） 容器——类比于C++中的对象，是大家写好的类模板（镜像）的实例化 镜像（image）：利用docker将程序和程序运行所需的环境打包，得到的就是镜像。镜像本身包含了程序运行所需要的一切依赖。镜像是只读的，作为创建容器的模板存在。 容器（container）：镜像运行在容器中，每个容器都是一个独立化的实例。正如在C艹我们可以通过一个class类实例化得到很多对象一样，我们可用同一个镜像运行多个容器。容器和容器之间相互独立，互不干扰，保证运行的安全性。 Docker 常用命令 docker的基本命令 docker build ：将源代码打包形成镜像并存放在本地 docker pull : 从docker hub上拉取镜像并存放在本地 docker run : 运行镜像image，如果在本地找到了该镜像就直接启动；否则从docker hub上拉去image并启动 参数-d：后台运行 参数-p：端口映射 docker run hello-world docker run ubuntu docker run -it ubuntu:latest /bin/bash docker info: 查看docker信息，如占用空间、版本等 docker --help: 获取docker的帮助信息 docker &lt;具体命令&gt; --help ：获取docker &lt;具体命令&gt;更详细的信息 docker images: 列出所有本地镜像&amp;详细信息 参数：-a ：列出所有本地镜像，含历史映像层 参数：-q ：只显示镜像ID docker search : 搜索远程仓库是否有相应的image docker pull [:tag]: 拉取镜像 example: docker pull centos:latest docker ps ：查看运行中的容器 docker rmi [options]：删除镜像 -f : 如果image正在被停止的容器无法删除，这时加上-f这个参数就可以被强制删除 example: （删除全部）docker rmi -f $(docker images -qa) 支持同时删除多个 docker rm [Options] : 删除容器 docker exec [OPTIONS] CONTAINER COMMAND: 进入容器内部进行调试 docker save: 将镜像打包成tar包 example: docker save demo &gt; demo.tar docker load：从tar包加载一个镜像 example: docker load &lt; backend.tar docker export 容器ID &gt; 文件名.tar 导出容器内部的内容作为tar归档文件（导出整个容器并进行备份） docker import ：将export的容器恢复 Windows下安装docker与配置（WSL+Docker Desktop） 查看版本并在功能中启用WSL 这里我以我的windows台式机作为例子，参考[https://learn.microsoft.com/zh-cn/windows/wsl/install]进行安装 win+r在框中输入winver查看当前的版本，必须运行 Windows 10 版本 2004 及更高版本（内部版本 19041 及更高版本）或 Windows 11 才能使用命令安装。 安装WSL命令 在管理员模式下打开 PowerShell 或 Windows 命令提示符，方法是右键单击并选择“以管理员身份运行”，输入 wsl --install 命令 wsl --install Docker Desktop安装 进入页面https://www.docker.com/products/docker-desktop/ 下载docker desktop for windows，点击安装，安装完毕后重启。如果出现WSL Version不匹配，在管理员模式下打开 PowerShell 或 Windows 命令提示符，输入 wsl --update 然后输入 wsl --shutdown 重启docker desktop Docker网络配置 打开settings 替换成下面的文字 { &quot;builder&quot;: { &quot;gc&quot;: { &quot;defaultKeepStorage&quot;: &quot;20GB&quot;, &quot;enabled&quot;: true } }, &quot;debug&quot;: false, &quot;experimental&quot;: false, &quot;features&quot;: { &quot;buildkit&quot;: false }, &quot;insecure-registries&quot;: [], &quot;registry-mirrors&quot;: [ https://docker.mirrors.ustc.edu.cn/&quot;, https://hub-mirror.c.163.com&quot;, https://registry.docker-cn.com&quot; ] } 换源完成之后重启，打开终端 docker run hello-world 创建Docker容器 首先我们要下载镜像，然后创建容器。（容器就是我们最终需要的！） 如果你有梯子，要自己下载镜像，就用下面这种方法 使用dockerfile生成镜像 使用我们提供的dockerfile文件，cd到对应目录，我这里以桌面举例（之后环境更改后使用的dockerfile操作同理） docker build -t scucpphw_test_img . 经过下载之后，可能要等比较久 docker images 可以看到对应的镜像，说明我们安装成功了对应的docker环境。 创建容器，并进行目录映射 -v $(你的本地工作区):/ws，就是将本地工作区映射到最终环境下的/ws，类似于共享文件夹。首先你需要在windows内创建一个合适的文件夹，本节课所有的实验都是在这个文件夹内进行，这个文件夹将会跟最终容器的/ws同步，这样的好处是在删除容器后，写的代码不会丢掉 docker run -it -d -v $(你的本地工作区):/ws scucpphw_test_img:latest /bin/bash 这里我还是用桌面举例 docker run -i -d -v C:\\Users\\YuCDg\\Documents\\SCUCPP:/ws scucpphw_test_img:latest /bin/bash 输出这样的 PS C:\\Users\\YuCDg\\Desktop&gt; docker run -i -d -v C:\\Users\\YuCDg\\Desktop\\SCUCPP:/ws scucpphw_test_img:latest /bin/bash f9cc010728d26936f3c83ba6d256414ddffe3108ce3ee34c7c06139b18d67c59 PS C:\\Users\\YuCDg\\Desktop&gt; docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f9cc010728d2 scucpphw_test_img:latest &quot;/bin/bash&quot; 37 seconds ago Up 36 seconds 22/tcp vigilant_knuth PS C:\\Users\\YuCDg\\Desktop&gt; docker exec -it f9cc010728d2 /bin/bash 然后 docker ps docker exec -it f9cc010728d2 /bin/bash docker exec -it &lt;container id（我这里是f9cc010728d2）&gt; /bin/bash 上面的f9cc010728d2用你自己的container id代替 这样我们就进入了这个容器的bash，在bash中输入以下指令安装gdb与vim 安装gdb与Vim apt-get update apt-get upgrade apt-get install gdb vim 导入实验代码 先讲一下如何启动对应的docker容器 docker ps docker exec -it f9cc010728d2 /bin/bash docker exec -it &lt;container id（我这里是f9cc010728d2）&gt; /bin/bash 上面的f9cc010728d2用你自己的container id代替 进入之后 cd ws 在windows内把code复制进入ws即可 Linux下安装docker（Ubuntu为例） 如果你用windows，你就不用Linux下配置 命令安装docker 参考https://docs.docker.com/engine/install/ubuntu/ sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin sudo docker run hello-world 导入dockerfile Dockerfile简介：Dockerfile是用来构建docker镜像的文本文件。是由一条条构建镜像所需的指令和参数构成的脚本。 使用Dockerfile创造镜像的大致流程：Dockerfile——&gt;docker image ——&gt; docker container 编写Dockerfile docker build ：构建镜像 docker run ： 以镜像为基础构建容器 进入下载好dockerfile的目录 docker build -f Dockerfile -t scucpphw_test_img . docker images 显示scucpphw_test_img即为导入成功 创建docker容器并映射 docker ps docker run -it -d -v /home/yuchuan/SCUCPP:/ws scucpphw_test_img:latest /bin/bash docker exec -it 99b93e33383a /bin/bash 安装GDB与Vim apt update apt upgrade apt install gdb apt install vim 安装完成后的测试 启动docker，编辑hello_world.cpp cd /ws/code/1_helloworld/ vim hello_world.cpp 替换如下 // ========================= C++ Way ============================== #include &lt;iostream&gt; void hello_cpp() { } // ========================= C Way ============================== #include &quot;stdio.h&quot; #include &quot;stdlib.h&quot; void hello_c() { printf(&quot;%s&quot;, &quot;Hello, world!\\n&quot;); } // ========================= Assembly Way ============================== #include &quot;stdio.h&quot; #include &quot;stdlib.h&quot; /* * Wrapper function for convenience */ void myputs(char *s) { puts(s); } /* * This will probably not work on your computer. * Assembly is not at all portable; a good * reason to avoid using it! * * Those of you who have taken 107 should * be able to somewhat see what is happening here. */ int hello_as() { /* The assembly literally writes the hex representation * of as big a portion of the string as it can into the addresses * at range rsp to rsp + 0xd. That range is exactly 12 bytes long * as there are 12 characters in the &quot;Hello, wordl!&quot; string. */ // 方法1 asm(&quot;sub $0x20,%rsp\\n\\t&quot; &quot;movabs $0x77202c6f6c6c6548,%rax\\n\\t&quot; // moves &quot;Hello, w&quot; portion to mem at $rsp &quot;mov %rax,(%rsp)\\n\\t&quot; &quot;movl $0x646c726f, 0x8(%rsp)\\n\\t&quot; // moves &quot;orld&quot; portion to mem at $rsp + 8 &quot;movw $0x21, 0xc(%rsp)\\n\\t&quot; // moves &quot;!&quot; portion to mem at $rsp + 12 &quot;movb $0x0,0xd(%rsp)\\n\\t&quot; // moves string null terminator to mem at $rsp + 13 &quot;leaq (%rsp),%rax\\n\\t&quot; // loads address of $rsp as first argument to puts &quot;mov %rax,%rdi\\n\\t&quot; &quot;call _Z6myputsPc\\n\\t&quot; // calls puts &quot;add $0x20, %rsp\\n\\t&quot; ); // 方法2 char *s = &quot;Hello, wrold!&quot;; asm(&quot;mov $0x402012,%edi\\n\\t&quot; &quot;call _Z6myputsPc\\n\\t&quot; &quot;mov $0x0,%eax\\n\\t&quot; ); return EXIT_SUCCESS; } int main() { // hello_cpp(); hello_c(); hello_as(); } 保存后 g++ hello_world.cpp ./a.out 或者 ./build.sh 打印Hello, wrold!即为成功 附录 Dockerfile FROM gcc:11.2.0 RUN sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list\\ &amp;&amp; apt-get clean\\ &amp;&amp; apt-get -qq update \\ &amp;&amp; apt-get -qq install --no-install-recommends openssh-server \\ &amp;&amp; apt-get -qq install --no-install-recommends sudo \\ &amp;&amp; apt-get -qq install --no-install-recommends cmake \\ &amp;&amp; apt-get -qq install --no-install-recommends rsync \\ &amp;&amp; apt-get clean \\ &amp;&amp; rm -rf /var/lib/apt/lists/* # setup ssh for use ubuntu, password scucpp RUN useradd -rm -d /home/ubuntu -s /bin/bash -g root -G sudo -u 1000 ubuntu RUN echo 'ubuntu:scucpp' | chpasswd RUN service ssh start EXPOSE 22 # install google test WORKDIR /usr/src/libraries RUN git clone --depth=1 -b main https://github.com/google/googletest.git WORKDIR /usr/src/libraries/googletest/build RUN cmake .. \\ &amp;&amp; make \\ &amp;&amp; make install WORKDIR / CMD [&quot;./main&quot;] Dockerfile的一些规则 文件名称为Dockerfile 表示注释 每条保留字都必须是大写字母后面跟着一些参数 每条指令从上倒下顺序执行 Docker官网 Docker官网：http://www.docker.com Docker Hub: http://hub.docker.com C++参考书籍 层级一：语法/语意(C++) C++ Primer ( 中文版，侯俊杰 译) by Stanley B. Lippman 层级二：专家经验(C++/OOP) (More )Effective C++(中文版,侯俊杰 译), by Scott Meyers. (More )Exceptional C++ (中文版,侯俊杰 译), by Herb Sutter Effective Modern C++, by Scott Meyers 层级三：底层机制(C++ Object Model) Inside the C++ Object Model (深度探索C++物件模型，侯俊杰 译),by Stanley Lippman. 层级四：设计观念的复用(C++/Patterns) Design Patterns：Elements of Reusable Object Oriented Software,by Erich Gamma,Richard Helm,Ralph Johnson,and John Vlissides Modern C++ Design: Generic Programming and Design Patterns Applied by Andrei Alexandrescu. 更多参考书籍可以查看https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list ","link":"https://kimokcheon.github.io/post/li-yong-wsldockeryuan-sheng-linuxdocker-pei-zhi-linux-cke-cheng-shi-yan-huan-jing/"},{"title":"使用telnet和ssh登录linux","content":"#telnet简介 Telnet协议是TCP/IP协议家族中的一员，是Internet远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的能力。在终端使用者的电脑上使用telnet程序，用它连接到服务器。终端使用者可以在telnet程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。可以在本地就能控制服务器。要开始一个telnet会话，必须输入用户名和密码来登录服务器。Telnet是常用的远程控制Web服务器的方法。 #telnet登录 例：使用telnet命令登录到127.0.0.1主机。登录用户：user01，密码：12345678，登录成功后退出登录。 telnet 127.0.0.1 user01 12345678 exit #SSH简介 Secure Shell(SSH) 是由 IETF(The Internet Engineering Task Force) 制定的建立在应用层基础上的安全网络协议。它是专为远程登录会话(甚至可以用Windows远程登录Linux服务器进行文件互传)和其他网络服务提供安全性的协议，可有效弥补网络中的漏洞。通过SSH，可以把所有传输的数据进行加密，也能够防止DNS欺骗和IP欺骗。还有一个额外的好处就是传输的数据是经过压缩的，所以可以加快传输的速度。目前已经成为Linux系统的标准配置。 #SSH的安全机制 SSH之所以能够保证安全，原因在于它采用了非对称加密技术(RSA)加密了所有传输的数据。 传统的网络服务程序，如FTP、Pop和Telnet其本质上都是不安全的；因为它们在网络上用明文传送数据、用户帐号和用户口令，很容易受到中间人（man-in-the-middle）攻击方式的攻击。就是存在另一个人或者一台机器冒充真正的服务器接收用户传给服务器的数据，然后再冒充用户把数据传给真正的服务器。 但并不是说SSH就是绝对安全的，因为它本身提供两种级别的验证方法： 第一种级别（基于口令的安全验证）：只要你知道自己帐号和口令，就可以登录到远程主机。所有传输的数据都会被加密，但是不能保证你正在连接的服务器就是你想连接的服务器。可能会有别的服务器在冒充真正的服务器，也就是受到“中间人攻击”这种方式的攻击。 第二种级别（基于密钥的安全验证）：你必须为自己创建一对密钥，并把公钥放在需要访问的服务器上。如果你要连接到SSH服务器上，客户端软件就会向服务器发出请求，请求用你的密钥进行安全验证。服务器收到请求之后，先在该服务器上你的主目录下寻找你的公钥，然后把它和你发送过来的公钥进行比较。如果两个密钥一致，服务器就用公钥加密“质询”(challenge)并把它发送给客户端软件。客户端软件收到“质询”之后就可以用你的私钥在本地解密再把它发送给服务器完成登录。与第一种级别相比，第二种级别不仅加密所有传输的数据，也不需要在网络上传送口令，因此安全性更高，可以有效防止中间人攻击。 #SSH的安装与运行 SSH分为客户端 openssh-client 和服务器 openssh-server，可以利用以下命令确认电脑上是否安装了客户端和服务器。 dpkg -l | grep ssh 开放本机的SSH服务就需要安装服务器 sudo apt-get install openssh-client sudo apt-get install openssh-server 启动服务器的SSH服务 ps -e | grep ssh//确认启动 未启动则 sudo /etc/init.d/ssh start 停止和重启ssh服务的命令如下：停止和重启ssh服务的命令如下： sudo /etc/init.d/ssh stop #server停止ssh服务 sudo /etc/init.d/ssh restart #server重启ssh服务 #SSH登录 ##口令登录 例：ssh命令登录到127.0.0.1主机。登录用户：user01，密码：12345678，登录成功后退出登录。 ssh user01@127.0.0.1 12345678 exit 如果被控端没有 user01 用户，那么创建user01 用户；如果没有开启telnet服务，那么手动开启telnet服务； 如果需要调用图形界面程序可以使用 -X 选项 ssh -X user01@127.0.0.1 如果客户机的用户名和服务器的用户名相同，登录时可以省略用户名 ssh 127.0.0.1 还要说明的是，SSH服务的默认端口是22，也就是说，如果你不设置端口的话登录请求会自动送到远程主机的22端口。我们可以使用 -p 选项来修改端口号，比如连接到服务器的1234端口： ssh -p 1234 user01@127.0.0.1 客户机必须要知道服务器的ip地址。可以在服务器端电脑上利用 ifconfig 命令查看该机的ip地址： ##公钥登录 ###在本机生成密钥对 ssh-keygen -t rsa #-t表示类型选项，这里采用rsa加密算法 然后根据提示一步步的按enter键即可（其中有一个提示是要求设置私钥口令passphrase，不设置则为空，这里看心情吧，如果不放心私钥的安全可以设置一下），执行结束以后会在 /home/当前用户 目录下生成一个 .ssh 文件夹,其中包含私钥文件 id_rsa 和公钥文件 id_rsa.pub。 ###将公钥复制到远程主机中 使用ssh-copy-id命令将公钥复制到远程主机。ssh-copy-id会将公钥写到远程主机的 ~/ .ssh/authorized_key 文件中 ssh-copy-id user01@127.0.0.1 #SSH使用远程主机不中断的跑程序 当我们利用ssh在远程主机上跑程序的时候，只要关闭了终端就会中断ssh连接，然后远程主机上正在跑的程序或者服务就会自动停止运行。我们可以利用 nohup + 需要运行的程序 使运行的程序在切断ssh连接的时候仍然能够继续在远程主机中运行。nohup即no hang up(不挂起)。 用Termux搞个好玩的，用手机操作电脑。具体来说就是实现了从手机上连接到电脑的cmd命令行窗口。借助ssh实现。 电脑安装和开启ssh 系统：win10 参考教程：win10 开启ssh server服务 远程登录 安装OpenSSH：按照下面几张图片依次找到设置 - 应用 - 可选功能 - 添加功能 找到OpenSSH服务器和OpenSSH客户端，选择安装（两个都要装） 到cmd中输入ssh，若出现下图结果说明客户端安装成功 启动SSH服务：以管理员身份运行cmd（否则会出现系统错误），执行命令 net start sshd 出现下图界面即为成功 注：可以使用命令 net stop sshd 来关闭SSH。 手机安装SSH并连接到电脑 到Termux下，执行命令 pkg install openssh 然后可以用命令 ssh username@ip 来连接电脑，其中username是你的电脑的用户名，ip是你的电脑的IP地址。 如何查看自己电脑的IP地址？在电脑命令行中输入 ipconfig 即可找到。例如我的是： 第一次连接时会出现如下提示 The authenticity of host 'host (xx.xxx.xx.xx)' can't be established. RSA key fingerprint is XX:XX:XX...... Are you sure you want to continue connecting (yes/no)? 意思是这个服务器的真实性尚未被证实，它的公钥指纹是XX:XX:XX:...，问你是否要继续连接？输入yes即可，它会将这个公钥加入到自己的列表中，日后就不需要再确认了。 之后会要求你输入密码，输入电脑的开机密码即可。出现下图即为成功。 可以输入exit退出SSH，回到原界面。 用Screenfetch测试连接成功 screenfetch可以显示当前运行的设备信息。我们先在电脑上以管理员权限打开powershell，按照如下步骤进行[1]： 输入 Install-Module -Name windows-screenfetch，回车（输入Y，接受） 输入 Set-ExecutionPolicy -ExecutionPolicy Unrestricted，回车（输入Y，接受） 输入 Import-Module windows-screenfetch 输入Screenfetch测试，出现下图界面即为安装成功： 我们先将powershell的路径添加到环境变量中： (1) 新建名为powershell，值为powershell所在文件夹的系统变量： (2) 向系统变量Path中添加%powershell%： 这样就可以直接在cmd中输入powershell打开powershell，而不用cd到powershell所在的目录，这对于手机操作尤为方便。 铺垫完成，我们下面在手机中使用Screenfetch，来确定自己的确用手机操控打开了电脑。 如果我们没有用ssh连接到电脑，直接在Termux上先使用pkg install screenfetch安装screenfetch（注意这里首字母s是小写，与上面不同），再执行命令screenfetch的话，看到的是安卓机的设备信息： 我们执行命令 ssh username@ip （同样地，username是你的电脑的用户名，ip是你的电脑的IP地址）来连接电脑，然后执行命令 powershell # 进入powershell Screenfetch # 打开Screenfetch，注意S大写 看到如下界面，说明的确连接到了我们的电脑。 后记 连接到电脑就可以干一些好玩的事情了，比如我们在手机上就可以浏览电脑上的文件，也可以用http-server在手机浏览器上看电脑上保存的视频，用cmd跑电脑上的程序。其实就是把电脑当作了一台可供同一局域网中设备访问的服务器。 美中不足的是，我们必须保证电脑和手机都在同一个局域网中，否则SSH无法连接。那能不能不在同一个局域网中依然可以访问呢？是可以的，利用内网穿透技术即可，我现在还没搞，之后搞了的话会在这里再次更新的。 如果要基于http-server实现功能，就必须要有shell，电脑上直接用cmd来搞就可以，手机上得有能支持shell的平台，我们这里选用Termux。教程参考此处：Termux 入门教程：架设手机 Server 下载文件 用Termux实现手机向电脑传输文件 Termux在安卓手机上模拟了Linux平台。这里分为三步走：安装Termux，安装Node.js，通过Node.js运行http-server。 1. 安装Termux Google Play商店因为技术原因已经停止更新Termux，故我们从GitHub上直接下载，地址为：https://github.com/termux/termux-app/releases。[2] 选择一个apk文件下载安装后直接打开应用，可以看到这样的界面： 做一下简单的环境准备： 执行下面两条命令更新系统： # 连接远程仓库，获取软件包信息 $ apt update # 更新本地已经安装的软件包 $ apt upgrade 可以安装运行sl软件包测试系统是否正常： # 安装 sl 软件包 $ apt install sl # 运行 $ sl 如果一切正常，会显示一个火车的命令行动画。 然后让手机能访问本地存储（重要）： $ termux-setup-storage 执行完之后手机会询问是否允许Termux访问本地存储，选择“始终允许”。 这样的话键入ls会看到本地目录下多了一个storage目录： 2. 安装Node.js 执行命令 $ apt install nodejs 即可安装Node.js 3. 架设Server 现在，通过 Node.js 运行 HTTP Server。 首先，安装 npm 模块http-server。 $ npm install -g http-server 然后，运行 Server。 $ http-server 正常情况下，命令行会提示 Server 已经在 8080 端口运行了，并且还会提示外部可以访问的 IP 地址。 这时，在电脑浏览器地址栏输入&quot;Available on&quot;后面的某个ip地址就能访问了（第一个不是，可能是第二个也可能是第三个，都试试肯定有一个能行），如下图： 可以看到，storage文件夹下面保存了手机中的图片、视频等文件： 实现电脑向手机传输文件 与手机端类似，不过这次我们可以直接用命令行窗口来搞了。 安装配置Node.js 参考这则教程：nodejs本地环境配置(windows10) 安装http-server 直接在cmd窗口中执行 npm install http-server 安装http-server。安装完毕后找到本地Node.js的目录，将其中node-global的路径放入环境变量中： 右键此电脑 - 属性 - 高级系统设置 - 环境变量，出现窗口： 找到系统变量中的Path，双击打开，然后新建环境变量并将node-global的路径放入其中，如图所示： 这时候到你想要分享的文件夹下，打开cmd，执行命令 http-server 看到如下窗口： 有了手机端的经验，我们直接在手机浏览器地址栏输入之前输入的ip地址，比如我的就是https://10.204.26.21:8080，就能得到如下的界面： 这些文件就可以下载到手机中了。 关于Termux，多说两句 Termux可以在手机上模拟Linux，那就可以写一些简单的C程序或者python程序了，比如我们可以用下面的命令安装clang包，支持C程序编译和运行 pkg install clang 再安装文本编辑器vim pkg install vim 这时候就可以像在电脑端linux的终端那样编写C代码了。当然也可以活学活用，比如把电脑上的C程序通过http-server传到手机上，再用Termux打开并保存。比如我在电脑上写了一个多项式求导的C程序，保存到手机上: 用gcc编译运行这个程序，就和电脑运行一模一样： 后续 之后想使用http-server，如果在电脑上，到想要共享的路径下打开cmd，输入http-server即可；如果在手机上，打开Termux，转到想要共享的路径下，输入http-server即可。 #参考教程 https://blog.csdn.net/pipisorry/article/details/52269785 https://blog.csdn.net/li528405176/article/details/82810342 来源：Windows10 安装 Screenfetch ↩︎ 更多Termux app相关内容可见此处。 ↩︎ ","link":"https://kimokcheon.github.io/post/shi-yong-telnet-he-ssh-deng-lu-linux/"},{"title":"Git 随记","content":"# 在当前目录新建一个Git代码库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 下载远程仓库 $ git clone xxxxxxx # 显示当前的Git配置 $ git config --list # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name &quot;[name]&quot; $ git config [--global] user.email &quot;[email address]&quot; Config表示告诉git系统你是谁 因为系统可能有多个用户，需要区分开 添加所有文件 # 添加当前目录的所有文件到暂存区 $ git add . # 添加指定文件到暂存区 $ git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录 $ git add [dir] # 添加每个变化前，都会要求确认 对于同一个文件的多处变化，可以实现分次提交 $ git add -p # 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1] [file2] ... # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed] Add 是非常重要的，git默认不会上传你的任何文件 Add相当于告诉git系统你哪些文件需要版本管理和上传 # 提交暂存区到仓库区 $ git commit -m [message] # 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] ... -m [message] # 提交工作区自上次commit之后的变化，直接到仓库区 $ git commit -a # 提交时显示所有diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] # 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [file1] [file2] ... Commit的含义是保存一份文件的备份 提交到版本管理系统，但是此时文件还在本地 # 下载远程仓库的所有变动 $ git fetch [remote] # 显示所有远程仓库 $ git remote -v # 显示某个远程仓库的信息 $ git remote show [remote] # 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --force # 推送所有分支到远程仓库 $ git push [remote] --all Pull = fetch + merge Push就是推送到远程 Commit之后，数据还只是在你电脑上 Push之后才会存到云端 如果不push，电脑坏了代码就GG 每天打开电脑，最先做的事情就是pull 因为你push之后别人可能push过 如果有冲突则必须新建分支然后merge（合并代码） 牢记Git使用流程： 上班---pull---改代码---add---commit/merge—push—下班 # 恢复暂存区的指定文件到工作区 $ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区 $ git checkout [commit] [file] # 恢复暂存区的所有文件到工作区 $ git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 $ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致 $ git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 $ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git reset --keep [commit] # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit] # 暂时将未提交的变化移除，稍后再移入 $ git stash $ git stash pop git stash [save message]保存，save为可选项，message为本次保存的注释 git stash list所有保存的记录列表 git stash pop stash@{num}恢复，num是可选项，通过git stash list可查看具体值。只能恢复一次 git stash apply stash@{num}恢复，num是可选项，通过git stash list可查看具体值。可回复多次 git stash drop stash@{num}删除某个保存，num是可选项，通过git stash list可查看具体值 git stash clear 查看所有分支： git branch –a 创建分支命令： git branch (branchname) 切换分支命令: git checkout (branchname) 现在，你已经决定要解决你的公司使用的问题追踪系统中的 #53 问题。 想要新建一个分支并同时切换到那个分支上，你可以运行一个带有 -b 参数的 git checkout 命令： $ git checkout -b iss53 Switched to a new branch &quot;iss53&quot; 它是下面两条命令的简写： $ git branch iss53 $ git checkout iss53 创建一个新分支指针。 创建一个新分支指针 你继续在 #53 问题上工作，并且做了一些提交。 在此过程中，iss53 分支在不断的向前推进，因为你已经检出到该分支 （也就是说，你的 HEAD 指针指向了 iss53 分支） $ vim index.html $ git commit -a -m 'added a new footer [issue 53]' 安装LFS 注意：安装 Git LFS 需要 Git 的版本不低于 1.8.5 Linux curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash sudo apt-get install git-lfs git lfs install 开启lfs功能 $ git lfs install 追踪大文件 $ git lfs track xxx # 例如追踪所有后缀为png的文件 $ git lfs track &quot;*.png“ # 提交文件 $ git commit -m &quot;xxx&quot; $ git push # 查看现有的文件追踪模式 $ git lfs track # 显示当前跟踪的文件列表 $ git lfs ls-files ","link":"https://kimokcheon.github.io/post/git-sui-ji/"},{"title":"Yuchuan Deng","content":"About me Hi! I am an undergraduate in Computer Science and Technology at Sichuan University and expected to graduate in June 2025. I have engaged in research projects related to Deep Learning (DL), Computer Vision (CV), MultiModal Machine Learning (MMML), etc. My current advisor is Prof. Qijun Zhao from the College of Computer Science. Education Sichuan University, Chengdu, Sichuan, China (2021.9 ~ Present) Experience Biometrics Research Lab, Sichuan University Research Asisistant (Sep.2021.9 to present) Advisor: Prof. Qijun Zhao IAPR/IEEE Winter School on Biometrics 2023 Visiting Student (Jan.2023.1.8 to Jul.2023.1.12) Advisor: Associate Prof. Shiqi Yu Association of Biometrics, Sichuan University The president of the association of biometrics (Sep.2023 to present) NUS SOC Summer Workshop, National University of Singapore Visiting Student (Jul.2023.7.4 to Jul.2023.7.25) Advisor: Associate Prof. Terence SIM Honors &amp; Awards Meritorious Award in 2023 US (International) College Student Mathematical Modeling Competition Provincial Second Prize in 2022 National College Student Mathematical Modeling Competition Huawei Certified Artificial Intelligence Engineer (HCIA-AI) Principal of the Innovation and Entrepreneurship Project for College Students at the School Level: &quot;Portrait Generation Based on Text Description and Low Quality Images&quot; (Project Number: 202310611040) Member of the Provincial College Student Innovation and Entrepreneurship Project &quot;Intelligent Guide System for Scenic Spots Based on Augmented Reality&quot; (Project Number: S202310610251) IAPR/IEEE WSB2023 Outstanding Participation IAPR/IEEE WSB2023 Outstanding Project Member of the FCN Image Semantic Segmentation Group for the MindSpot Zhongzhi Project between Sichuan University and Huawei (has been added to the MindSpot official routine) The second prize of the 9th &quot;Internet plus&quot; Undergraduate Innovation and Entrepreneurship Competition of Sichuan University (second place for core members) Third Prize of &quot;Challenge and Guess&quot; for Top Students in Basic Disciplines at Sichuan University in 2023 (Principal) Skills Programming Languages: Python, C/C++, Java, JavaScript, HTML/CSS, Bash, SQL Tools and Framework: Git, \\LaTex, Pytorch, Bazel, Docker, MindSpore, Tensorflow, React ","link":"https://kimokcheon.github.io/post/about-me/"}]}